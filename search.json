[
  {
    "objectID": "blogs/GitHub_Actions_Introduction/001_GitHub_Actions_Introduction.html",
    "href": "blogs/GitHub_Actions_Introduction/001_GitHub_Actions_Introduction.html",
    "title": "GitHub Actions Introduction",
    "section": "",
    "text": "GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline. You can create workflows that build and test every pull request to your repository, or deploy merged pull requests to production.\nGitHub Actions goes beyond just DevOps and lets you run workflows when other events happen in your repository. For example, you can run a workflow to automatically add the appropriate labels whenever someone creates a new issue in your repository.\nGitHub provides Linux, Windows, and macOS virtual machines to run your workflows, or you can host your own self-hosted runners in your own data center or cloud infrastructure."
  },
  {
    "objectID": "blogs/GitHub_Actions_Introduction/001_GitHub_Actions_Introduction.html#overview",
    "href": "blogs/GitHub_Actions_Introduction/001_GitHub_Actions_Introduction.html#overview",
    "title": "GitHub Actions Introduction",
    "section": "",
    "text": "GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline. You can create workflows that build and test every pull request to your repository, or deploy merged pull requests to production.\nGitHub Actions goes beyond just DevOps and lets you run workflows when other events happen in your repository. For example, you can run a workflow to automatically add the appropriate labels whenever someone creates a new issue in your repository.\nGitHub provides Linux, Windows, and macOS virtual machines to run your workflows, or you can host your own self-hosted runners in your own data center or cloud infrastructure."
  },
  {
    "objectID": "blogs/GitHub_Actions_Introduction/001_GitHub_Actions_Introduction.html#the-components-of-github-actions",
    "href": "blogs/GitHub_Actions_Introduction/001_GitHub_Actions_Introduction.html#the-components-of-github-actions",
    "title": "GitHub Actions Introduction",
    "section": "The components of GitHub Actions",
    "text": "The components of GitHub Actions\nYou can configure a GitHub Actions¬†workflow¬†to be triggered when an¬†event¬†occurs in your repository, such as a pull request being opened or an issue being created. Your workflow contains one or more¬†jobs¬†which can run in sequential order or in parallel. Each job will run inside its own virtual machine¬†runner, or inside a container, and has one or more¬†steps¬†that either run a script that you define or run an¬†action, which is a reusable extension that can simplify your workflow.\n\n\n\nThe_concept_of_GitHub_Actions\n\n\n\nWorkflows\nA workflow is a configurable automated process that will run one or more jobs.\nWorkflows are defined by a YAML file checked in to your repository and will run when triggered by an event in your repository, or they can be triggered manually, or at a defined schedule.\nWorkflows are defined in the¬†.github/workflows¬†directory in a repository, and a repository can have multiple workflows, each of which can perform a different set of tasks.\n\n\n\n\n\n\nFor example, you can have one workflow to build and test pull requests, another workflow to deploy your application every time a release is created, and still another workflow that adds a label every time someone opens a new issue.\n\n\n\nYou can reference a workflow within another workflow. For more information, see ‚ÄúReusing workflows.‚Äù For more information about workflows, see ‚ÄúUsing workflows.‚Äù\n\n\n\nEvents\nAn event is a specific activity in a repository that triggers a workflow run.\n\n\n\n\n\n\nFor example, activity can originate from GitHub when someone creates a pull request, opens an issue, or pushes a commit to a repository. You can also trigger a workflow to run on a schedule, by¬†posting to a REST API, or manually.\n\n\n\nFor a complete list of events that can be used to trigger workflows, see¬†Events that trigger workflows.\n\n\n\nJobs\nA job is a set of¬†steps¬†in a workflow that is executed on the same runner.\nEach step is either a shell script that will be executed, or an¬†action that will be run. Steps are executed in order and are dependent on each other.Since each step is executed on the same runner, you can share data from one step to another.\n\n\n\n\n\n\nFor example, you can have a step that builds your application followed by a step that tests the application that was built.\n\n\n\nYou can configure a job‚Äôs dependencies with other jobs; by default, jobs have no dependencies and run in parallel with each other. When a job takes a dependency on another job, it will wait for the dependent job to complete before it can run.\n\n\n\n\n\n\nFor example, you may have multiple build jobs for different architectures that have no dependencies, and a packaging job that is dependent on those jobs. The build jobs will run in parallel, and when they have all completed successfully, the packaging job will run.\n\n\n\nFor more information about jobs, see ‚ÄúUsing jobs.‚Äù\n\n\n\nActions\n\n\n\n\n\n\nImportant\n\n\n\nAn¬†action¬†is a custom application for the GitHub Actions platform that performs a complex but frequently repeated task. Use an action to help reduce the amount of repetitive code that you write in your workflow files.\n\n\n\n\n\n\n\n\nAn action can pull your git repository from GitHub, set up the correct toolchain for your build environment, or set up the authentication to your cloud provider.\n\n\n\nYou can write your own actions, or you can find actions to use in your workflows in the GitHub Marketplace. For more information, see ‚ÄúCreating actions.‚Äù\n\n\n\nRunners\n\n\n\n\n\n\nImportant\n\n\n\nA runner is a server that runs your workflows when they‚Äôre triggered. Each runner can run a single job at a time.\n\n\n\n\n\n\n\n\nGitHub provides Ubuntu Linux, Microsoft Windows, and macOS runners to run your workflows; each workflow run executes in a fresh, newly-provisioned virtual machine.\n\n\n\nGitHub also offers larger runners, which are available in larger configurations. For more information, see ‚ÄúAbout larger runners.‚Äù If you need a different operating system or require a specific hardware configuration, you can host your own runners. For more information about self-hosted runners, see ‚ÄúHosting your own runners.‚Äù"
  },
  {
    "objectID": "blogs/GitHub_Actions_Introduction/001_GitHub_Actions_Introduction.html#create-an-workflow",
    "href": "blogs/GitHub_Actions_Introduction/001_GitHub_Actions_Introduction.html#create-an-workflow",
    "title": "GitHub Actions Introduction",
    "section": "Create an workflow",
    "text": "Create an workflow\nGitHub Actions uses YAML syntax to define the workflow. Each workflow is stored as a separate YAML file in your code repository, in a directory named¬†.github/workflows.\nYou can create an example workflow in your repository that automatically triggers a series of commands whenever code is pushed. 1. In your repository, create the¬†.github/workflows/¬†directory to store your workflow files. 2. In the¬†.github/workflows/¬†directory, create a new file called¬†your_file_name.yml¬†and write the code. 3. Commit these changes and push them to your GitHub repository.\nYour new GitHub Actions workflow file is now installed in your repository and will run automatically each time someone pushes a change to the repository. To see the details about a workflow‚Äôs execution history, see ‚ÄúViewing the activity for a workflow run.‚Äù\n\nCode Block\n# This is a comment line, and it's for providing information about the workflow.\n# The name of the workflow is \"Hello world workflow.\"\nname: Hello word workflow\n\n# This section defines when the workflow should run.\non:\n  # This workflow runs when there's a code push to the \"main\" branch.\n  push:\n    branches:\n      - main\n  # This workflow also runs when there's a pull request to the \"main\" branch.\n  pull_request:\n    branches:\n      - main\n  # This line allows manual triggering of the workflow through the GitHub Actions web interface.\n  workflow_dispatch:\n\n# This section defines the jobs that this workflow contains.\njobs:\n  # This is the first job named \"hello.\"\n  hello:\n    # It runs on an \"ubuntu-latest\" runner, which is a virtual machine with Ubuntu.\n    runs-on: ubuntu-latest\n    steps:\n      # This step checks out (fetches) the code from the GitHub repository onto the runner.\n      - uses: actions/checkout@v3\n      # This step is named \"hello world.\"\n      - name: hello world\n        # It runs the command \"echo 'hello world'\" in the bash shell.\n        run: echo \"hello world\"\n        # This specifies that the shell to use is \"bash.\"\n\n  # This is the second job named \"goodbye.\"\n  goodbye:\n    # It also runs on an \"ubuntu-latest\" runner.\n    runs-on: ubuntu-latest\n    steps:\n      # This step is named \"good bye world.\"\n      - name: good bye world\n        # It runs the command \"echo 'goodbye world'\" in the bash shell.\n        run: echo \"goodbye world\"\n        # This specifies that the shell to use is \"bash.\"\n\n\n\nGitHub Interface\n     \nThe only difference between the above job ‚Äòhello world‚Äô and below job ‚Äògood bye‚Äô is here we are not using GitHub‚Äôs actions/checkout i.e.¬†we‚Äôre not copying the copying the code from repository to runner. We‚Äôre running only simple shell command.\n\nExtra Utilities\n\n\n\n\nReference Material\n\n\nOfficial Documentation from GitHub for GitHub actions Personal GitHub Repository for trying the methods"
  },
  {
    "objectID": "blogs/SVM/SVM.html",
    "href": "blogs/SVM/SVM.html",
    "title": "Support Vector Machines",
    "section": "",
    "text": "SVM is a powerful supervised machine learning algorithm that works best on smaller dataset but on complex ones. Support Vector Machine, abbreviated as SVM can be used for both classification and regression tasks, but generally, they generally works best in classification problems."
  },
  {
    "objectID": "blogs/SVM/SVM.html#kernels-in-support-vector-machine",
    "href": "blogs/SVM/SVM.html#kernels-in-support-vector-machine",
    "title": "Support Vector Machines",
    "section": "Kernels in Support Vector Machine",
    "text": "Kernels in Support Vector Machine\nThe most interesting feature of SVM is that it can even work with a non-linear dataset and for this, we use ‚ÄúKernel Trick‚Äù which makes it easier to classifies the points. Suppose we have a dataset like this:\n\nHere we see we cannot draw a single line or say hyperplane which can classify the points correctly. So what we do is try converting this lower dimension space to a higher dimension space using some quadratic functions which will allow us to find a decision boundary that clearly divides the data points. These functions which help us do this are called Kernels and which kernel to use is purely determined by hyperparameter tuning.\n\n\nDifferent Kernel Functions\nSome kernel functions which you can use in SVM are given below: #### 1.¬†Polynomial Kernel Following is the formula for the polynomial kernel:\n\nHere d is the degree of the polynomial, which we need to specify manually.\nSuppose we have two features X1 and X2 and output variable as Y, so using polynomial kernel we can write it as:\n\nSo we basically need to find X12¬†, X22¬†and X1.X2, and now we can see that 2 dimensions got converted into 5 dimensions.\n\n\n2.¬†Sigmoid Kernel\nWe can use it as the proxy for neural networks. Equation is:\n\nIt is just taking your input, mapping them to a value of 0 and 1 so that they can be separated by a simple straight line.\n\n\n\n3.¬†RBF Kernel\nWhat it actually does is to create non-linear combinations of our features to lift your samples onto a higher-dimensional feature space where we can use a linear decision boundary to separate your classes It is the most used kernel in SVM classifications, the following formula explains it mathematically:\n\nwhere,\n\n\\(œÉ\\) is the variance and our hyperparameter\n\n\\(||X_‚ÇÅ ‚Äì X_‚ÇÇ||\\)¬†is the Euclidean Distance between two points X‚ÇÅ and X‚ÇÇ\n\n\n\n\n4. Bessel function kernel\nIt is mainly used for eliminating the cross term in mathematical functions. Following is the formula of the Bessel function kernel:\n\n\n\n5. Anova Kernel\nIt performs well on multidimensional regression problems. The formula for this kernel function is:\n\n\n\n\nHow to Choose the Right Kernel?\nI am well aware of the fact that you must be having this doubt about how to decide which kernel function will work efficiently for your dataset. It is necessary to choose a good kernel function because the performance of the model depends on it.\nChoosing a kernel totally depends on what kind of dataset are you working on. If it is linearly separable then you must opt. for linear kernel function since it is very easy to use and the complexity is much lower compared to other kernel functions. I‚Äôd recommend you start with a hypothesis that your data is linearly separable and choose a linear kernel function.\nYou can then¬†work your way up towards the more complex kernel functions. Usually, we use SVM with RBF and linear kernel function because other kernels like polynomial kernel are rarely used due to poor efficiency. But what if linear and RBF both give approximately similar results? Which kernel do we choose now?\n\nExample\nLet‚Äôs understand this with the help of an example, for simplicity I‚Äôll only take 2 features that mean 2 dimensions only. In the figure below I have plotted the decision boundary of a linear SVM on 2 features of the iris dataset:\n\nHere we see that a linear kernel works fine on this dataset, but now let‚Äôs see how will RBF kernel work.\n\nWe can observe that both the kernels give similar results, both work well with our dataset but which one should we choose? Linear SVM is a parametric model.¬†A Parametric Model is a concept used to describe a model in which all its data is represented within its parameters.¬† In short, the only information needed to predict the future from the current value is the parameters.\nThe complexity of the RBF kernel grows as the training data size increases.¬†In addition to the fact that it is more expensive to prepare RBF kernel,¬†we also have to keep the kernel matrix around, and the projection into this ‚Äúinfinite‚Äù higher dimensional space where the data becomes linearly separable is more expensive as well during prediction. If the dataset is not linear then using linear kernel doesn‚Äôt make sense we‚Äôll get a very low accuracy if we do so.\n\nSo for this kind of dataset, we can use RBF without even a second thought because it makes decision boundary like this:\n\n\n\nAdvantages of SVM\n\nSVM works better when the data is Linear\nIt is more effective in high dimensions\nWith the help of the kernel trick, we can solve any complex problem\nSVM is not sensitive to outliers\nCan help us with Image classification\n\n\n\nDisadvantages of SVM\n\nChoosing a good kernel is not easy\nIt doesn‚Äôt show good results on a big dataset\nThe SVM hyperparameters are Cost -C and gamma. It is not that easy to fine-tune these hyper-parameters. It is hard to visualize their impact"
  },
  {
    "objectID": "blogs/SVM/SVM.html#conclusion",
    "href": "blogs/SVM/SVM.html#conclusion",
    "title": "Support Vector Machines",
    "section": "Conclusion",
    "text": "Conclusion\nIn this article, we looked at a very powerful machine learning algorithm, Support Vector Machine in detail. I discussed its concept of working, math intuition behind SVM, implementation in python, the tricks to classify non-linear datasets, Pros and cons, and finally, we solved a problem with the help of SVM."
  },
  {
    "objectID": "blogs/Unsupervised_Learning_Algorithms/Unsupervised Learning Algorithms.html",
    "href": "blogs/Unsupervised_Learning_Algorithms/Unsupervised Learning Algorithms.html",
    "title": "Unsupervised Learning Algorithms",
    "section": "",
    "text": "Imagine you give the computer a bunch of puzzle pieces without telling it what the picture should be. Unsupervised learning is like asking the computer to figure out if these pieces naturally form any meaningful patterns.\n\n\n\nunsupervised algorithms\n\n\nWhy Do We Use It?\nUnsupervised learning helps the computer discover hidden structures, group similar things, and uncover secrets within data.\nThe Heroes of Unsupervised Learning\n\nK-Means Clustering: Think of it as the computer‚Äôs way of putting similar items into groups. It‚Äôs like sorting fruits by their type without telling the computer what each fruit is.\nPrincipal Component Analysis (PCA): Imagine the computer finding the most important parts of a big puzzle. It‚Äôs used to reduce complex data into simpler pieces while keeping the essential information.\n\nHow It Works\n\nNo Teacher Needed: In unsupervised learning, there are no ‚Äúright answers‚Äù provided during training. The computer explores data independently.\nDiscovering Patterns: It looks for similarities, differences, and structures within the data without us guiding it.\n\nIn the Real World\n\nSorting customer preferences in online shopping.\nGrouping news articles into topics without prior labels.\nIdentifying patterns in medical data for disease diagnosis.\n\nPros and Cons\n\nPros: It‚Äôs great for exploring unknown data structures and reducing data complexity.\nCons: You might need to interpret the results yourself, and it can be tricky if there are no clear patterns.\n\nTakeaway\nUnsupervised learning is like letting a detective loose in a mysterious room with no clues. It‚Äôs a valuable tool when you want the computer to find hidden gems and structures within your data, even when you don‚Äôt know exactly what to look for.\n\n\nReference Reading\n# Unsupervised Learning: Types, Applications & Advantages"
  },
  {
    "objectID": "blogs/GitHub_Actions_Continuous_Integration_CI/002_GitHub_Actions_Continuous_Integration_CI.html#before-continuous-integration-automation",
    "href": "blogs/GitHub_Actions_Continuous_Integration_CI/002_GitHub_Actions_Continuous_Integration_CI.html#before-continuous-integration-automation",
    "title": "GitHub Actions Continuous Integration CI",
    "section": "Before Continuous Integration Automation",
    "text": "Before Continuous Integration Automation\n\nSCM:\nBefore the introduction of modern tools like GitHub, source code management (SCM) primarily relied on older systems and practices. One of the earliest forms of SCM was manual version control, where developers would create backups or copies of their code and manually track changes. Here‚Äôs how SCM worked in the ‚Äúolden days‚Äù before platforms like GitHub:\n\n\n\n\n\n\nSCM -&gt; Source Code Management System\n\n\n\n\nLocal Backups: Developers would often maintain local backups of their code on their own computers or servers. These backups were typically directories or folders containing different versions of the code.\nLabels or Tags: Developers would label or tag specific versions of their code with names or numbers to indicate milestones, releases, or significant changes.These labels helped in identifying and retrieving specific versions when needed.\nDocumentation: Detailed documentation about code changes, bug fixes, and new features was crucial. Developers would maintain written logs or files that described the modifications made in each version of the code.\nManual Collaboration: Collaboration among developers was challenging. They would often share code changes through emails, physical copies, or by copying files to shared network drives. Merging changes from different contributors was a manual and error-prone process.\nRisk of Overwrites: Without robust SCM tools, there was a significant risk of accidentally overwriting someone else‚Äôs changes, leading to code conflicts and errors.\nLimited Visibility: It was difficult to have a comprehensive view of the entire project‚Äôs history and changes. Developers had to rely on their local records and communication with colleagues to understand the evolution of the codebase.\nNo Central Repository: Unlike modern SCM systems that have a central repository (like GitHub), older SCM relied on each developer‚Äôs local copies and backups. This decentralized approach could lead to data loss if a developer‚Äôs machine failed or backups were not maintained properly.\n\n\n\n\nCentral Repository:\nBefore the introduction of centralized platforms like GitHub, central repositories for source code management (SCM) were typically set up and maintained using traditional version control systems or network file systems. Here‚Äôs how central repositories worked in the ‚Äúolden days‚Äù before GitHub:\n\nVersion Control Systems (VCS): Organizations often used traditional VCS software like CVS (Concurrent Versions System) or SVN (Subversion) to create central repositories. These systems allowed developers to check in and check out code from a central location.\nLocal Copies: Developers had local copies of the code on their own machines, but the authoritative or master copy resided in the central repository. Developers would make changes to their local copies and then commit those changes to the central repository.\nAccess Control: Access to the central repository was controlled through user authentication and permissions. Typically, only authorized individuals or teams had write access to the central repository, while others had read-only access.\nCheck-In and Check-Out: Developers would check out code from the central repository to work on it. When they were done making changes, they would check the code back into the central repository. This process ensured that changes were tracked and managed centrally.\nVersion History: The central repository maintained a version history of the code. Each check-in or commit created a new version, allowing developers to see how the code evolved over time.\nBranching and Merging: These systems supported branching and merging, but it was often a more manual and less user-friendly process compared to modern distributed version control systems like Git. Merging code changes from different branches could be complex.\nCommunication: Collaboration and communication among developers were essential. Developers needed to coordinate with each other to avoid conflicts when making changes to the central repository.\nBackup and Recovery: Maintaining backups of the central repository was crucial because the loss of the central repository could result in significant data loss. Regular backups were often performed to ensure data integrity.\nLimited Collaboration Features: Unlike modern platforms like GitHub, these central repositories typically lacked collaboration features such as issue tracking, pull requests, and code review tools. Collaboration mainly happened outside the central repository using email or other communication tools.\n\n\n\n\nDeveloper Team\nFor the understanding purpose, we are working on a application with the olden system as discussed above with [[002_GitHub_Actions_Continuous_Integration_CI#SCM| SCM]] and [[002_GitHub_Actions_Continuous_Integration_CI#Central Repository| repository system]].\nOur developers are working on features, every developer is working on individual feature.\nFor the time sake, we say every developer is responsible for the feature he is assign to, he doesn‚Äôt know about the working code of other developer\nAfter completing the feature, the developer will check in the code into the central repository. Similarly other developers will also do the same. Once all the developers have check in the code, there work is complete for the time being.\n\n\n\nIntegration Team\nHere we will have integration team for the integration of code, they will checkout the code for each feature from the central repository and will build the application on a machine.\nThe goal of integration team is: - Integrate all the code for the feature and build it. - Run the code. - Test the integration quality.\nWhat doesn‚Äôt come under their scope: - Test the features according to the specification and design.\nOnce they finished the integration, they will share the details with the QA (Quality Assurance) team for further testing.\n\n\n\nQuality Assurance (QA) Team\nAfter the integration of the code, and building. The QA team will test the features if they meet the specification and business requirements.\nIf they find any problem with the features, they will send the code back to the developer and the process will repeat again.\n(developer team) feature development/bug fixing ‚Äì&gt; code integration ‚Äì&gt; quality assurance tests.\n\n\n\nProblem with Manual Approach\n\nTime consuming\nExtra manpower\nCost expensive."
  },
  {
    "objectID": "blogs/GitHub_Actions_Continuous_Integration_CI/002_GitHub_Actions_Continuous_Integration_CI.html#with-continuous-integration",
    "href": "blogs/GitHub_Actions_Continuous_Integration_CI/002_GitHub_Actions_Continuous_Integration_CI.html#with-continuous-integration",
    "title": "GitHub Actions Continuous Integration CI",
    "section": "With Continuous Integration",
    "text": "With Continuous Integration\n\nIn this approach we will use the same problem statement of building an application.\nHere we will use git as SCM and GitHub as Central Repository\nHere the developers will start working on the features, and with each code update they will check in the code in the central repository. In this approach, the developer will not have to worry about the other developers, he can work in his own feature branch at his own pace. He can also track the progress of other developers."
  },
  {
    "objectID": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#introduction",
    "href": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#introduction",
    "title": "Accessing Ollama in Free Google Colab Session",
    "section": "Introduction",
    "text": "Introduction\nThis guide walks you through running Large Language Models (LLMs) locally in a free Google Colab environment using Ollama. It covers setting up terminal access, installing Ollama, pulling models like LLaMA3 and DeepSeek, and performing inference using Python libraries such as requests, ollama, and openai. Ideal for developers looking to experiment with local LLMs without needing a powerful machine.\n\nStep-by-Step Setup\n\nEnable Terminal Access in Colab\n\nInstall colab-xterm package:\n!pip install colab-xterm\nLoad the xterm extension:\n%load_ext colabxterm\nOpen a terminal window:\n %xterm\n\n\n\nInstall and Run Ollama from Terminal\n\nIn the terminal, run the following to install Ollama:\ncurl -fsSL https://ollama.com/install.sh | sh\nThen run the following command in terminal to pull the model from ollma model repository and host it on google colab:\nollama serve & ollma pull llama3.2"
  },
  {
    "objectID": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#creating-payload-and-inference-via-local-url",
    "href": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#creating-payload-and-inference-via-local-url",
    "title": "Accessing Ollama in Free Google Colab Session",
    "section": "2. Creating Payload and Inference via Local URL",
    "text": "2. Creating Payload and Inference via Local URL\n\nSample Payload Format\nMODEL = \"llama3.2\"\nOLLAMA_API = \"http://localhost:11434/api/chat\"\nHEADERS = {\"Content-Type\": \"application/json\"}\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n]\n\npayload = {\n    \"model\": MODEL,\n    \"messages\": messages,\n    \"stream\": False\n}\n\n\nSending Payload via requests\nimport requests\nresponse = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\nprint(response.json()[\"message\"][\"content\"])"
  },
  {
    "objectID": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#using-the-python-ollama-library",
    "href": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#using-the-python-ollama-library",
    "title": "Accessing Ollama in Free Google Colab Session",
    "section": "3. Using the Python ollama Library",
    "text": "3. Using the Python ollama Library\n\nInstallation (if needed)\n!pip install ollama\n\n\nInference Example\nimport ollama\nresponse = ollama.chat(model=MODEL, messages=messages)\nprint(response[\"message\"][\"content\"])"
  },
  {
    "objectID": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#using-the-openai-library-for-inference-with-ollama",
    "href": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#using-the-openai-library-for-inference-with-ollama",
    "title": "Accessing Ollama in Free Google Colab Session",
    "section": "4. Using the openai Library for Inference with Ollama",
    "text": "4. Using the openai Library for Inference with Ollama\n\nInstallation\n!pip install openai\n\n\nSet API Key and Base URL (Ollama emulates OpenAI API)\nfrom openai import OpenAI\n\nclient = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n\nresponse = client.chat.completions.create(\n    model=\"llama3.2\",\n    messages=[{\"role\": \"user\", \"content\": \"What is Artificial Intelligence?\"}]\n)\n\nprint(response.choices[0].message.content)"
  },
  {
    "objectID": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#pulling-and-using-deepseek-model",
    "href": "blogs/Day 2 Inferencing Local Ollama/Day 2 Inferencing Local Ollama.html#pulling-and-using-deepseek-model",
    "title": "Accessing Ollama in Free Google Colab Session",
    "section": "5. Pulling and Using DeepSeek Model",
    "text": "5. Pulling and Using DeepSeek Model\n\nPull DeepSeek Model\n!ollama pull deepseek-coder:6.7b-instruct\n\n\nInference with DeepSeek Model\nresponse = requests.post(\"http://localhost:11434/api/generate\", json={\n    \"model\": \"deepseek-coder:6.7b-instruct\",\n    \"prompt\": \"Write a Python function to compute factorial.\"\n})\nprint(response.json()[\"response\"])\nOr using Python ollama package:\nresponse = ollama.chat(model=\"deepseek-coder:6.7b-instruct\", messages=[\n    {\"role\": \"user\", \"content\": \"Explain decorators in Python\"}\n])\nprint(response[\"message\"][\"content\"])"
  },
  {
    "objectID": "blogs/Introduction_to_Algorithm/Introduction to Algorithm.html",
    "href": "blogs/Introduction_to_Algorithm/Introduction to Algorithm.html",
    "title": "Introduction to Algorithm",
    "section": "",
    "text": "In the context of machine learning and deep learning, an algorithm is like a set of step-by-step instructions that a computer follows to learn from data or make predictions.\nIt‚Äôs a recipe for the computer to process information, find patterns, and make decisions.\nThink of it as a smart way for a computer to solve problems or make sense of complex data.\nThese algorithms help us build models that can recognize patterns, understand language, or even play games, among many other things.\n\n\n\n\nIn machine learning and deep learning, there are several types of algorithms, each with its own purpose and characteristics. Here‚Äôs a simple overview of some common types:\n\n[[Supervised Learning Algorithms]]:\n\nThese algorithms learn from labeled data, where the input and the desired output are known.\nCommon algorithms include Linear Regression, Decision Trees, and Support Vector Machines (SVM). \n\n[[Unsupervised Learning Algorithms]]:\n\nThese algorithms work with unlabeled data, aiming to find hidden patterns or group similar data points.\nExamples include K-Means Clustering and Principal Component Analysis (PCA).\n\nDeep Learning Algorithms:\n\nDeep learning is a subset of machine learning that uses neural networks with many layers (deep networks) to learn from data.\nCommon deep learning algorithms include Convolutional Neural Networks (CNNs) for image analysis and Recurrent Neural Networks (RNNs) for sequence data.\n\nReinforcement Learning Algorithms:\n\nThese algorithms are used in scenarios where an agent learns to take actions to maximize rewards in an environment.\nWell-known algorithms include Q-Learning and Deep Q-Networks (DQNs).\n\nSemi-Supervised and Self-Supervised Learning:\n\nThese approaches combine elements of supervised and unsupervised learning, making use of both labeled and unlabeled data.\n\nTransfer Learning:\n\nTransfer learning involves using a pre-trained model on a related task as a starting point for a new task, saving training time and resources.\n\nEnsemble Methods:\n\nEnsemble methods combine multiple models to improve prediction accuracy. Examples include Random Forests and Gradient Boosting.\n\nNatural Language Processing (NLP) Algorithms:\n\nThese are specialized algorithms for working with text data, such as sentiment analysis and named entity recognition.\n\nDeep Reinforcement Learning:\n\nThis combines deep learning and reinforcement learning, often used in complex tasks like game playing (e.g., AlphaGo).\n\nDimensionality Reduction:\n\nAlgorithms like t-SNE and UMAP are used to reduce the number of features in high-dimensional data while preserving important relationships.\n\n\nThese are just some of the many types of algorithms used in machine learning and deep learning. The choice of algorithm depends on the specific problem you‚Äôre trying to solve and the type of data you have."
  },
  {
    "objectID": "blogs/Introduction_to_Algorithm/Introduction to Algorithm.html#introduction-to-algorithm",
    "href": "blogs/Introduction_to_Algorithm/Introduction to Algorithm.html#introduction-to-algorithm",
    "title": "Introduction to Algorithm",
    "section": "",
    "text": "In the context of machine learning and deep learning, an algorithm is like a set of step-by-step instructions that a computer follows to learn from data or make predictions.\nIt‚Äôs a recipe for the computer to process information, find patterns, and make decisions.\nThink of it as a smart way for a computer to solve problems or make sense of complex data.\nThese algorithms help us build models that can recognize patterns, understand language, or even play games, among many other things.\n\n\n\n\nIn machine learning and deep learning, there are several types of algorithms, each with its own purpose and characteristics. Here‚Äôs a simple overview of some common types:\n\n[[Supervised Learning Algorithms]]:\n\nThese algorithms learn from labeled data, where the input and the desired output are known.\nCommon algorithms include Linear Regression, Decision Trees, and Support Vector Machines (SVM). \n\n[[Unsupervised Learning Algorithms]]:\n\nThese algorithms work with unlabeled data, aiming to find hidden patterns or group similar data points.\nExamples include K-Means Clustering and Principal Component Analysis (PCA).\n\nDeep Learning Algorithms:\n\nDeep learning is a subset of machine learning that uses neural networks with many layers (deep networks) to learn from data.\nCommon deep learning algorithms include Convolutional Neural Networks (CNNs) for image analysis and Recurrent Neural Networks (RNNs) for sequence data.\n\nReinforcement Learning Algorithms:\n\nThese algorithms are used in scenarios where an agent learns to take actions to maximize rewards in an environment.\nWell-known algorithms include Q-Learning and Deep Q-Networks (DQNs).\n\nSemi-Supervised and Self-Supervised Learning:\n\nThese approaches combine elements of supervised and unsupervised learning, making use of both labeled and unlabeled data.\n\nTransfer Learning:\n\nTransfer learning involves using a pre-trained model on a related task as a starting point for a new task, saving training time and resources.\n\nEnsemble Methods:\n\nEnsemble methods combine multiple models to improve prediction accuracy. Examples include Random Forests and Gradient Boosting.\n\nNatural Language Processing (NLP) Algorithms:\n\nThese are specialized algorithms for working with text data, such as sentiment analysis and named entity recognition.\n\nDeep Reinforcement Learning:\n\nThis combines deep learning and reinforcement learning, often used in complex tasks like game playing (e.g., AlphaGo).\n\nDimensionality Reduction:\n\nAlgorithms like t-SNE and UMAP are used to reduce the number of features in high-dimensional data while preserving important relationships.\n\n\nThese are just some of the many types of algorithms used in machine learning and deep learning. The choice of algorithm depends on the specific problem you‚Äôre trying to solve and the type of data you have."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Building a Company Brochure with AI\n\n\n\n\n\n\n\n\nMay 4, 2025\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nBrand Detection\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nVegetable Recognition\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nSadashiv\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html",
    "title": "Building a Company Brochure with AI",
    "section": "",
    "text": "This project demonstrates how to create a company brochure using AI. By leveraging web scraping and OpenAI‚Äôs GPT-4o-mini, we can efficiently gather information from a company‚Äôs website and generate compelling content for prospective clients, investors, and potential recruits. This approach streamlines the brochure creation process, making it faster and more cost-effective."
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#second-step-make-the-brochure",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#second-step-make-the-brochure",
    "title": "Building a Company Brochure with AI",
    "section": "Second step: make the brochure!",
    "text": "Second step: make the brochure!\nAssemble all the details into another prompt to GPT4-o\n\n\nCode\ndef get_all_details(url):\n    result = \"Landing page:\\n\"\n    result += Website(url).get_contents()\n    links = get_links(url)\n\n    print(f\"Found links: {links}\")\n    for link in links['links']:\n        result += f\"\\n\\n{link['type']}\\n\"\n        result += Website(link['url']).get_contents()\n    return result\n\n\n\n\nCode\nprint(get_all_details(\"https://huggingface.co\"))\n\n\n\n\nCode\nsystem_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\nand creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\nInclude details of company culture, customers and careers/jobs if you have the information.\"\n\n# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n\n# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n# Include details of company culture, customers and careers/jobs if you have the information.\"\n\n\n\n\nCode\ndef get_brochure_user_prompt(company_name: str, url: str):\n    user_prompt = f\"You are looking at a company called {company_name}.\\n\"\n    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n    user_prompt += get_all_details(url)\n    user_prompt += user_prompt[:7_000]  # Truncate if more than 7,000 characters\n    return user_prompt\n\n\n\n\nCode\nget_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")\n\n\nFound links: {'links': [{'type': 'about_page', 'url': 'https://huggingface.co'}, {'type': 'careers_page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise_page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'blog_page', 'url': 'https://huggingface.co/blog'}, {'type': 'models_page', 'url': 'https://huggingface.co/models'}, {'type': 'datasets_page', 'url': 'https://huggingface.co/datasets'}, {'type': 'spaces_page', 'url': 'https://huggingface.co/spaces'}, {'type': 'docs_page', 'url': 'https://huggingface.co/docs'}, {'type': 'community_page', 'url': 'https://discuss.huggingface.co'}, {'type': 'github_page', 'url': 'https://github.com/huggingface'}, {'type': 'twitter_page', 'url': 'https://twitter.com/huggingface'}, {'type': 'linkedin_page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n\n\n'You are looking at a company called HuggingFace.\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title: Hugging Face ‚Äì The AI community building the future.\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nQwen/Qwen3-235B-A22B\\nUpdated\\n3 days ago\\n‚Ä¢\\n28.6k\\n‚Ä¢\\n644\\ndeepseek-ai/DeepSeek-Prover-V2-671B\\nUpdated\\n4 days ago\\n‚Ä¢\\n1.71k\\n‚Ä¢\\n627\\nnari-labs/Dia-1.6B\\nUpdated\\n7 days ago\\n‚Ä¢\\n108k\\n‚Ä¢\\n1.77k\\nQwen/Qwen3-30B-A3B\\nUpdated\\n4 days ago\\n‚Ä¢\\n39.8k\\n‚Ä¢\\n428\\nQwen/Qwen3-32B\\nUpdated\\n5 days ago\\n‚Ä¢\\n73k\\n‚Ä¢\\n263\\nBrowse 1M+ models\\nSpaces\\nRunning\\n5.86k\\n5.86k\\nDeepSite\\nüê≥\\nGenerate any application with DeepSeek\\nRunning\\n362\\n362\\nQwen3 Demo\\nüìä\\nGenerate responses to user queries using conversation history\\nRunning\\non\\nZero\\n1.09k\\n1.09k\\nDia 1.6B\\nüëØ\\nGenerate realistic dialogue from a script, using Dia!\\nRunning\\non\\nZero\\n285\\n285\\nStep1X Edit\\nüíª\\nEdit an image based on the given instruction.\\nRunning\\non\\nZero\\n245\\n245\\nDescribe Anything\\n‚ö°\\nDescribe image parts using masks\\nBrowse 400k+ applications\\nDatasets\\nnvidia/OpenMathReasoning\\nUpdated\\n10 days ago\\n‚Ä¢\\n19.5k\\n‚Ä¢\\n163\\nnvidia/Nemotron-CrossThink\\nUpdated\\n3 days ago\\n‚Ä¢\\n299\\n‚Ä¢\\n33\\nnvidia/OpenCodeReasoning\\nUpdated\\n19 days ago\\n‚Ä¢\\n15.6k\\n‚Ä¢\\n335\\nOpenGVLab/InternVL-Data\\nUpdated\\nabout 2 hours ago\\n‚Ä¢\\n6.98k\\n‚Ä¢\\n106\\nEureka-Lab/PHYBench\\nUpdated\\n8 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n47\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n‚Ä¢\\n756 models\\n‚Ä¢\\n3.19k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.12k models\\n‚Ä¢\\n5.78k followers\\nAmazon\\ncompany\\n‚Ä¢\\n20 models\\n‚Ä¢\\n3.11k followers\\nGoogle\\ncompany\\n‚Ä¢\\n991 models\\n‚Ä¢\\n12.7k followers\\nIntel\\ncompany\\n‚Ä¢\\n220 models\\n‚Ä¢\\n2.5k followers\\nMicrosoft\\ncompany\\n‚Ä¢\\n375 models\\n‚Ä¢\\n12k followers\\nGrammarly\\nEnterprise\\ncompany\\n‚Ä¢\\n10 models\\n‚Ä¢\\n156 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n266 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n143,809\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n28,840\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,251\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,573\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,651\\nFast tokenizers optimized for research & production\\nTRL\\n13,572\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,540\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n17,944\\nSmol library to build great agents in Python\\nPEFT\\n18,288\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,062\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,078\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,674\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nTasks\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nabout_page\\nWebpage Title: Hugging Face ‚Äì The AI community building the future.\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nQwen/Qwen3-235B-A22B\\nUpdated\\n3 days ago\\n‚Ä¢\\n28.6k\\n‚Ä¢\\n644\\ndeepseek-ai/DeepSeek-Prover-V2-671B\\nUpdated\\n4 days ago\\n‚Ä¢\\n1.71k\\n‚Ä¢\\n627\\nnari-labs/Dia-1.6B\\nUpdated\\n7 days ago\\n‚Ä¢\\n108k\\n‚Ä¢\\n1.77k\\nQwen/Qwen3-30B-A3B\\nUpdated\\n4 days ago\\n‚Ä¢\\n39.8k\\n‚Ä¢\\n428\\nQwen/Qwen3-32B\\nUpdated\\n5 days ago\\n‚Ä¢\\n73k\\n‚Ä¢\\n263\\nBrowse 1M+ models\\nSpaces\\nRunning\\n5.86k\\n5.86k\\nDeepSite\\nüê≥\\nGenerate any application with DeepSeek\\nRunning\\n362\\n362\\nQwen3 Demo\\nüìä\\nGenerate responses to user queries using conversation history\\nRunning\\non\\nZero\\n1.09k\\n1.09k\\nDia 1.6B\\nüëØ\\nGenerate realistic dialogue from a script, using Dia!\\nRunning\\non\\nZero\\n285\\n285\\nStep1X Edit\\nüíª\\nEdit an image based on the given instruction.\\nRunning\\non\\nZero\\n245\\n245\\nDescribe Anything\\n‚ö°\\nDescribe image parts using masks\\nBrowse 400k+ applications\\nDatasets\\nnvidia/OpenMathReasoning\\nUpdated\\n10 days ago\\n‚Ä¢\\n19.5k\\n‚Ä¢\\n163\\nnvidia/Nemotron-CrossThink\\nUpdated\\n3 days ago\\n‚Ä¢\\n299\\n‚Ä¢\\n33\\nnvidia/OpenCodeReasoning\\nUpdated\\n19 days ago\\n‚Ä¢\\n15.6k\\n‚Ä¢\\n335\\nOpenGVLab/InternVL-Data\\nUpdated\\nabout 2 hours ago\\n‚Ä¢\\n6.98k\\n‚Ä¢\\n106\\nEureka-Lab/PHYBench\\nUpdated\\n8 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n47\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n‚Ä¢\\n756 models\\n‚Ä¢\\n3.19k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.12k models\\n‚Ä¢\\n5.78k followers\\nAmazon\\ncompany\\n‚Ä¢\\n20 models\\n‚Ä¢\\n3.11k followers\\nGoogle\\ncompany\\n‚Ä¢\\n991 models\\n‚Ä¢\\n12.7k followers\\nIntel\\ncompany\\n‚Ä¢\\n220 models\\n‚Ä¢\\n2.5k followers\\nMicrosoft\\ncompany\\n‚Ä¢\\n375 models\\n‚Ä¢\\n12k followers\\nGrammarly\\nEnterprise\\ncompany\\n‚Ä¢\\n10 models\\n‚Ä¢\\n156 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n266 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n143,809\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n28,840\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,251\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,573\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,651\\nFast tokenizers optimized for research & production\\nTRL\\n13,572\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,540\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n17,944\\nSmol library to build great agents in Python\\nPEFT\\n18,288\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,062\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,078\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,674\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nTasks\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\ncareers_page\\nWebpage Title: Hugging Face - Current Openings\\nWebpage Content:\\n\\n\\n\\n\\nenterprise_page\\nWebpage Title: Enterprise Hub - Hugging Face\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nEnterprise Hub\\nEnterprise-ready version of the world‚Äôs leading AI platform\\nSubscribe to\\nEnterprise Hub\\nfor $20/user/month with your Hub organization\\nGive your organization the most advanced platform to build AI with enterprise-grade security, access controls,\\n\\t\\t\\tdedicated support and more.\\nSingle Sign-On\\nConnect securely to your identity provider with SSO integration.\\nRegions\\nSelect, manage, and audit the location of your repository data.\\nAudit Logs\\nStay in control with comprehensive logs that report on actions taken.\\nResource Groups\\nAccurately manage access to repositories with granular access control.\\nToken Management\\nCentralized token control and custom approval policies for organization access.\\nAnalytics\\nTrack and analyze repository usage data in a single dashboard.\\nAdvanced Compute Options\\nIncrease scalability and performance with more compute options like ZeroGPU.\\nZeroGPU Quota Boost\\nAll organization members get 5x more ZeroGPU quota to get the most of Spaces.\\nPrivate Datasets Viewer\\nEnable the Dataset Viewer on your private datasets for easier collaboration.\\nAdvanced security\\nConfigure organization-wide security policies and default repository visibility.\\nBilling\\nControl your budget effectively with managed billing and yearly commit options.\\nPriority Support\\nMaximize your platform usage with priority support from the Hugging Face team.\\nExtra Private Storage\\nGet an additional 1 TB of private storage for each member of your organization (then $25/month per extra TB).\\nJoin the most forward-thinking AI organizations\\nEverything you already know and love about Hugging Face in Enterprise mode.\\nSubscribe to\\nEnterprise Hub\\nor\\nTalk to sales\\nNVIDIA\\nEnterprise\\ncompany\\n‚Ä¢\\n353 models\\n‚Ä¢\\n24.2k followers\\nShopify\\nEnterprise\\ncompany\\n‚Ä¢\\n445 followers\\nSnowflake\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n501 followers\\nTogether\\nEnterprise\\ncompany\\n‚Ä¢\\n29 models\\n‚Ä¢\\n586 followers\\nQwen\\nEnterprise\\ncompany\\n‚Ä¢\\n262 models\\n‚Ä¢\\n29.1k followers\\nXsolla\\nEnterprise\\ncompany\\n‚Ä¢\\n133 followers\\nToyota Research Institute\\nEnterprise\\ncompany\\n‚Ä¢\\n10 models\\n‚Ä¢\\n110 followers\\nJusbrasil\\nEnterprise\\ncompany\\n‚Ä¢\\n92 followers\\nTNG Technology Consulting GmbH\\nEnterprise\\ncompany\\n‚Ä¢\\n3 models\\n‚Ä¢\\n137 followers\\nAledade Inc\\nEnterprise\\ncompany\\n‚Ä¢\\n70 followers\\nChegg Inc\\nEnterprise\\ncompany\\n‚Ä¢\\n84 followers\\nJohnson & Johnson\\nEnterprise\\ncompany\\n‚Ä¢\\n59 followers\\nWidn AI\\nEnterprise\\ncompany\\n‚Ä¢\\n48 followers\\nBCG X\\nEnterprise\\ncompany\\n‚Ä¢\\n39 followers\\nInfosys Limited\\nEnterprise\\ncompany\\n‚Ä¢\\n2 models\\n‚Ä¢\\n819 followers\\nNerdy Face\\nEnterprise\\ncompany\\n‚Ä¢\\n1 model\\n‚Ä¢\\n297 followers\\nAMD\\nEnterprise\\ncompany\\n‚Ä¢\\n130 models\\n‚Ä¢\\n1.51k followers\\nArm\\nEnterprise\\ncompany\\n‚Ä¢\\n191 followers\\nLiveRAG by AIIR\\nEnterprise\\ncompany\\n‚Ä¢\\n127 followers\\nServiceNow-AI\\nEnterprise\\ncompany\\n‚Ä¢\\n2 models\\n‚Ä¢\\n228 followers\\nFidelity Investments\\nEnterprise\\ncompany\\n‚Ä¢\\n139 followers\\nNutanix\\nEnterprise\\ncompany\\n‚Ä¢\\n261 models\\n‚Ä¢\\n88 followers\\nIBM Granite\\nEnterprise\\ncompany\\n‚Ä¢\\n117 models\\n‚Ä¢\\n1.64k followers\\ncreditkarma\\nEnterprise\\ncompany\\n‚Ä¢\\n63 followers\\nHiddenLayer\\nEnterprise\\ncompany\\n‚Ä¢\\n1 model\\n‚Ä¢\\n69 followers\\nGrammarly\\nEnterprise\\ncompany\\n‚Ä¢\\n10 models\\n‚Ä¢\\n156 followers\\nMiniMax\\nEnterprise\\ncompany\\n‚Ä¢\\n2 models\\n‚Ä¢\\n628 followers\\nStability AI\\nEnterprise\\ncompany\\n‚Ä¢\\n105 models\\n‚Ä¢\\n22.3k followers\\nMeta Llama\\nEnterprise\\ncompany\\n‚Ä¢\\n70 models\\n‚Ä¢\\n41.4k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.12k models\\n‚Ä¢\\n5.78k followers\\nOrange\\nEnterprise\\ncompany\\n‚Ä¢\\n7 models\\n‚Ä¢\\n218 followers\\nServiceNow\\nEnterprise\\ncompany\\n‚Ä¢\\n502 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n266 followers\\nDeutsche Telekom AG\\nEnterprise\\ncompany\\n‚Ä¢\\n7 models\\n‚Ä¢\\n143 followers\\nMercedes-Benz AG\\nEnterprise\\ncompany\\n‚Ä¢\\n153 followers\\nMistral AI_\\nEnterprise\\ncompany\\n‚Ä¢\\n26 models\\n‚Ä¢\\n8.04k followers\\nH2O.ai\\nEnterprise\\ncompany\\n‚Ä¢\\n71 models\\n‚Ä¢\\n421 followers\\nTechnology Innovation Institute\\nEnterprise\\ncompany\\n‚Ä¢\\n65 models\\n‚Ä¢\\n1.32k followers\\nHyperCLOVA X\\nEnterprise\\ncompany\\n‚Ä¢\\n3 models\\n‚Ä¢\\n257 followers\\nNovo Nordisk\\nEnterprise\\ncompany\\n‚Ä¢\\n78 followers\\nLiquid AI\\nEnterprise\\ncompany\\n‚Ä¢\\n130 followers\\nKakao Corp.\\nEnterprise\\ncompany\\n‚Ä¢\\n3 models\\n‚Ä¢\\n129 followers\\nCompliance & Certifications\\nGDPR Compliant\\nSOC 2 Type 2\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nTasks\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nblog_page\\nWebpage Title: Hugging Face ‚Äì Blog\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nBlog, Articles, and discussions\\nNew Article\\nEverything\\ncommunity\\nguide\\nopen source collab\\npartnerships\\nresearch\\nNLP\\nAudio\\nCV\\nRL\\nethics\\nDiffusion\\nGame Development\\nRLHF\\nLeaderboard\\nCase Studies\\nLeRobot\\nHow to Build an MCP Server with Gradio\\nBy\\nabidlabs\\nApril 30, 2025\\n‚Ä¢\\n66\\nCommunity Articles\\nview all\\nI trained a Language Model to schedule events with GRPO!\\nBy\\nanakin87\\n‚Ä¢\\n5 days ago\\n‚Ä¢\\n30\\nBamba-9B-v2 - Fast and powerful!\\nBy\\nibm-ai-platform\\nand 12 others\\n‚Ä¢\\n5 days ago\\n‚Ä¢\\n26\\nIntroducing HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Detecting Hallucinations in Real-World Scenarios\\nBy\\nquotientai\\nand 3 others\\n‚Ä¢\\n2 days ago\\n‚Ä¢\\n18\\nü¶∏üèª#14: What Is MCP, and Why Is Everyone ‚Äì Suddenly!‚Äì Talking About It?\\nBy\\nKseniase\\n‚Ä¢\\nMar 17\\n‚Ä¢\\n226\\nUncensor any LLM with abliteration\\nBy\\nmlabonne\\n‚Ä¢\\nJun 13, 2024\\n‚Ä¢\\n542\\nCreating your custom Ghibli Text-to-Image model\\nBy\\natlasia\\nand 3 others\\n‚Ä¢\\n3 days ago\\n‚Ä¢\\n12\\nDeepWiki: Best AI Documentation Generator for Any Github Repo\\nBy\\nlynn-mikami\\n‚Ä¢\\n6 days ago\\n‚Ä¢\\n11\\nIntroduction to State Space Models (SSM)\\nBy\\nlbourdois\\n‚Ä¢\\nJul 19, 2024\\n‚Ä¢\\n126\\nMixture of Tunable Experts - Behavior Modification of DeepSeek-R1 at Inference Time\\nBy\\nrbrt\\nand 4 others\\n‚Ä¢\\nFeb 18\\n‚Ä¢\\n31\\nPipelineRL\\nBy\\nServiceNow\\nand 3 others\\n‚Ä¢\\n9 days ago\\n‚Ä¢\\n17\\nCode a simple RAG from scratch\\nBy\\nngxson\\n‚Ä¢\\nOct 29, 2024\\n‚Ä¢\\n63\\nOpenManus: The Open Source Alternative to Manus AI\\nBy\\nlynn-mikami\\n‚Ä¢\\nMar 30\\n‚Ä¢\\n13\\nHow to Use FastAPI MCP Server: A Complete Guide\\nBy\\nlynn-mikami\\n‚Ä¢\\n23 days ago\\n‚Ä¢\\n26\\nBuilding Multimodal RAG Systems: Supercharging Retrieval with MultiModal Embeddings and LLMs\\nBy\\nOmartificial-Intelligence-Space\\n‚Ä¢\\n3 days ago\\n‚Ä¢\\n5\\nWhat is test-time compute and how to scale it?\\nBy\\nKseniase\\nand 1 other\\n‚Ä¢\\nFeb 6\\n‚Ä¢\\n82\\nNavigating the RLHF Landscape: From Policy Gradients to PPO, GAE, and DPO for LLM Alignment\\nBy\\nNormalUhr\\n‚Ä¢\\nFeb 11\\n‚Ä¢\\n26\\nChatGPT-4o\\'s Image Generation Capabilities and Its Wild Examples\\nBy\\nprithivMLmods\\n‚Ä¢\\n29 days ago\\n‚Ä¢\\n19\\nWhat is The Agent2Agent Protocol (A2A) and Why You Must Learn It Now\\nBy\\nlynn-mikami\\n‚Ä¢\\n22 days ago\\n‚Ä¢\\n14\\nWhat is MoE 2.0? Update Your Knowledge about Mixture-of-experts\\nBy\\nKseniase\\nand 1 other\\n‚Ä¢\\n7 days ago\\n‚Ä¢\\n4\\nA Guide to Running Qwen 3 Locally with Ollama and vLLM\\nBy\\nlynn-mikami\\n‚Ä¢\\n5 days ago\\n‚Ä¢\\n4\\nWelcoming Llama Guard 4 on Hugging Face Hub\\nBy\\nmerve\\nApril 29, 2025\\n‚Ä¢\\n26\\nThe 4 Things Qwen-3\\'s Chat Template Teaches Us\\nBy\\ncfahlgren1\\nApril 30, 2025\\n‚Ä¢\\n18\\nTiny Agents: a MCP-powered agent in 50 lines of code\\nBy\\njulien-c\\nApril 25, 2025\\n‚Ä¢\\n207\\nIntroducing AutoRound: Intel‚Äôs Advanced Quantization for LLMs and VLMs\\nBy\\nwenhuach\\nApril 29, 2025\\n‚Ä¢\\n15\\n17 Reasons Why Gradio Isn\\'t Just Another UI Library\\nBy\\nysharma\\nApril 16, 2025\\n‚Ä¢\\n28\\nCohere on Hugging Face Inference Providers üî•\\nBy\\nburtenshaw\\nApril 16, 2025\\n‚Ä¢\\n124\\nIntroducing HELMET\\nBy\\nhyen\\nApril 16, 2025\\n‚Ä¢\\n23\\nHugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ\\nBy\\nthomwolf\\nApril 14, 2025\\n‚Ä¢\\n42\\n4M Models Scanned: Protect AI + Hugging Face 6 Months In\\nBy\\nsean-pai\\nApril 14, 2025\\n‚Ä¢\\n27\\nHugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC\\nBy\\nfreddyaboulton\\nApril 9, 2025\\n‚Ä¢\\n23\\nArabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More\\nBy\\nalielfilali01\\nApril 8, 2025\\nguest\\n‚Ä¢\\n16\\nWelcome Llama 4 Maverick & Scout on Hugging Face!\\nBy\\nburtenshaw\\nApril 5, 2025\\n‚Ä¢\\n142\\nJourney to 1 Million Gradio Users!\\nBy\\nabidlabs\\nApril 4, 2025\\n‚Ä¢\\n25\\nThe NLP Course is becoming the LLM Course!\\nBy\\nburtenshaw\\nApril 3, 2025\\n‚Ä¢\\n87\\nPrevious\\n1\\n2\\n3\\n...\\n41\\nNext\\nCommunity Articles\\nSort:\\xa0\\n\\t\\tTrending\\nI trained a Language Model to schedule events with GRPO!\\nBy\\nanakin87\\n‚Ä¢\\n5 days ago\\n‚Ä¢\\n30\\nBamba-9B-v2 - Fast and powerful!\\nBy\\nibm-ai-platform\\nand 12 others\\n‚Ä¢\\n5 days ago\\n‚Ä¢\\n26\\nIntroducing HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Detecting Hallucinations in Real-World Scenarios\\nBy\\nquotientai\\nand 3 others\\n‚Ä¢\\n2 days ago\\n‚Ä¢\\n18\\nü¶∏üèª#14: What Is MCP, and Why Is Everyone ‚Äì Suddenly!‚Äì Talking About It?\\nBy\\nKseniase\\n‚Ä¢\\nMar 17\\n‚Ä¢\\n226\\nUncensor any LLM with abliteration\\nBy\\nmlabonne\\n‚Ä¢\\nJun 13, 2024\\n‚Ä¢\\n542\\nCreating your custom Ghibli Text-to-Image model\\nBy\\natlasia\\nand 3 others\\n‚Ä¢\\n3 days ago\\n‚Ä¢\\n12\\nDeepWiki: Best AI Documentation Generator for Any Github Repo\\nBy\\nlynn-mikami\\n‚Ä¢\\n6 days ago\\n‚Ä¢\\n11\\nIntroduction to State Space Models (SSM)\\nBy\\nlbourdois\\n‚Ä¢\\nJul 19, 2024\\n‚Ä¢\\n126\\nMixture of Tunable Experts - Behavior Modification of DeepSeek-R1 at Inference Time\\nBy\\nrbrt\\nand 4 others\\n‚Ä¢\\nFeb 18\\n‚Ä¢\\n31\\nPipelineRL\\nBy\\nServiceNow\\nand 3 others\\n‚Ä¢\\n9 days ago\\n‚Ä¢\\n17\\nCode a simple RAG from scratch\\nBy\\nngxson\\n‚Ä¢\\nOct 29, 2024\\n‚Ä¢\\n63\\nOpenManus: The Open Source Alternative to Manus AI\\nBy\\nlynn-mikami\\n‚Ä¢\\nMar 30\\n‚Ä¢\\n13\\nHow to Use FastAPI MCP Server: A Complete Guide\\nBy\\nlynn-mikami\\n‚Ä¢\\n23 days ago\\n‚Ä¢\\n26\\nBuilding Multimodal RAG Systems: Supercharging Retrieval with MultiModal Embeddings and LLMs\\nBy\\nOmartificial-Intelligence-Space\\n‚Ä¢\\n3 days ago\\n‚Ä¢\\n5\\nWhat is test-time compute and how to scale it?\\nBy\\nKseniase\\nand 1 other\\n‚Ä¢\\nFeb 6\\n‚Ä¢\\n82\\nNavigating the RLHF Landscape: From Policy Gradients to PPO, GAE, and DPO for LLM Alignment\\nBy\\nNormalUhr\\n‚Ä¢\\nFeb 11\\n‚Ä¢\\n26\\nChatGPT-4o\\'s Image Generation Capabilities and Its Wild Examples\\nBy\\nprithivMLmods\\n‚Ä¢\\n29 days ago\\n‚Ä¢\\n19\\nWhat is The Agent2Agent Protocol (A2A) and Why You Must Learn It Now\\nBy\\nlynn-mikami\\n‚Ä¢\\n22 days ago\\n‚Ä¢\\n14\\nWhat is MoE 2.0? Update Your Knowledge about Mixture-of-experts\\nBy\\nKseniase\\nand 1 other\\n‚Ä¢\\n7 days ago\\n‚Ä¢\\n4\\nA Guide to Running Qwen 3 Locally with Ollama and vLLM\\nBy\\nlynn-mikami\\n‚Ä¢\\n5 days ago\\n‚Ä¢\\n4\\nView all\\nSystem theme\\nCompany\\nTOS\\nPrivacy\\nAbout\\nJobs\\nWebsite\\nModels\\nDatasets\\nSpaces\\nPricing\\nDocs\\n\\n\\n\\nmodels_page\\nWebpage Title: Models - Hugging Face\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nEdit Models filters\\nTasks\\nLibraries\\nDatasets\\nLanguages\\nLicenses\\nOther\\nMultimodal\\nAudio-Text-to-Text\\nImage-Text-to-Text\\nVisual Question Answering\\nDocument Question Answering\\nVideo-Text-to-Text\\nVisual Document Retrieval\\nAny-to-Any\\nComputer Vision\\nDepth Estimation\\nImage Classification\\nObject Detection\\nImage Segmentation\\nText-to-Image\\nImage-to-Text\\nImage-to-Image\\nImage-to-Video\\nUnconditional Image Generation\\nVideo Classification\\nText-to-Video\\nZero-Shot Image Classification\\nMask Generation\\nZero-Shot Object Detection\\nText-to-3D\\nImage-to-3D\\nImage Feature Extraction\\nKeypoint Detection\\nNatural Language Processing\\nText Classification\\nToken Classification\\nTable Question Answering\\nQuestion Answering\\nZero-Shot Classification\\nTranslation\\nSummarization\\nFeature Extraction\\nText Generation\\nText2Text Generation\\nFill-Mask\\nSentence Similarity\\nText Ranking\\nAudio\\nText-to-Speech\\nText-to-Audio\\nAutomatic Speech Recognition\\nAudio-to-Audio\\nAudio Classification\\nVoice Activity Detection\\nTabular\\nTabular Classification\\nTabular Regression\\nTime Series Forecasting\\nReinforcement Learning\\nReinforcement Learning\\nRobotics\\nOther\\nGraph Machine Learning\\nApply filters\\nModels\\nFull-text search\\nAdd filters\\nSort:\\xa0\\n\\t\\tTrending\\nQwen/Qwen3-235B-A22B\\nText Generation\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n28.6k\\n‚Ä¢\\n‚Ä¢\\n644\\ndeepseek-ai/DeepSeek-Prover-V2-671B\\nText Generation\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n1.71k\\n‚Ä¢\\n‚Ä¢\\n627\\nnari-labs/Dia-1.6B\\nText-to-Speech\\n‚Ä¢\\nUpdated\\n7 days ago\\n‚Ä¢\\n108k\\n‚Ä¢\\n‚Ä¢\\n1.77k\\nQwen/Qwen3-30B-A3B\\nText Generation\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n39.8k\\n‚Ä¢\\n‚Ä¢\\n428\\nQwen/Qwen3-32B\\nText Generation\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n73k\\n‚Ä¢\\n‚Ä¢\\n263\\nQwen/Qwen3-8B\\nText Generation\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n74.7k\\n‚Ä¢\\n205\\ntngtech/DeepSeek-R1T-Chimera\\nText Generation\\n‚Ä¢\\nUpdated\\n1 day ago\\n‚Ä¢\\n2.17k\\n‚Ä¢\\n212\\nXiaomiMiMo/MiMo-7B-RL\\nUpdated\\n4 days ago\\n‚Ä¢\\n1.92k\\n‚Ä¢\\n198\\nJetBrains/Mellum-4b-base\\nText Generation\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n431\\n‚Ä¢\\n191\\nQwen/Qwen3-0.6B\\nText Generation\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n63.7k\\n‚Ä¢\\n177\\nmoonshotai/Kimi-Audio-7B-Instruct\\nText-to-Speech\\n‚Ä¢\\nUpdated\\n6 days ago\\n‚Ä¢\\n3.09k\\n‚Ä¢\\n276\\nmicrosoft/Phi-4-reasoning-plus\\nText Generation\\n‚Ä¢\\nUpdated\\n1 day ago\\n‚Ä¢\\n1.67k\\n‚Ä¢\\n159\\nstepfun-ai/Step1X-Edit\\nImage-to-Image\\n‚Ä¢\\nUpdated\\n7 days ago\\n‚Ä¢\\n‚Ä¢\\n236\\nQwen/Qwen2.5-Omni-3B\\nAny-to-Any\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n2.2k\\n‚Ä¢\\n151\\nQwen/Qwen3-4B\\nText Generation\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n78.7k\\n‚Ä¢\\n146\\nmicrosoft/Phi-4-reasoning\\nText Generation\\n‚Ä¢\\nUpdated\\n1 day ago\\n‚Ä¢\\n1.37k\\n‚Ä¢\\n123\\nunsloth/Qwen3-30B-A3B-GGUF\\nText Generation\\n‚Ä¢\\nUpdated\\n2 days ago\\n‚Ä¢\\n137k\\n‚Ä¢\\n119\\nQwen/Qwen3-14B\\nText Generation\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n63.5k\\n‚Ä¢\\n117\\nmicrosoft/bitnet-b1.58-2B-4T\\nText Generation\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n43.3k\\n‚Ä¢\\n926\\nsand-ai/MAGI-1\\nImage-to-Video\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n531\\nHiDream-ai/HiDream-E1-Full\\nAny-to-Any\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n1.31k\\n‚Ä¢\\n109\\nnvidia/parakeet-tdt-0.6b-v2\\nAutomatic Speech Recognition\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n1.19k\\n‚Ä¢\\n100\\nmicrosoft/Phi-4-mini-reasoning\\nText Generation\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n1.91k\\n‚Ä¢\\n97\\nostris/Flex.2-preview\\nText-to-Image\\n‚Ä¢\\nUpdated\\n9 days ago\\n‚Ä¢\\n8.92k\\n‚Ä¢\\n314\\nFreepik/F-Lite\\nText-to-Image\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n570\\n‚Ä¢\\n91\\nQwen/Qwen3-1.7B\\nText Generation\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n53.8k\\n‚Ä¢\\n87\\nblack-forest-labs/FLUX.1-dev\\nText-to-Image\\n‚Ä¢\\nUpdated\\nAug 16, 2024\\n‚Ä¢\\n2.67M\\n‚Ä¢\\n‚Ä¢\\n10k\\nXiaomiMiMo/MiMo-7B-Base\\nUpdated\\n4 days ago\\n‚Ä¢\\n278\\n‚Ä¢\\n81\\nfdtn-ai/Foundation-Sec-8B\\nText Generation\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n17.6k\\n‚Ä¢\\n79\\nTHUDM/GLM-4-32B-0414\\nText Generation\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n14.6k\\n‚Ä¢\\n‚Ä¢\\n366\\nSystem theme\\nCompany\\nTOS\\nPrivacy\\nAbout\\nJobs\\nWebsite\\nModels\\nDatasets\\nSpaces\\nPricing\\nDocs\\n\\n\\n\\ndatasets_page\\nWebpage Title: Hugging Face ‚Äì The AI community building the future.\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nEdit Datasets filters\\nMain\\nTasks\\nLibraries\\nLanguages\\nLicenses\\nOther\\nModalities\\n3D\\nAudio\\nGeospatial\\nImage\\nTabular\\nText\\nTime-series\\nVideo\\nSize\\n\\t\\t\\t(rows)\\nReset Size\\n&lt; 1K\\n&gt; 1T\\nFormat\\njson\\ncsv\\nparquet\\nimagefolder\\nsoundfolder\\nwebdataset\\ntext\\narrow\\nApply filters\\nDatasets\\n376,525\\nFull-text search\\nAdd filters\\nSort:\\xa0\\n\\t\\tTrending\\nnvidia/OpenMathReasoning\\nViewer\\n‚Ä¢\\nUpdated\\n10 days ago\\n‚Ä¢\\n5.47M\\n‚Ä¢\\n19.5k\\n‚Ä¢\\n163\\nnvidia/Nemotron-CrossThink\\nPreview\\n‚Ä¢\\nUpdated\\n3 days ago\\n‚Ä¢\\n299\\n‚Ä¢\\n33\\nnvidia/OpenCodeReasoning\\nViewer\\n‚Ä¢\\nUpdated\\n19 days ago\\n‚Ä¢\\n753k\\n‚Ä¢\\n15.6k\\n‚Ä¢\\n335\\nOpenGVLab/InternVL-Data\\nPreview\\n‚Ä¢\\nUpdated\\nabout 2 hours ago\\n‚Ä¢\\n6.98k\\n‚Ä¢\\n106\\nEureka-Lab/PHYBench\\nViewer\\n‚Ä¢\\nUpdated\\n8 days ago\\n‚Ä¢\\n1k\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n47\\nrajpurkarlab/ReXGradient-160K\\nViewer\\n‚Ä¢\\nUpdated\\n2 days ago\\n‚Ä¢\\n160k\\n‚Ä¢\\n8\\n‚Ä¢\\n24\\ndeepseek-ai/DeepSeek-ProverBench\\nViewer\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n325\\n‚Ä¢\\n387\\n‚Ä¢\\n20\\nAnthropic/values-in-the-wild\\nViewer\\n‚Ä¢\\nUpdated\\n6 days ago\\n‚Ä¢\\n6.91k\\n‚Ä¢\\n839\\n‚Ä¢\\n124\\nfka/awesome-chatgpt-prompts\\nViewer\\n‚Ä¢\\nUpdated\\nJan 6\\n‚Ä¢\\n203\\n‚Ä¢\\n13.9k\\n‚Ä¢\\n7.75k\\nRapidata/text-2-image-Rich-Human-Feedback-32k\\nViewer\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n31.9k\\n‚Ä¢\\n616\\n‚Ä¢\\n14\\nopenai/gsm8k\\nViewer\\n‚Ä¢\\nUpdated\\nJan 4, 2024\\n‚Ä¢\\n17.6k\\n‚Ä¢\\n497k\\n‚Ä¢\\n715\\nnvidia/dynpose-100k\\nUpdated\\n9 days ago\\n‚Ä¢\\n1.44k\\n‚Ä¢\\n23\\nnvidia/When2Call\\nViewer\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n28k\\n‚Ä¢\\n114\\n‚Ä¢\\n13\\nnvidia/describe-anything-dataset\\nViewer\\n‚Ä¢\\nUpdated\\n10 days ago\\n‚Ä¢\\n916k\\n‚Ä¢\\n6.36k\\n‚Ä¢\\n31\\nnyuuzyou/svgfind\\nViewer\\n‚Ä¢\\nUpdated\\n6 days ago\\n‚Ä¢\\n3.66M\\n‚Ä¢\\n172\\n‚Ä¢\\n12\\nzwhe99/DeepMath-103K\\nViewer\\n‚Ä¢\\nUpdated\\nabout 6 hours ago\\n‚Ä¢\\n103k\\n‚Ä¢\\n18.8k\\n‚Ä¢\\n164\\ngaia-benchmark/GAIA\\nUpdated\\nFeb 13\\n‚Ä¢\\n11.7k\\n‚Ä¢\\n314\\nHuggingFaceFW/fineweb\\nViewer\\n‚Ä¢\\nUpdated\\nJan 31\\n‚Ä¢\\n25B\\n‚Ä¢\\n842k\\n‚Ä¢\\n2.13k\\nFreedomIntelligence/medical-o1-reasoning-SFT\\nViewer\\n‚Ä¢\\nUpdated\\n12 days ago\\n‚Ä¢\\n90.1k\\n‚Ä¢\\n12.4k\\n‚Ä¢\\n671\\nKaichengalex/RealSyn100M\\nViewer\\n‚Ä¢\\nUpdated\\nFeb 19\\n‚Ä¢\\n89.6M\\n‚Ä¢\\n15.6k\\n‚Ä¢\\n12\\nsyCen/CameraBench\\nViewer\\n‚Ä¢\\nUpdated\\n5 days ago\\n‚Ä¢\\n1.07k\\n‚Ä¢\\n2.35k\\n‚Ä¢\\n12\\nAmod/mental_health_counseling_conversations\\nViewer\\n‚Ä¢\\nUpdated\\nApr 5, 2024\\n‚Ä¢\\n3.51k\\n‚Ä¢\\n3.9k\\n‚Ä¢\\n364\\nfuture-technologies/Universal-Transformers-Dataset\\nPreview\\n‚Ä¢\\nUpdated\\n4 days ago\\n‚Ä¢\\n7.29k\\n‚Ä¢\\n96\\nopen-r1/OpenR1-Math-220k\\nViewer\\n‚Ä¢\\nUpdated\\nFeb 18\\n‚Ä¢\\n450k\\n‚Ä¢\\n30.1k\\n‚Ä¢\\n568\\nnvidia/Llama-Nemotron-Post-Training-Dataset\\nViewer\\n‚Ä¢\\nUpdated\\n7 days ago\\n‚Ä¢\\n3.91M\\n‚Ä¢\\n9.01k\\n‚Ä¢\\n436\\nLLM360/MegaMath\\nViewer\\n‚Ä¢\\nUpdated\\n25 days ago\\n‚Ä¢\\n217M\\n‚Ä¢\\n68.9k\\n‚Ä¢\\n83\\nGiova-tech/sentiment-analysis-test\\nViewer\\n‚Ä¢\\nUpdated\\n18 days ago\\n‚Ä¢\\n349\\n‚Ä¢\\n509\\n‚Ä¢\\n9\\nqwertychri/sentiment-analysis-test\\nViewer\\n‚Ä¢\\nUpdated\\n18 days ago\\n‚Ä¢\\n349\\n‚Ä¢\\n489\\n‚Ä¢\\n8\\nwikimedia/wikipedia\\nViewer\\n‚Ä¢\\nUpdated\\nJan 9, 2024\\n‚Ä¢\\n61.6M\\n‚Ä¢\\n107k\\n‚Ä¢\\n795\\nCongliu/Chinese-DeepSeek-R1-Distill-data-110k\\nViewer\\n‚Ä¢\\nUpdated\\nFeb 21\\n‚Ä¢\\n110k\\n‚Ä¢\\n2.46k\\n‚Ä¢\\n652\\nPrevious\\n1\\n2\\n3\\n...\\n100\\nNext\\nSystem theme\\nCompany\\nTOS\\nPrivacy\\nAbout\\nJobs\\nWebsite\\nModels\\nDatasets\\nSpaces\\nPricing\\nDocs\\n\\n\\n\\nspaces_page\\nWebpage Title: Spaces - Hugging Face\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nSpaces\\n¬∑\\nThe AI App Directory\\nNew Space\\nWhat is Spaces?\\nImage Generation\\nVideo Generation\\nText Generation\\nLanguage Translation\\nSpeech Synthesis\\n3D Modeling\\nObject Detection\\nText Analysis\\nImage Editing\\nCode Generation\\nQuestion Answering\\nData Visualization\\nVoice Cloning\\nBackground Removal\\nImage Upscaling\\nOCR\\nDocument Analysis\\nVisual QA\\nImage Captioning\\nChatbots\\nSentiment Analysis\\nText Summarization\\nMusic Generation\\nMedical Imaging\\nFinancial Analysis\\nGame AI\\nModel Benchmarking\\nFine Tuning Tools\\nDataset Creation\\nPose Estimation\\nFace Recognition\\nAnomaly Detection\\nRecommendation Systems\\nCharacter Animation\\nStyle Transfer\\nImage\\nSpaces of the week\\n28 Apr 2025\\nSort:\\xa0\\n\\t\\tRelevance\\nRunning\\non\\nZero\\n285\\nStep1X Edit\\nüíª\\nEdit an image based on the given instruction.\\nstepfun-ai\\n6 days ago\\nRunning\\non\\nZero\\n245\\nDescribe Anything\\n‚ö°\\nDescribe image parts using masks\\nnvidia\\n3 days ago\\nRunning\\non\\nZero\\n397\\nInstantCharacter\\nüê¢\\nCustomize characters with prompts and styles\\nInstantX\\n14 days ago\\nRunning\\n56\\nOS1 (Ultravox Llama 3.2 1b + Kokoro TTS + Whisper)\\nüíª\\nIn-browser local conversational AI inspired by \\'Her\\'\\nwebml-community\\n11 days ago\\nRunning\\non\\nZero\\n75\\nVevo for Zero-shot VC, TTS, and More\\nüê†\\nControllable Zero-Shot Voice Imitation\\namphion\\n11 days ago\\nRunning\\n19\\nERNIE X1 Turbo Demo\\nüòª\\nBAIDU\\'s Reasoning LLM, https://yiyan.baidu.com/\\nPaddlePaddle\\n9 days ago\\nRunning\\n32\\nHandwritten Digit Classifier\\nüìà\\nAn interactive digit classification demo\\nJechen00\\n4 days ago\\nRunning\\non\\nZero\\n61\\nIP Composer\\nüé®\\nplug-and-play with visual concepts\\nIP-composer\\n17 days ago\\nAll running apps, trending first\\nRunning\\n5.86k\\nDeepSite\\nüê≥\\nGenerate any application with DeepSeek\\nenzostvs\\n16 days ago\\nRunning\\n362\\nQwen3 Demo\\nüìä\\nGenerate responses to user queries using conversation history\\nQwen\\n6 days ago\\nRunning\\non\\nZero\\n1.09k\\nDia 1.6B\\nüëØ\\nGenerate realistic dialogue from a script, using Dia!\\nnari-labs\\n8 days ago\\nRunning\\non\\nZero\\n285\\nStep1X Edit\\nüíª\\nEdit an image based on the given instruction.\\nstepfun-ai\\n6 days ago\\nRunning\\non\\nZero\\n245\\nDescribe Anything\\n‚ö°\\nDescribe image parts using masks\\nnvidia\\n3 days ago\\nRunning\\non\\nZero\\n397\\nInstantCharacter\\nüê¢\\nCustomize characters with prompts and styles\\nInstantX\\n14 days ago\\nRunning\\non\\nZero\\n2.5k\\nHunyuan3D-2.0\\nüåç\\nText-to-3D and Image-to-3D Generation\\ntencent\\n9 days ago\\nRunning\\non\\nZero\\n212\\nWaiNSFWIllustrious V110\\nüñº\\nGenerate images from textual prompts\\nretwpay\\nMar 19\\nRunning\\non\\nZero\\n97\\nICEdit\\nüñº\\nUniversal Image Editing is worth a single LoRA\\nRiverZ\\nabout 3 hours ago\\nRunning\\non\\nZero\\n206\\nFramePackÂõæÂÉèÂà∞ËßÜÈ¢ëÁîüÊàê(5ÁßíÈôêÂà∂Áâà)\\nüé¨\\nGenerate video from an image\\nlisonallen\\n15 days ago\\nRunning\\non\\nZero\\n677\\nUNO FLUX\\n‚ö°\\nGenerate customized images using text and multiple images\\nbytedance-research\\n22 days ago\\nRunning\\non\\nCPU Upgrade\\n8.61k\\nKolors Virtual Try-On\\nüëï\\nTry on virtual garments on person images\\nKwai-Kolors\\nSep 18, 2024\\nRunning\\non\\nZero\\n72\\nFantasyTalking\\nüòª\\nGenerate realistic talking portrait videos from images and audio\\nacvlab\\n5 days ago\\nRunning\\non\\nCPU Upgrade\\n10k\\nAI Comic Factory\\nüë©\\nCreate your own AI comic with a single prompt\\njbilcke-hf\\nOct 15, 2024\\nRunning\\non\\nZero\\n8.21k\\nFLUX.1 [dev]\\nüñ•\\nGenerate images from text prompts\\nblack-forest-labs\\n18 days ago\\nRunning\\non\\nZero\\n3.46k\\nIC Light V2\\nüìà\\nExecute custom code from environment variables\\nlllyasviel\\nOct 26, 2024\\nRunning\\non\\nCPU Upgrade\\n5.55k\\nMTEB Leaderboard\\nü•á\\nEmbedding Leaderboard\\nmteb\\n17 days ago\\nRunning\\non\\nCPU Upgrade\\n55\\nHiDream E1 Full\\nüöÄ\\nGenerate an edited image based on text instructions\\nHiDream-ai\\n4 days ago\\nRunning\\n126\\nMotionShop2\\nüèÉ\\nReplace characters in a video with characters in photos\\n3DAIGC\\n19 days ago\\nRunning\\n56\\nOS1 (Ultravox Llama 3.2 1b + Kokoro TTS + Whisper)\\nüíª\\nIn-browser local conversational AI inspired by \\'Her\\'\\nwebml-community\\n11 days ago\\nRunning\\non\\nZero\\n1.72k\\nBackground Removal\\nüåò\\nRemove backgrounds from images\\nnot-lain\\nJan 2\\nRunning\\n395\\nDeepSite Gallery\\nüêã\\nBrowse apps made with DeepSite\\nvictor\\n26 days ago\\nRunning\\non\\nZero\\n2.27k\\nF5-TTS\\nüó£\\nF5-TTS & E2-TTS: Zero-Shot Voice Cloning (Unofficial Demo)\\nmrfakename\\nabout 9 hours ago\\nRunning\\non\\nZero\\n46\\nF Lite\\nüê†\\nF Lite image generator\\nFreepik\\n11 days ago\\nSystem theme\\nCompany\\nTOS\\nPrivacy\\nAbout\\nJobs\\nWebsite\\nModels\\nDatasets\\nSpaces\\nPricing\\nDocs\\n\\n\\n\\ndocs_page\\nWebpage Title: Hugging Face - Documentation\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nDocumentations\\nHub & Client Libraries\\nHub\\nHost Git-based models, datasets, and Spaces on the HF Hub\\nHub Python Library\\nPython client to interact with the Hugging Face Hub\\nHuggingface.js\\nJavaScript libraries for Hugging Face with built-in TS types\\nTasks\\nExplore demos, models, and datasets for any ML tasks\\nDataset viewer\\nAPI for metadata, stats, and content of HF Hub datasets\\nDeployment & Inference\\nInference Providers\\nCall 200k+ models hosted by our 10+ Inference partners\\nInference Endpoints (dedicated)\\nDeploy models on dedicated & fully managed infrastructure on HF\\nAmazon SageMaker\\nTrain/deploy Transformers models with SageMaker/HF DLCs\\nText Generation Inference\\nServe language models with TGI optimized toolkit\\nText Embeddings Inference\\nServe embeddings models with TEI optimized toolkit\\nCore ML Libraries\\nTransformers\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\nState-of-the-art Diffusion models in PyTorch\\nDatasets\\nAccess & share datasets for any ML tasks\\nTransformers.js\\nState-of-the-art ML running directly in your browser\\nTokenizers\\nFast tokenizers optimized for research & production\\nEvaluate\\nEvaluate and compare models performance\\ntimm\\nState-of-the-art vision models: layers, optimizers, and utilities\\nSentence Transformers\\nEmbeddings, Retrieval, and Reranking\\nTraining & Optimization\\nPEFT\\nParameter-efficient finetuning for large language models\\nAccelerate\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nOptimum\\nOptimize HF Transformers for faster training/inference\\nAWS Trainium & Inferentia\\nTrain/deploy Transformers/Diffusers on AWS\\nTRL\\nTrain transformers LMs with reinforcement learning\\nSafetensors\\nSafe way to store/distribute neural network weights\\nBitsandbytes\\nOptimize and quantize models with bitsandbytes\\nLighteval\\nAll-in-one toolkit to evaluate LLMs across multiple backends\\nCollaboration & Extras\\nGradio\\nBuild ML demos and web apps with a few lines of Python\\nsmolagents\\nSmol library to build great agents in Python\\nAutoTrain\\nAutoTrain API and UI for seamless model training\\nChat UI\\nOpen source chat frontend powering HuggingChat\\nLeaderboards\\nCreate custom Leaderboards on Hugging Face\\nArgilla\\nCollaboration tool for building high-quality datasets\\nDistilabel\\nFramework for synthetic data generation and AI feedback\\nCommunity\\nBlog\\nLearn\\nDiscord\\nForum\\nGithub\\nSystem theme\\nCompany\\nTOS\\nPrivacy\\nAbout\\nJobs\\nWebsite\\nModels\\nDatasets\\nSpaces\\nPricing\\nDocs\\n\\n\\n\\ncommunity_page\\nWebpage Title: Hugging Face Forums - Hugging Face Community Discussion\\nWebpage Content:\\nHugging Face Forums\\nTopic\\nReplies\\nViews\\nActivity\\nQuestion about HuggingFaceChat\\nBeginners\\n1\\n12\\nMay 4, 2025\\nHow AI Sunny Helped Me Unlock the Secrets of The Tree Oil Painting\"\\nResearch\\n0\\n8\\nMay 3, 2025\\nHF Playground Incorrect Billing -\\nBeginners\\n1\\n13\\nMay 3, 2025\\nHuggingface payment system is having problems\\nBeginners\\n3\\n41\\nMay 2, 2025\\nAlternative options for API endpoints\\nCourse\\n0\\n19\\nMay 2, 2025\\nInference API stopped working\\nInference Endpoints on the Hub\\n28\\n973\\nApril 30, 2025\\nHow do i batch in streaming of data set\\nIntermediate\\n1\\n20\\nMay 3, 2025\\nError in HF Space Docker\\nBeginners\\n15\\n371\\nApril 22, 2025\\nSoftprompt for Llama generating gibberish output\\nBeginners\\n2\\n10\\nMay 3, 2025\\n500 Internal Error - We\\'re working hard to fix this as soon as possible\\nü§óTransformers\\n44\\n1581\\nApril 25, 2025\\nPhoto Maker Runtime Error\\nBeginners\\n3\\n35\\nMay 3, 2025\\nChapter 3 questions\\nCourse\\n139\\n9962\\nMay 3, 2025\\n403 Error: ‚ÄúPrivate repository storage limit reached‚Äù ‚Äî quota shows space remaining\\nü§óHub\\n1\\n35\\nMay 1, 2025\\nChecking if two column have the language i want\\nIntermediate\\n1\\n14\\nMay 1, 2025\\nSpace stuck for more than 1 hour\\nBeginners\\n4\\n25\\nMay 1, 2025\\nHuggingface get billing usage\\nBeginners\\n1\\n18\\nMay 2, 2025\\nHow do i load part of the data set\\nBeginners\\n2\\n26\\nMay 2, 2025\\nMy Space suddenly went offline. The CPU cannot restart\\nBeginners\\n24\\n419\\nApril 23, 2025\\nHow to get around rate limits?\\nBeginners\\n17\\n166\\nApril 23, 2025\\nWhen I\\'m downloading the weights, the cell keeps running and doesn\\'t stop. I need to fine tune Mistral-Small-3.1-24B-Instruct-2503 model\\nü§óTransformers\\n4\\n15\\nMay 2, 2025\\nText 2 Video -&gt; Wan2_1-T2V-1_3B_fp32\\nModels\\n0\\n9\\nMay 2, 2025\\nRuntime Identity Drift in LLMs ‚Äî Can We Stabilize Without Memory?\\nResearch\\n4\\n91\\nApril 28, 2025\\nWhy are only 2 of the RT-DETR v2 implemented losses actually used?\\nü§óTransformers\\n2\\n26\\nMay 2, 2025\\nLlama 4 access pending\\nBeginners\\n10\\n63\\nMay 3, 2025\\nEvaluate fine-tuned LLM for question answering\\nBeginners\\n1\\n14\\nMay 2, 2025\\nHow to setup JSON based workflow/flowchart generation based on user prompt?\\nIntermediate\\n0\\n8\\nMay 2, 2025\\nFinal Project evaluation\\nCourse\\n0\\n12\\nMay 2, 2025\\nGemma3TextModel weights\\nModels\\n1\\n16\\nMay 2, 2025\\nsentence-transformers/all-MiniLM-L6-v2 Not working all of a sudden\\nBeginners\\n7\\n48\\nApril 29, 2025\\nWhat if Claude is more than Claude?\\nBeginners\\n3\\n55\\nMay 3, 2025\\nnext page ‚Üí\\nHome\\nCategories\\nGuidelines\\nTerms of Service\\nPrivacy Policy\\nPowered by\\nDiscourse\\n, best viewed with JavaScript enabled\\n\\n\\n\\ngithub_page\\nWebpage Title: Hugging Face ¬∑ GitHub\\nWebpage Content:\\nSkip to content\\nNavigation Menu\\nToggle navigation\\nSign in\\nhuggingface\\nProduct\\nGitHub Copilot\\nWrite better code with AI\\nGitHub Advanced Security\\nFind and fix vulnerabilities\\nActions\\nAutomate any workflow\\nCodespaces\\nInstant dev environments\\nIssues\\nPlan and track work\\nCode Review\\nManage code changes\\nDiscussions\\nCollaborate outside of code\\nCode Search\\nFind more, search less\\nExplore\\nWhy GitHub\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\nSolutions\\nBy company size\\nEnterprises\\nSmall and medium teams\\nStartups\\nNonprofits\\nBy use case\\nDevSecOps\\nDevOps\\nCI/CD\\nView all use cases\\nBy industry\\nHealthcare\\nFinancial services\\nManufacturing\\nGovernment\\nView all industries\\nView all solutions\\nResources\\nTopics\\nAI\\nDevOps\\nSecurity\\nSoftware Development\\nView all\\nExplore\\nLearning Pathways\\nEvents & Webinars\\nEbooks & Whitepapers\\nCustomer Stories\\nPartners\\nExecutive Insights\\nOpen Source\\nGitHub Sponsors\\nFund open source developers\\nThe ReadME Project\\nGitHub community articles\\nRepositories\\nTopics\\nTrending\\nCollections\\nEnterprise\\nEnterprise platform\\nAI-powered developer platform\\nAvailable add-ons\\nGitHub Advanced Security\\nEnterprise-grade security features\\nCopilot for business\\nEnterprise-grade AI features\\nPremium Support\\nEnterprise-grade 24/7 support\\nPricing\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel\\nSubmit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nCancel\\nCreate saved search\\nSign in\\nSign up\\nReseting focus\\nYou signed in with another tab or window.\\nReload\\nto refresh your session.\\nYou signed out in another tab or window.\\nReload\\nto refresh your session.\\nYou switched accounts on another tab or window.\\nReload\\nto refresh your session.\\nDismiss alert\\nHugging Face\\nThe AI community building the future.\\nVerified\\nWe\\'ve verified that the organization\\nhuggingface\\ncontrols the domain:\\nhuggingface.co\\nLearn more about verified organizations\\n48.4k\\nfollowers\\nNYC + Paris\\nhttps://huggingface.co/\\nX\\n@huggingface\\nOverview\\nRepositories\\nProjects\\nPackages\\nPeople\\nSponsoring\\n0\\nMore\\nOverview\\nRepositories\\nProjects\\nPackages\\nPeople\\nSponsoring\\nPinned\\nLoading\\ntransformers\\ntransformers\\nPublic\\nü§ó Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.\\nPython\\n144k\\n28.8k\\ndiffusers\\ndiffusers\\nPublic\\nü§ó Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.\\nPython\\n28.8k\\n5.9k\\ndatasets\\ndatasets\\nPublic\\nü§ó The largest hub of ready-to-use datasets for ML models with fast, easy-to-use and efficient data manipulation tools\\nPython\\n20.1k\\n2.8k\\npeft\\npeft\\nPublic\\nü§ó PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.\\nPython\\n18.3k\\n1.8k\\naccelerate\\naccelerate\\nPublic\\nüöÄ A simple way to launch, train, and use PyTorch models on almost any device and distributed configuration, automatic mixed precision (including fp8), and easy-to-configure FSDP and DeepSpeed support\\nPython\\n8.7k\\n1.1k\\noptimum\\noptimum\\nPublic\\nüöÄ Accelerate inference and training of ü§ó Transformers, Diffusers, TIMM and Sentence Transformers with easy to use hardware optimization tools\\nPython\\n2.9k\\n528\\nRepositories\\nLoading\\nType\\nSelect type\\nForks\\nArchived\\nMirrors\\nTemplates\\nLanguage\\nSelect language\\nAll\\nC\\nC#\\nC++\\nCuda\\nDockerfile\\nGo\\nHandlebars\\nHTML\\nJava\\nJavaScript\\nJupyter Notebook\\nKotlin\\nLua\\nMDX\\nMustache\\nNix\\nPython\\nRust\\nShell\\nSmarty\\nSvelte\\nSwift\\nTypeScript\\nSort\\nSelect order\\nLast updated\\nName\\nStars\\nShowing 10 of 307 repositories\\ngym-genesis\\nPublic\\nA gym environment for GENESIS\\nhuggingface/gym-genesis‚Äôs past year of commit activity\\nPython\\n11\\nApache-2.0\\n2\\n1\\n4\\nUpdated\\nMay 4, 2025\\noptimum-benchmark\\nPublic\\nüèãÔ∏è A unified multi-backend utility for benchmarking Transformers, Timm, PEFT, Diffusers and Sentence-Transformers with full support of Optimum\\'s hardware optimizations & quantization schemes.\\nhuggingface/optimum-benchmark‚Äôs past year of commit activity\\nPython\\n297\\nApache-2.0\\n58\\n9\\n(1 issue needs help)\\n1\\nUpdated\\nMay 4, 2025\\ncandle\\nPublic\\nMinimalist ML framework for Rust\\nhuggingface/candle‚Äôs past year of commit activity\\nRust\\n17,113\\nApache-2.0\\n1,093\\n410\\n(5 issues need help)\\n113\\nUpdated\\nMay 4, 2025\\nsmolagents\\nPublic\\nü§ó smolagents: a barebones library for agents that think in python code.\\nhuggingface/smolagents‚Äôs past year of commit activity\\nPython\\n17,944\\nApache-2.0\\n1,559\\n132\\n(1 issue needs help)\\n101\\nUpdated\\nMay 4, 2025\\nhub-docs\\nPublic\\nDocs of the Hugging Face Hub\\nhuggingface/hub-docs‚Äôs past year of commit activity\\nHandlebars\\n385\\nApache-2.0\\n298\\n106\\n25\\nUpdated\\nMay 4, 2025\\nhfendpoints\\nPublic\\nSDK for creating Hugging Face Inference Endpoints deployments\\nhuggingface/hfendpoints‚Äôs past year of commit activity\\nRust\\n2\\n1\\n0\\n1\\nUpdated\\nMay 3, 2025\\nxet-core\\nPublic\\nxet client tech, used in huggingface_hub\\nhuggingface/xet-core‚Äôs past year of commit activity\\nRust\\n92\\nApache-2.0\\n12\\n5\\n13\\nUpdated\\nMay 3, 2025\\ndiffusers\\nPublic\\nü§ó Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch and FLAX.\\nhuggingface/diffusers‚Äôs past year of commit activity\\nPython\\n28,841\\nApache-2.0\\n5,922\\n500\\n(10 issues need help)\\n184\\nUpdated\\nMay 3, 2025\\nhf-workflows\\nPublic\\nhuggingface/hf-workflows‚Äôs past year of commit activity\\n5\\n7\\n0\\n1\\nUpdated\\nMay 3, 2025\\ntransformers\\nPublic\\nü§ó Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.\\nhuggingface/transformers‚Äôs past year of commit activity\\nPython\\n143,811\\nApache-2.0\\n28,839\\n1,057\\n(2 issues need help)\\n729\\nUpdated\\nMay 3, 2025\\nView all repositories\\nPeople\\nView all\\nTop languages\\nPython\\nJupyter Notebook\\nRust\\nTypeScript\\nJavaScript\\nMost used topics\\npytorch\\nmachine-learning\\nnlp\\ntransformers\\ndeep-learning\\nFooter\\n¬© 2025 GitHub,\\xa0Inc.\\nFooter navigation\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\nManage cookies\\nDo not share my personal information\\nYou can‚Äôt perform that action at this time.\\n\\n\\n\\ntwitter_page\\nWebpage Title: No title found\\nWebpage Content:\\nJavaScript is not available.\\nWe‚Äôve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.\\nHelp Center\\nTerms of Service\\nPrivacy Policy\\nCookie Policy\\nImprint\\nAds info\\n¬© 2025 X Corp.\\nSomething went wrong, but don‚Äôt fret ‚Äî let‚Äôs give it another shot.\\nTry again\\nSome privacy related extensions may cause issues on x.com. Please disable them and try again.\\n\\n\\n\\nlinkedin_page\\nWebpage Title: Hugging Face | LinkedIn\\nWebpage Content:\\nSkip to main content\\nLinkedIn\\nArticles\\nPeople\\nLearning\\nJobs\\nGames\\nGet the app\\nJoin now\\nSign in\\nHugging Face\\nSoftware Development\\nThe AI community building the future.\\nSee jobs\\nFollow\\nView all 533 employees\\nReport this company\\nAbout us\\nThe AI community building the future.\\nWebsite\\nhttps://huggingface.co\\nExternal link for Hugging Face\\nIndustry\\nSoftware Development\\nCompany size\\n51-200 employees\\nType\\nPrivately Held\\nFounded\\n2016\\nSpecialties\\nmachine learning, natural language processing, and deep learning\\nProducts\\nHugging Face\\nHugging Face\\nNatural Language Processing (NLP) Software\\nWe‚Äôre on a journey to solve and democratize artificial intelligence through natural language.\\nLocations\\nPrimary\\nGet directions\\nParis, FR\\nGet directions\\nEmployees at Hugging Face\\nLudovic Huraux\\nRajat Arya\\nTech Lead & Software Engineer @ HF | prev: co-founder XetHub, Apple, Turi, AWS, Microsoft\\nJeff Boudier\\nProduct + Growth at Hugging Face\\nTerrence Rohan\\nSeed Investor\\nSee all employees\\nUpdates\\nHugging Face\\nreposted this\\nBen Burtenshaw\\nMachine Learning Advocacy @ ü§ó Hugging Face\\n2d\\nReport this post\\nStill building with Qwen3-30B-A3B. The MoE variant was serious benchmark scores for 3B active params. I\\'ve got some handy stuff to share:\\n\\n1. Take the model out for a spin on Inference Providers:\\nhttps://lnkd.in/eAkUri43\\n2. If you\\'re running it locally.\\nUnsloth AI\\nis the place to start\\nhttps://lnkd.in/ehB86DHj\\n3. If you\\'re building inference yourself, the model card has practical tips for squeezing everything out of the model. Don\\'t miss this! üî´ foot guns for me were managing reasoning chains and 32k output length!\\n\\n4. I share this notebook on fine-tuning the dense variant:\\nhttps://lnkd.in/e3Wu2wiP\\n5. And this script for LoRA SFT on the MoE:\\nhttps://lnkd.in/ehm4b2GU\\n6. I\\'m also keeping a logbook of the experiment so far in this thread:\\nhttps://lnkd.in/epgdNq9b\\n7. All the models, datasets, and scripts I\\'m building are in this collection:\\nhttps://lnkd.in/eSU3_Trk\\n277\\n9 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nBespoke Labs\\n2,311 followers\\n2d\\nReport this post\\nDeadline Extended To May 9th: ‚è≥ \\nYour ideas deserve a bit more breathing room, so we‚Äôre keeping the door open a little longer. The new submission deadline is May 9 at 11:59 PM PT. \\n\\nThanks to everyone who‚Äôs been contributing, let‚Äôs keep the momentum going!\\n\\nüìÇ Browse current submissions:\\nhttps://lnkd.in/gb-2EGkY\\n25\\n2 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nGradio\\n63,111 followers\\n3d\\nReport this post\\nüöÄ ü§© BIG ANNOUNCEMENT: Build an MCP Server in 5 Lines of Python with Gradio!\\n\\nThe Model Context Protocol (MCP) is revolutionizing how LLMs access tools, but implementation has been complex... until now. üòâ \\n\\nWith our latest release, any Gradio app BECOMES an MCP server with ONE simple parameter:\\ndemo.launch\\n(mcp_server=True)\\n\\nThis means your custom Python functions‚Äîfrom image generators to specialized calculators‚Äîcan be instantly available to Claude, Cursor, and other MCP-compatible LLMs.\\n\\nüìà What this enables:\\n- Enhance LLMs with domain-specific capabilities or tools\\n- ü§ØüëâDEPLOY YOUR MCP SERVERS FOR FREE ON Hugging Face Spacesüëàü§Ø\\n- Automatic file handling and data conversion for your MCP Server (this is üî•) \\n\\nLearn how to build your MCP server from our small release blog:\\nhttps://lnkd.in/gvUnFxKE\\nHow would you extend LLM capabilities with your own tools?\\n1,502\\n65 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nAymeric Roucher\\nLeading agents @ Hugging Face ü§ó | Polytechnique - Cambridge\\n3d\\nReport this post\\nThe agentic framework of\\nHugging Face\\n, smolagents, is the tinyest ever. It implements fewer features than other frameworks -&gt; that\\'s the feature.\\n\\n‚û°Ô∏è The main issue among agentic frameworks is complexity : they tend to pile up abstractions, trying to solve everything rather than bein part of a bigger workflow. So instead of making the all-encompassing factory, we set out to make the smallest possible framework for agents, the one that would just provide the essential building blocks and let users build the rest.\\n\\nüí° Optimizing for reducing size is interesting, because it forces you to consider simplicity at each step :\\n- do we need this abstraction, won\\'t it make the code less readable?\\n- instead of adding this feature, why shouldn\\'t we just provide the building blocks that will let users build it for themselves?\\n\\nGo try it out! Now there\\'s a short course on Deeplearning AI if you want to get onboard! üöÄ\\n438\\n32 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nGradio\\n63,111 followers\\n3d\\nEdited\\nReport this post\\nü§© FantasyTalking -- Realistic talking portrait generations have never been this good! üëá\\n‚Ä¶more\\n106\\n7 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nGradio\\n63,111 followers\\n4d\\nReport this post\\nFreepik has released image gen models trained on 80 million commercially licensed imagesüíØüëå\\n\\n- Models are called F Lite image generation models\\n- Come in two flavors: standard and texture\\n- Standard is more prompt-faithful, Texture delivers better textures and more \"creative\" results\\n- Needs GPU with &gt;=24GB of VRAM to run\\n- Permissive CreativeML Open RAIL-M License\\n‚Ä¶more\\n73\\n4 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nMerve Noyan\\nopen-sourceress at ü§ó | Google Developer Expert in Machine Learning, MSc Candidate in Data Science\\n4d\\nReport this post\\nMeta released Llama Guard 4 and new Prompt Guard 2 models ü¶ô‚ù§Ô∏è\\n\\n&gt; Llama Guard 4 is a new model to filter model inputs/outputs both text-only and image üõ°Ô∏è use it before and after LLMs/VLMs!\\n&gt; Prompt Guard 2 22M & 86M are smol models to prevent model jailbreaks and prompt injections ‚öîÔ∏è\\n&gt; Both come with new release of transformers ü§ó \\nFind links to our explanatory blog and notebook in comments üí¨\\n510\\n7 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nKalyan Dutia\\nHead of Data Science at Climate Policy Radar\\n5d\\nReport this post\\nTwo exciting open data announcements:\\n- We‚Äôve updated\\nClimate Policy Radar\\n\\'s open data on\\nHugging Face\\nHub, giving you the full, translated text of climate laws & policies plus the most recent UNFCCC submissions\\n- With help from\\nJan Ainali\\nand\\nStuart Prior\\n, climate laws & policies are started to get added to\\nWikidata\\nwith links back to our tools! I\\'m really happy our data can be used to improve the quality of Wikidata, and am hoping this will lead to better Wikipedia pages about climate policy with more language coverage üí™\\n\\n(We\\'re on the lookout for any Wikimedia volunteers who might be able to help get more documents onto Wikidata, so drop me a DM if you could!)\\n\\nLinks in comments üëá\\n69\\n5 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nBen Burtenshaw\\nMachine Learning Advocacy @ ü§ó Hugging Face\\n5d\\nReport this post\\nJust shipped a space for image generation on any LoRA adapter from the\\nHugging Face\\nhub. \\n\\nüîó\\nhttps://lnkd.in/eeFmv3t4\\nYou can do this:\\n\\n- describe an image to generate\\n- pick any community lora adapter from the hub. i.e. ghibli, photorealism, etc\\n- generate the image in seconds, powered by inference providers and\\nfal\\nLet me know what you build with LoRA or inference providers.\\n‚Ä¶more\\n84\\n3 Comments\\nLike\\nComment\\nShare\\nHugging Face\\nreposted this\\nMikolaj Czerkawski\\nCo-Founder & Partner Scientist @ Asterisk Labs | ex-Research Fellow @ European Space Agency Œ¶-lab\\n6d\\nReport this post\\n‚ö†Ô∏è Nearly 40 billion (39,820,373,479) new embeddings of Major TOM Copernicus data now released!\\n\\nTogether with\\nCloudFerro S.A.\\n,\\nEuropean Space Agency - ESA\\n, and\\nasterisk labs\\nwe continue expanding the Major TOM project and its set of open embedding datasets.\\n\\nToday, we make publicly available 3 new expansions:\\n\\n‚úÖ DeCUR - Sentinel-2 L1C - another ResNet model (developed by\\nYi Wang\\n) focused on learning both common and unique representations between MSI and SAR.\\nü§ó\\nhttps://lnkd.in/da7CKJ28\\n‚úÖ DeCUR - Sentinel-1 RTC - the second Major TOM embedding dataset of Sentinel-1 data with stunning PCA visualisations!\\nü§ó\\nhttps://lnkd.in/dfaNUZmJ\\n‚úÖ MMEarth - Sentinel-2 L2A - our first embedding of complete L2A (atmospherically corrected) Sentinel-2 data and also the first one where we release dense embeddings (133 x 133 vectors) for each grid cell. It is an embedding dataset that in fact occupies more space than the input data, unlike the previous ones. Big thanks to\\nVishal Nedungadi\\nand\\nNico Lang\\nfor directly supporting our efforts!\\nü§ó\\nhttps://lnkd.in/dQ3SzfGU\\nThe datasets are available for instant use on\\nHugging Face\\n, except for MMEarth, which due to storage limitations has been downsampled from 133x133 resolution to 13x13. Full versions of the datasets are available on\\nCREODIAS\\nhttps://creodias.eu/\\n.\\n\\nüéôÔ∏è\\nMarcin Kluczek\\nwho spearheaded the challenge of embedding hundreds of terabytes of data will present today at\\nEuropean Geosciences Union (EGU)\\nat 9:40:\\nhttps://lnkd.in/d6w48rym\\nBig kudos to\\nJƒôdrzej S. Bojanowski\\nfor supporting our joint effort towards open embeddings of Copernicus!\\n343\\n22 Comments\\nLike\\nComment\\nShare\\nJoin now to see what you are missing\\nFind people you know at Hugging Face\\nBrowse recommended jobs for you\\nView all updates, news, and articles\\nJoin now\\nSimilar pages\\nAnthropic\\nResearch Services\\nPerplexity\\nSoftware Development\\nSan Francisco, California\\nMistral AI\\nTechnology, Information and Internet\\nParis, France\\nOpenAI\\nResearch Services\\nSan Francisco, CA\\nLangChain\\nTechnology, Information and Internet\\nGenerative AI\\nTechnology, Information and Internet\\nDeepLearning.AI\\nSoftware Development\\nPalo Alto, California\\nGoogle DeepMind\\nResearch Services\\nLondon, London\\nCohere\\nSoftware Development\\nToronto, Ontario\\nLlamaIndex\\nTechnology, Information and Internet\\nSan Francisco, California\\nShow more similar pages\\nShow fewer similar pages\\nBrowse jobs\\nEngineer jobs\\n555,845 open jobs\\nMachine Learning Engineer jobs\\n148,937 open jobs\\nScientist jobs\\n48,969 open jobs\\nSoftware Engineer jobs\\n300,699 open jobs\\nAnalyst jobs\\n694,057 open jobs\\nIntern jobs\\n71,196 open jobs\\nDeveloper jobs\\n258,935 open jobs\\nManager jobs\\n1,880,925 open jobs\\nProduct Manager jobs\\n199,941 open jobs\\nDirector jobs\\n1,220,357 open jobs\\nPython Developer jobs\\n46,642 open jobs\\nData Scientist jobs\\n264,158 open jobs\\nData Analyst jobs\\n329,009 open jobs\\nSenior Software Engineer jobs\\n78,145 open jobs\\nProject Manager jobs\\n253,048 open jobs\\nResearcher jobs\\n195,654 open jobs\\nAssociate jobs\\n1,091,945 open jobs\\nData Engineer jobs\\n192,126 open jobs\\nVice President jobs\\n235,270 open jobs\\nSpecialist jobs\\n768,666 open jobs\\nShow more jobs like this\\nShow fewer jobs like this\\nFunding\\nHugging Face\\n8 total rounds\\nLast Round\\nSeries unknown\\nSep 1, 2024\\nExternal Crunchbase Link for last round of funding\\nSee more info on\\ncrunchbase\\nMore searches\\nMore searches\\nEngineer jobs\\nScientist jobs\\nMachine Learning Engineer jobs\\nSoftware Engineer jobs\\nIntern jobs\\nDeveloper jobs\\nAnalyst jobs\\nManager jobs\\nSenior Software Engineer jobs\\nData Scientist jobs\\nResearcher jobs\\nProduct Manager jobs\\nDirector jobs\\nAssociate jobs\\nIntelligence Specialist jobs\\nData Analyst jobs\\nData Science Specialist jobs\\nPython Developer jobs\\nQuantitative Analyst jobs\\nProject Manager jobs\\nAccount Executive jobs\\nSpecialist jobs\\nData Engineer jobs\\nDesigner jobs\\nQuantitative Researcher jobs\\nConsultant jobs\\nSolutions Architect jobs\\nVice President jobs\\nUser Experience Designer jobs\\nHead jobs\\nFull Stack Engineer jobs\\nEngineering Manager jobs\\nSoftware Engineer Intern jobs\\nJunior Software Engineer jobs\\nSoftware Intern jobs\\nProduct Designer jobs\\nSolutions Engineer jobs\\nStaff Software Engineer jobs\\nProgram Manager jobs\\nSenior Scientist jobs\\nWriter jobs\\nResearch Intern jobs\\nSenior Product Manager jobs\\nSummer Intern jobs\\nAccount Manager jobs\\nRecruiter jobs\\nLead jobs\\nResearch Engineer jobs\\nComputer Science Intern jobs\\nPlatform Engineer jobs\\nJunior Developer jobs\\nAndroid Developer jobs\\nUser Experience Researcher jobs\\nJava Software Engineer jobs\\nSite Reliability Engineer jobs\\nGraduate jobs\\nSoftware Engineering Manager jobs\\nRepresentative jobs\\nBusiness Development Specialist jobs\\nComputer Engineer jobs\\nLinkedIn\\n¬© 2025\\nAbout\\nAccessibility\\nUser Agreement\\nPrivacy Policy\\nCookie Policy\\nCopyright Policy\\nBrand Policy\\nGuest Controls\\nCommunity Guidelines\\nÿßŸÑÿπÿ±ÿ®Ÿäÿ© (Arabic)\\n‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ (Bangla)\\nƒåe≈°tina (Czech)\\nDansk (Danish)\\nDeutsch (German)\\nŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ (Greek)\\nEnglish (English)\\nEspa√±ol (Spanish)\\nŸÅÿßÿ±ÿ≥€å (Persian)\\nSuomi (Finnish)\\nFran√ßais (French)\\n‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi)\\nMagyar (Hungarian)\\nBahasa Indonesia (Indonesian)\\nItaliano (Italian)\\n◊¢◊ë◊®◊ô◊™ (Hebrew)\\nÊó•Êú¨Ë™û (Japanese)\\nÌïúÍµ≠Ïñ¥ (Korean)\\n‡§Æ‡§∞‡§æ‡§†‡•Ä (Marathi)\\nBahasa Malaysia (Malay)\\nNederlands (Dutch)\\nNorsk (Norwegian)\\n‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä (Punjabi)\\nPolski (Polish)\\nPortugu√™s (Portuguese)\\nRom√¢nƒÉ (Romanian)\\n–†—É—Å—Å–∫–∏–π (Russian)\\nSvenska (Swedish)\\n‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å (Telugu)\\n‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (Thai)\\nTagalog (Tagalog)\\nT√ºrk√ße (Turkish)\\n–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ (Ukrainian)\\nTi·∫øng Vi·ªát (Vietnamese)\\nÁÆÄ‰Ωì‰∏≠Êñá (Chinese (Simplified))\\nÊ≠£È´î‰∏≠Êñá (Chinese (Traditional))\\nLanguage\\nAgree & Join LinkedIn\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs\\nUser Agreement\\n,\\nPrivacy Policy\\n, and\\nCookie Policy\\n.\\nSign in to see who you already know at Hugging Face\\nSign in\\nWelcome back\\nEmail or phone\\nPassword\\nShow\\nForgot password?\\nSign in\\nor\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs\\nUser Agreement\\n,\\nPrivacy Policy\\n, and\\nCookie Policy\\n.\\nNew to LinkedIn?\\nJoin now\\nor\\nNew to LinkedIn?\\nJoin now\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs\\nUser Agreement\\n,\\nPrivacy Policy\\n, and\\nCookie Policy\\n.\\nLinkedIn\\nLinkedIn is better on the app\\nDon‚Äôt have the app? Get it in the Microsoft Store.\\nOpen the app\\n\\nYou are looking at a company called HuggingFace.\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title: Hugging Face ‚Äì The AI community building the future.\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nQwen/Qwen3-235B-A22B\\nUpdated\\n3 days ago\\n‚Ä¢\\n28.6k\\n‚Ä¢\\n644\\ndeepseek-ai/DeepSeek-Prover-V2-671B\\nUpdated\\n4 days ago\\n‚Ä¢\\n1.71k\\n‚Ä¢\\n627\\nnari-labs/Dia-1.6B\\nUpdated\\n7 days ago\\n‚Ä¢\\n108k\\n‚Ä¢\\n1.77k\\nQwen/Qwen3-30B-A3B\\nUpdated\\n4 days ago\\n‚Ä¢\\n39.8k\\n‚Ä¢\\n428\\nQwen/Qwen3-32B\\nUpdated\\n5 days ago\\n‚Ä¢\\n73k\\n‚Ä¢\\n263\\nBrowse 1M+ models\\nSpaces\\nRunning\\n5.86k\\n5.86k\\nDeepSite\\nüê≥\\nGenerate any application with DeepSeek\\nRunning\\n362\\n362\\nQwen3 Demo\\nüìä\\nGenerate responses to user queries using conversation history\\nRunning\\non\\nZero\\n1.09k\\n1.09k\\nDia 1.6B\\nüëØ\\nGenerate realistic dialogue from a script, using Dia!\\nRunning\\non\\nZero\\n285\\n285\\nStep1X Edit\\nüíª\\nEdit an image based on the given instruction.\\nRunning\\non\\nZero\\n245\\n245\\nDescribe Anything\\n‚ö°\\nDescribe image parts using masks\\nBrowse 400k+ applications\\nDatasets\\nnvidia/OpenMathReasoning\\nUpdated\\n10 days ago\\n‚Ä¢\\n19.5k\\n‚Ä¢\\n163\\nnvidia/Nemotron-CrossThink\\nUpdated\\n3 days ago\\n‚Ä¢\\n299\\n‚Ä¢\\n33\\nnvidia/OpenCodeReasoning\\nUpdated\\n19 days ago\\n‚Ä¢\\n15.6k\\n‚Ä¢\\n335\\nOpenGVLab/InternVL-Data\\nUpdated\\nabout 2 hours ago\\n‚Ä¢\\n6.98k\\n‚Ä¢\\n106\\nEureka-Lab/PHYBench\\nUpdated\\n8 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n47\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n‚Ä¢\\n756 models\\n‚Ä¢\\n3.19k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.12k models\\n‚Ä¢\\n5.78k followers\\nAmazon\\ncompany\\n‚Ä¢\\n20 models\\n‚Ä¢\\n3.11k followers\\nGoogle\\ncompany\\n‚Ä¢\\n991 models\\n‚Ä¢\\n12.7k followers\\nIntel\\ncompany\\n‚Ä¢\\n220 models\\n‚Ä¢\\n2.5k followers\\nMicrosoft\\ncompany\\n‚Ä¢\\n375 models\\n‚Ä¢\\n12k followers\\nGrammarly\\nEnterprise\\ncompany\\n‚Ä¢\\n10 models\\n‚Ä¢\\n156 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n266 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n143,809\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n28,840\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,251\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,573\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,651\\nFast tokenizers optimized for research & production\\nTRL\\n13,572\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,540\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n17,944\\nSmol library to build great agents in Python\\nPEFT\\n18,288\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,062\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,078\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,674\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nTasks\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nabout_page\\nWebpage Title: Hugging Face ‚Äì The AI community building the future.\\nWebpage Content:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nPosts\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nQwen/Qwen3-235B-A22B\\nUpdated\\n3 days ago\\n‚Ä¢\\n28.6k\\n‚Ä¢\\n644\\ndeepseek-ai/DeepSeek-Prover-V2-671B\\nUpdated\\n4 days ago\\n‚Ä¢\\n1.71k\\n‚Ä¢\\n627\\nnari-labs/Dia-1.6B\\nUpdated\\n7 days ago\\n‚Ä¢\\n108k\\n‚Ä¢\\n1.77k\\nQwen/Qwen3-30B-A3B\\nUpdated\\n4 days ago\\n‚Ä¢\\n39.8k\\n‚Ä¢\\n428\\nQwen/Qwen3-32B\\nUpdated\\n5 days ago\\n‚Ä¢\\n73k\\n‚Ä¢\\n263\\nBrowse 1M+ models\\nSpaces\\nRunning\\n5.86k\\n5.86k\\nDeepSite\\nüê≥\\nGenerate any application with DeepSeek\\nRunning\\n362\\n362\\nQwen3 Demo\\nüìä\\nGenerate responses to user queries using conversation history\\nRunning\\non\\nZero\\n1.09k\\n1.09k\\nDia 1.6B\\nüëØ\\nGenerate realistic dialogue from a script, using Dia!\\nRunning\\non\\nZero\\n285\\n285\\nStep1X Edit\\nüíª\\nEdit an image based on the given instruction.\\nRunning\\non\\nZero\\n245\\n245\\nDescribe Anything\\n‚ö°\\nDescribe image parts using masks\\nBrowse 400k+ applications\\nDatasets\\nnvidia/OpenMathReasoning\\nUpdated\\n10 days ago\\n‚Ä¢\\n19.5k\\n‚Ä¢\\n163\\nnvidia/Nemotron-CrossThink\\nUpdated\\n3 days ago\\n‚Ä¢\\n299\\n‚Ä¢\\n33\\nnvidia/OpenCodeReasoning\\nUpdated\\n19 days ago\\n‚Ä¢\\n15.6k\\n‚Ä¢\\n335\\nOpenGVLab/InternVL-Data\\nUpdated\\nabout 2 hours ago\\n‚Ä¢\\n6.98k\\n‚Ä¢\\n106\\nEureka-Lab/PHYBench\\nUpdated\\n8 days ago\\n‚Ä¢\\n1.04k\\n‚Ä¢\\n47\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nEnterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n‚Ä¢\\n756 models\\n‚Ä¢\\n3.19k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.12k models\\n‚Ä¢\\n5.78k followers\\nAmazon\\ncompany\\n‚Ä¢\\n20 models\\n‚Ä¢\\n3.11k followers\\nGoogle\\ncompany\\n‚Ä¢\\n991 models\\n‚Ä¢\\n12.7k followers\\nIntel\\ncompany\\n‚Ä¢\\n220 models\\n‚Ä¢\\n2.5k followers\\nMicrosoft\\ncompany\\n‚Ä¢\\n375 models\\n‚Ä¢\\n12k followers\\nGrammarly\\nEnterprise\\ncompany\\n‚Ä¢\\n10 models\\n‚Ä¢\\n156 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n266 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n1'\n\n\n\n5. Generating the Brochure Content\nThe create_brochure function uses the gpt-4o-mini model to generate the brochure content. It takes the company name and URL as input, fetches the website content, identifies relevant links, and then prompts the LLM to create a brochure.\n\n\nCode\ndef create_brochure(company_name, url):\n    response = openai.chat.completions.create(\n        model=MODEL,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n        ],\n    )\n    result = response.choices[0].message.content\n    display(Markdown(result))\n\n\n\n\n6. Running the Example\n\n\nCode\ncreate_brochure(\"HuggingFace\", \"https://huggingface.co\")\n\n\nFound links: {'links': [{'type': 'about_page', 'url': 'https://huggingface.co/huggingface'}, {'type': 'careers_page', 'url': 'https://apply.workable.com/huggingface/'}, {'type': 'enterprise_page', 'url': 'https://huggingface.co/enterprise'}, {'type': 'posts_page', 'url': 'https://huggingface.co/posts'}, {'type': 'blog_page', 'url': 'https://huggingface.co/blog'}, {'type': 'community_page', 'url': 'https://discuss.huggingface.co'}, {'type': 'social_media_page', 'url': 'https://twitter.com/huggingface'}, {'type': 'linkedin_page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n\n\nWelcome to Hugging Face\n\nThe AI Community Building the Future\nHugging Face is a pioneering company dedicated to democratizing machine learning and artificial intelligence. With over 1 million models and 250,000 datasets, we provide a collaborative platform for researchers, developers, and enthusiasts in the machine learning community to share, innovate, and advance the state of AI technology.\n\n\nWhat We Offer\nCollaboration Platform\nJoin a global network where you can create, discover, and collaborate on machine learning models, datasets, and applications.\n\nModels: Explore the latest trending models like Qwen/Qwen3 and DeepSeek-Prover.\nDatasets: Access a rich repository of datasets for any ML task, including OpenMathReasoning and OpenCodeReasoning.\nSpaces: Experiment and run applications in a user-friendly interface, optimized for development.\n\n\n\n\nWhy Choose Hugging Face?\n\nCommunity-Driven: Actively engage with more than 50,000 organizations including industry giants like Google, Amazon, and Microsoft who trust our platform.\nOpen Source: We believe in transparency and availability. Contribute to our models and explore extensive resources including Transformers, Tokenizers, and more.\nEnterprise Solutions: With specialized features for organizations, Hugging Face provides security, access controls, and prioritized support to help your team effectively build AI applications.\n\n\n\n\nCompany Culture\nWe are on a mission to democratize good machine learning, making it accessible for everyone involved in the AI ecosystem. Our community is composed of over 200 dedicated employees who continually contribute to fostering an inclusive and innovative work environment.\nWe encourage continuous learning, collaboration, and creativity, allowing our team members to thrive and push the boundaries of what‚Äôs possible in AI.\n\n\n\nCareer Opportunities\nWe‚Äôre constantly looking for talented individuals to join our dynamic team. If you‚Äôre passionate about AI, machine learning, or software development, consider exploring open positions with us. Dive into the world of cutting-edge AI technology and help us shape the future with your expertise.\n\nExplore Open Positions: Join our collaborative work environment that values innovation and learning.\n\n\n\n\nJoin Us!\nWhether you‚Äôre looking to leverage our powerful tools in your projects, become a part of our thriving community, or start a career with us, Hugging Face is the place to be.\nContact Us | Visit Our Website\nhuggingface - The AI community building the future.\n\n\n\n\n\n\nCode\ncreate_brochure(\"Anthropic\", \"https://www.anthropic.com/\")\n\n\nFound links: {'links': [{'type': 'about_page', 'url': 'https://www.anthropic.com/company'}, {'type': 'careers_page', 'url': 'https://www.anthropic.com/careers'}, {'type': 'research_page', 'url': 'https://www.anthropic.com/research'}, {'type': 'team_page', 'url': 'https://www.anthropic.com/team'}, {'type': 'news_page', 'url': 'https://www.anthropic.com/news'}]}\n\n\n# Anthropic Brochure\n\n## About Anthropic\nAt Anthropic, our mission is clear: **to build AI systems that serve humanity's long-term well-being**. We are a Public Benefit Corporation headquartered in San Francisco, dedicated to creating reliable, interpretable, and steerable AI systems. Our pioneering work not only focuses on powerful technologies, but also emphasizes the importance of considering their societal implications through rigorous research and policy-making.\n\n## Our Vision\nWe believe AI will have a vast impact on the world. By harnessing cutting-edge research and applying our findings to create tangible products, we aim to ensure that AI serves as a positive force for humanity. Our flagship model, **Claude**, represents our commitment to developing advanced AI tools that are safe, interpretable, and beneficial for all.\n\n## Company Culture\n### Values\nOur organization thrives on a unique set of values:\n1. **Act for the Global Good**: We maximize positive outcomes for humanity while being bold in our actions.\n2. **Hold Light and Shade**: We acknowledge the risks and rewards of AI, striving to protect against the bad while amplifying the good.\n3. **Be Good to Our Users**: We extend kindness and generosity to everyone influenced by our technology, including customers, policy-makers, and employees.\n4. **Ignite a Race to the Top on Safety**: We aim to inspire all developers to prioritize safety in AI systems, setting high standards for the industry.\n5. **Do the Simple Thing That Works**: We embrace practical, effective solutions that have a meaningful impact.\n6. **Be Helpful, Honest, and Harmless**: Our high-trust culture emphasizes integrity, collaboration, and a shared mission.\n7. **Put the Mission First**: Our mission guides our decisions and actions, fostering collaboration and trust across teams.\n\n## Research and Development\nOur interdisciplinary team comprises researchers, engineers, policy experts, and operational leaders, all collaborating to push the boundaries of AI safety. Our research spans various modalities, tackling novel areas such as interpretability, human feedback, and societal impact analysis.\n\n## Customer Solutions\nWe translate our research into practical tools and applications that benefit various sectors, including:\n- **AI Agents** for automated tasks\n- **Coding support** to assist developers\n- **Customer service solutions** for improved interaction\n- **Specialized applications** for education and enterprise needs\n\n## Career Opportunities\n### Join Us!\nAt Anthropic, we value a diverse range of experiences and ideas. Our team members come from backgrounds in physics, machine learning, public policy, and business. We are committed to creating a supportive work environment where everyone can thrive. Some of our employee benefits include:\n- Comprehensive health, dental, and vision insurance\n- Flexible paid time off and paid parental leave\n- Retirement plans with competitive matching\n- Wellness stipends and commuter benefits\n\nIf you're passionate about AI safety and want to make a real difference, [**join our team**](#careers).\n\n## Customer Testimonials\n&gt; \"Claude has transformed our way of working at North Highland. It has enabled us to complete tasks up to 5x faster!\"  \n&gt; ‚Äî Luka Anic, Senior Director at North Highland\n\n&gt; \"Leveraging Claude in our workflows has made generating content and insights significantly easier and faster.\"  \n&gt; ‚Äî Olga Pirog, Head of AI Transformation at IG Group\n\n## Stay Updated\nFor the latest news and developments in AI safety and our product offerings, visit our [**Newsroom**](#news) and follow us on our social media channels.\n\n---\n\n### Contact Us\nFor inquiries, partnerships, and support, please visit our website at [Anthropic.ai](https://www.anthropic.ai).\n\n---\n\n**Anthropic**: Crafting the Future of Safe AI.\n\n\n\n\nCode\ncreate_brochure(\"Maruti Suzuki\", \"https://www.marutisuzuki.com/\")\n\n\nFound links: {'links': [{'type': 'about_page', 'url': 'https://www.marutisuzuki.com/corporate/about-us'}, {'type': 'about_history', 'url': 'https://www.marutisuzuki.com/corporate/about-us/history'}, {'type': 'about_leadership', 'url': 'https://www.marutisuzuki.com/corporate/about-us/leadership'}, {'type': 'about_strength', 'url': 'https://www.marutisuzuki.com/corporate/about-us/strength'}, {'type': 'about_values', 'url': 'https://www.marutisuzuki.com/corporate/about-us/values'}, {'type': 'about_exports', 'url': 'https://www.marutisuzuki.com/corporate/about-us/exports'}, {'type': 'about_sustainability', 'url': 'https://www.marutisuzuki.com/corporate/about-us/sustainability'}, {'type': 'about_csr', 'url': 'https://www.marutisuzuki.com/corporate/about-us/csr'}, {'type': 'careers_page', 'url': 'https://www.marutisuzuki.com/corporate/careers'}, {'type': 'careers_life', 'url': 'https://www.marutisuzuki.com/corporate/careers/life-at-msil'}, {'type': 'careers_why_work_with_us', 'url': 'https://www.marutisuzuki.com/corporate/careers/why-work-with-us'}, {'type': 'careers_join_us', 'url': 'https://www.marutisuzuki.com/corporate/careers/join-us'}, {'type': 'careers_meet_our_people', 'url': 'https://www.marutisuzuki.com/corporate/careers/meet-our-people'}, {'type': 'media_page', 'url': 'https://www.marutisuzuki.com/corporate/media'}, {'type': 'technology_page', 'url': 'https://www.marutisuzuki.com/corporate/technology'}]}\n\n\nMaruti Suzuki: Driving India Forward\n\nOverview\nMaruti Suzuki India Limited (MSIL) is the largest passenger vehicle manufacturer in India, recognized for its commitment to quality and reliability. Celebrated for manufacturing a wide array of cars, including hatchbacks, sedans, SUVs, and vans, Maruti Suzuki‚Äôs brands include ARENA, NEXA, True Value, and Commercial.\n\n\nCompany Culture\nAt Maruti Suzuki, the work culture is rooted in teamwork, innovation, and continuous learning. The organization fosters an atmosphere that embraces diversity, encourages openness, and values employee contributions, ensuring that every voice is heard. Employees enjoy supportive policies aimed at professional growth and personal development, making Maruti Suzuki not just a workplace, but a vibrant community.\n\nWhy Work with Us?\n\nCareer Growth: We offer extensive training and mentorship programs to help you maximize your potential.\nEmployee Welfare: Benefits like subsidized meals, flexible work hours, and wellness programs ensure a healthy work-life balance.\nRecognition: Exceptional performance is acknowledged and rewarded, fostering a culture of excellence.\n\n\n\n\nCommitment to Sustainability\nMaruti Suzuki prioritizes environmental responsibility. The company invests in green technologies, striving to reduce its ecological footprint by developing eco-friendly vehicles and managing resources efficiently. The implementation of best practices in sustainability ensures Maruti Suzuki is not just a leader in manufacturing but also in eco-friendliness.\n\n\nCorporate Social Responsibility (CSR)\nMaruti Suzuki is dedicated to uplifting the communities it serves through various initiatives in education, health, and environmental conservation. The firm values corporate citizenship and actively engages in philanthropic efforts to promote societal well-being.\n\n\nCome Join Us\nMaruti Suzuki is always on the lookout for diverse talent to join its expanding team. Whether you are a fresh graduate, a seasoned professional, or looking for workmen hiring (ITI), Maruti Suzuki offers many opportunities across various functions and locations.\n\nCurrent Openings: Check out the careers page for fresh engineering graduates, experienced professionals, and apprentices.\nTraining Academy: Our in-house training program equips employees with the skills needed for success in the automotive industry.\n\n\n\nInnovation and Technology\nWith a strong focus on R&D, Maruti Suzuki leverages cutting-edge technology to enhance vehicle performance and efficiency. The company is committed to advancements in hybrid, Smart Hybrid, and CNG technology.\n\n\nContact Us\nFor inquiries or to learn more about our offerings, please visit our website or reach us at: - Phone: 1800 102 1800 - Email: contact@maruti.co.in\nJoin Maruti Suzuki in shaping the future of mobility in India. Drive change, drive innovation, drive with Maruti Suzuki!"
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#the-ai-community-building-the-future",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#the-ai-community-building-the-future",
    "title": "Building a Company Brochure with AI",
    "section": "The AI Community Building the Future",
    "text": "The AI Community Building the Future\nHugging Face is a pioneering company dedicated to democratizing machine learning and artificial intelligence. With over 1 million models and 250,000 datasets, we provide a collaborative platform for researchers, developers, and enthusiasts in the machine learning community to share, innovate, and advance the state of AI technology.\n\n\nWhat We Offer\nCollaboration Platform\nJoin a global network where you can create, discover, and collaborate on machine learning models, datasets, and applications.\n\nModels: Explore the latest trending models like Qwen/Qwen3 and DeepSeek-Prover.\nDatasets: Access a rich repository of datasets for any ML task, including OpenMathReasoning and OpenCodeReasoning.\nSpaces: Experiment and run applications in a user-friendly interface, optimized for development.\n\n\n\n\nWhy Choose Hugging Face?\n\nCommunity-Driven: Actively engage with more than 50,000 organizations including industry giants like Google, Amazon, and Microsoft who trust our platform.\nOpen Source: We believe in transparency and availability. Contribute to our models and explore extensive resources including Transformers, Tokenizers, and more.\nEnterprise Solutions: With specialized features for organizations, Hugging Face provides security, access controls, and prioritized support to help your team effectively build AI applications.\n\n\n\n\nCompany Culture\nWe are on a mission to democratize good machine learning, making it accessible for everyone involved in the AI ecosystem. Our community is composed of over 200 dedicated employees who continually contribute to fostering an inclusive and innovative work environment.\nWe encourage continuous learning, collaboration, and creativity, allowing our team members to thrive and push the boundaries of what‚Äôs possible in AI.\n\n\n\nCareer Opportunities\nWe‚Äôre constantly looking for talented individuals to join our dynamic team. If you‚Äôre passionate about AI, machine learning, or software development, consider exploring open positions with us. Dive into the world of cutting-edge AI technology and help us shape the future with your expertise.\n\nExplore Open Positions: Join our collaborative work environment that values innovation and learning.\n\n\n\n\nJoin Us!\nWhether you‚Äôre looking to leverage our powerful tools in your projects, become a part of our thriving community, or start a career with us, Hugging Face is the place to be.\nContact Us | Visit Our Website\nhuggingface - The AI community building the future."
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#overview",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#overview",
    "title": "Building a Company Brochure with AI",
    "section": "Overview",
    "text": "Overview\nMaruti Suzuki India Limited (MSIL) is the largest passenger vehicle manufacturer in India, recognized for its commitment to quality and reliability. Celebrated for manufacturing a wide array of cars, including hatchbacks, sedans, SUVs, and vans, Maruti Suzuki‚Äôs brands include ARENA, NEXA, True Value, and Commercial."
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#company-culture-1",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#company-culture-1",
    "title": "Building a Company Brochure with AI",
    "section": "Company Culture",
    "text": "Company Culture\nAt Maruti Suzuki, the work culture is rooted in teamwork, innovation, and continuous learning. The organization fosters an atmosphere that embraces diversity, encourages openness, and values employee contributions, ensuring that every voice is heard. Employees enjoy supportive policies aimed at professional growth and personal development, making Maruti Suzuki not just a workplace, but a vibrant community.\n\nWhy Work with Us?\n\nCareer Growth: We offer extensive training and mentorship programs to help you maximize your potential.\nEmployee Welfare: Benefits like subsidized meals, flexible work hours, and wellness programs ensure a healthy work-life balance.\nRecognition: Exceptional performance is acknowledged and rewarded, fostering a culture of excellence."
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#commitment-to-sustainability",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#commitment-to-sustainability",
    "title": "Building a Company Brochure with AI",
    "section": "Commitment to Sustainability",
    "text": "Commitment to Sustainability\nMaruti Suzuki prioritizes environmental responsibility. The company invests in green technologies, striving to reduce its ecological footprint by developing eco-friendly vehicles and managing resources efficiently. The implementation of best practices in sustainability ensures Maruti Suzuki is not just a leader in manufacturing but also in eco-friendliness."
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#corporate-social-responsibility-csr",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#corporate-social-responsibility-csr",
    "title": "Building a Company Brochure with AI",
    "section": "Corporate Social Responsibility (CSR)",
    "text": "Corporate Social Responsibility (CSR)\nMaruti Suzuki is dedicated to uplifting the communities it serves through various initiatives in education, health, and environmental conservation. The firm values corporate citizenship and actively engages in philanthropic efforts to promote societal well-being."
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#come-join-us",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#come-join-us",
    "title": "Building a Company Brochure with AI",
    "section": "Come Join Us",
    "text": "Come Join Us\nMaruti Suzuki is always on the lookout for diverse talent to join its expanding team. Whether you are a fresh graduate, a seasoned professional, or looking for workmen hiring (ITI), Maruti Suzuki offers many opportunities across various functions and locations.\n\nCurrent Openings: Check out the careers page for fresh engineering graduates, experienced professionals, and apprentices.\nTraining Academy: Our in-house training program equips employees with the skills needed for success in the automotive industry."
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#innovation-and-technology",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#innovation-and-technology",
    "title": "Building a Company Brochure with AI",
    "section": "Innovation and Technology",
    "text": "Innovation and Technology\nWith a strong focus on R&D, Maruti Suzuki leverages cutting-edge technology to enhance vehicle performance and efficiency. The company is committed to advancements in hybrid, Smart Hybrid, and CNG technology."
  },
  {
    "objectID": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#contact-us",
    "href": "projects/Building_a_Company_Brochure_with_AI/Building_a_Company_Brochure_with_AI.html#contact-us",
    "title": "Building a Company Brochure with AI",
    "section": "Contact Us",
    "text": "Contact Us\nFor inquiries or to learn more about our offerings, please visit our website or reach us at: - Phone: 1800 102 1800 - Email: contact@maruti.co.in\nJoin Maruti Suzuki in shaping the future of mobility in India. Drive change, drive innovation, drive with Maruti Suzuki!"
  },
  {
    "objectID": "projects/Brand Detection/Brand_Detection.html",
    "href": "projects/Brand Detection/Brand_Detection.html",
    "title": "Brand Detection",
    "section": "",
    "text": "Brand Detection\nVisual content, such as videos and images, plays a significant role in modern-day marketing. Traditionally, brands have had to pay content creators to feature their brand logo in their content. However, marketers can now leverage ML-powered computer vision to identify and recognize their products in various forms of content, including videos and images. This technology enables marketers to extract valuable insights from the content and understand the audience‚Äôs behaviour better. With this understanding, brands can improve their advertising strategies and achieve higher ROI by targeting their audience more effectively and personalizing their messaging. The potential benefits of ML-powered computer vision in marketing make it an exciting area of exploration for brands and marketers.\n\n\n\nimage\n\n\n\n\nInstruction to train the model in Google Colab\n!rm -r /content/sample_data; # remove the sample directory from google colab\n!git clone https://github.com/07Sada/brand.git # clone the repository\n# change the directory\n%cd /content/brand \n# install the requirements\n%pip install -r /content/brand/requirements.txt -q\n# initiate the training\nfrom BrandRecognition.pipeline.training_pipeline import TrainPipeline\nobj = TrainPipeline()\nobj.run_pipeline()\n\n\nScreenshots\n\n\n\nimage\n\n\n\n\nDemo\n\n\n\nPoject_video_#01\n\n\n\n\n\nPoject_video_#02"
  },
  {
    "objectID": "projects/computer_vison_project/Vegetable_Recognition.html",
    "href": "projects/computer_vison_project/Vegetable_Recognition.html",
    "title": "Vegetable Recognition",
    "section": "",
    "text": "This notebook demonstrates a deep learning approach to classifying vegetable types from images, a task with applications in agriculture and retail. The model is built using PyTorch and features a custom ResNet9 architecture tailored for effective image classification. The notebook outlines the key steps in data preprocessing, model architecture, training, and evaluation, providing a comprehensive walkthrough of the process."
  },
  {
    "objectID": "projects/computer_vison_project/Vegetable_Recognition.html#downloading-the-dataset",
    "href": "projects/computer_vison_project/Vegetable_Recognition.html#downloading-the-dataset",
    "title": "Vegetable Recognition",
    "section": "Downloading the dataset",
    "text": "Downloading the dataset\n\n\nCode\n# installing opendatasets to download the dataset from kaggle\n%pip install opendatasets -q\n\n\n\n\nCode\n# installing albumentations library for image transformation\n%pip install albumentations -q\n\n\n\n\nCode\n# importing opendatasets\nimport opendatasets as od\n\n# dataset url path\nurl = \"https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset?datasetId=1817999&sortBy=voteCount\"\n\n# download the dataset\nod.download(url)\n\n\nDownloading vegetable-image-dataset.zip to ./vegetable-image-dataset\n\n\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 534M/534M [00:04&lt;00:00, 117MB/s]\n\n\n\n\n\n\n\nCode\n# imorting dependancies\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport albumentations as A\nimport torch\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport torch.nn as nn\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset\nimport os\n\n\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "projects/computer_vison_project/Vegetable_Recognition.html#introduction-to-dataset",
    "href": "projects/computer_vison_project/Vegetable_Recognition.html#introduction-to-dataset",
    "title": "Vegetable Recognition",
    "section": "Introduction to Dataset",
    "text": "Introduction to Dataset\n\n\nCode\n# dataset path\nDATASET_PATH = \"./vegetable-image-dataset/Vegetable Images\"\nTRAIN_DATASET = DATASET_PATH + '/train'\nVALIDATION_DATASET = DATASET_PATH + '/validation'\n\nprint(f\"Total Categories in the dataset: {len(os.listdir(TRAIN_DATASET))}\")\n\nCATEGORIES_COUNT = {}\nCATEGORIES_LIST = os.listdir(TRAIN_DATASET)\n\nfor i in CATEGORIES_LIST:\n  CATEGORIES_COUNT[i] = len(os.listdir(str(TRAIN_DATASET) + \"/\" +str(i)))\n\nprint(CATEGORIES_COUNT)\nprint('\\n')\n\nCATEGORIES_COUNT = list(CATEGORIES_COUNT.values())\nplt.pie(CATEGORIES_COUNT, labels=CATEGORIES_LIST, autopct='%1.1f%%');\n\n\nTotal Categories in the dataset: 15\n{'Cucumber': 1000, 'Capsicum': 1000, 'Papaya': 1000, 'Tomato': 1000, 'Cabbage': 1000, 'Pumpkin': 1000, 'Bitter_Gourd': 1000, 'Radish': 1000, 'Broccoli': 1000, 'Cauliflower': 1000, 'Bean': 1000, 'Carrot': 1000, 'Bottle_Gourd': 1000, 'Potato': 1000, 'Brinjal': 1000}"
  },
  {
    "objectID": "projects/computer_vison_project/Vegetable_Recognition.html#importing-the-dataset-into-pytorch",
    "href": "projects/computer_vison_project/Vegetable_Recognition.html#importing-the-dataset-into-pytorch",
    "title": "Vegetable Recognition",
    "section": "Importing the dataset into pytorch",
    "text": "Importing the dataset into pytorch\n\n\nCode\n# importing pytorch\nimport torch\n\n# checking the version of the torch\nprint(f\"torch version: {torch.__version__}\")\n\n# Importing Imagefolder\nfrom torchvision.datasets import ImageFolder\n\n\ntorch version: 2.0.1+cu118\n\n\n\n\nCode\ntrain_dataset = ImageFolder(root=TRAIN_DATASET)\n\n# total images in the train_dataset\nprint(f\"Total images in train dataset: {len(train_dataset)}\\n\")\n\n# checking sample image from the train dataset\nimg, label = train_dataset[10]\n\nprint(f\"Sample image from train dataset\")\nplt.imshow(img)\nplt.axis('OFF');\n\n\nTotal images in train dataset: 15000\n\nSample image from train dataset\n\n\n\n\n\n\n\n\n\n\n\nCode\nvalidation_dataset = ImageFolder(root=VALIDATION_DATASET)\n\n# total images in the validation_dataset\nprint(f\"Total images in train dataset: {len(validation_dataset)}\\n\")\n\n# checking sample image from the train dataset\nimg, label = validation_dataset[2000]\n\nprint(f\"Sample image from validation_dataset\")\nplt.imshow(img)\nplt.axis('OFF');\n\n\nTotal images in train dataset: 3000\n\nSample image from validation_dataset\n\n\n\n\n\n\n\n\n\nImage transformation\n\n\nCode\n# Creating a class for image transformation with albumentations library\nclass ImageFolder(Dataset):\n    def __init__(self, root_dir, transform=None):\n        super(ImageFolder, self).__init__()\n        self.data = []\n        self.root_dir = root_dir\n        self.transform = transform\n        self.class_names = os.listdir(root_dir)\n\n        for index, name in enumerate(self.class_names):\n            files = os.listdir(os.path.join(root_dir, name))\n            self.data += list(zip(files, [index] * len(files)))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        img_file, label = self.data[index]\n        root_and_dir = os.path.join(self.root_dir, self.class_names[label])\n        image = np.array(Image.open(os.path.join(root_and_dir, img_file)))\n\n        if self.transform is not None:\n            augmentations = self.transform(image=image)\n            image = augmentations[\"image\"]\n\n        return image, label\n\n\ntransform = A.Compose(\n    [\n        A.Resize(width=64, height=64),\n        A.Rotate(limit=40, p=0.9, border_mode=cv2.BORDER_CONSTANT),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.1),\n        A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25, p=0.9),\n        A.OneOf(\n            [\n                A.Blur(blur_limit=3, p=0.5),\n                A.ColorJitter(p=0.5),\n            ],\n            p=1.0,\n        ),\n        A.Normalize(\n            mean=[0, 0, 0],\n            std=[1, 1, 1],\n            max_pixel_value=255,\n        ),\n        ToTensorV2(),\n    ]\n)\n\n\n\n\nCode\n# Applying transformation on training_dataset and validation_dataset\ntrain_dataset = ImageFolder(root_dir=TRAIN_DATASET, transform=transform)\nvalidation_dataset = ImageFolder(root_dir=VALIDATION_DATASET, transform=transform)\n\n\n\n\nCode\n# checking a random image from train_dataset\nimg, label = train_dataset[100]\n\nprint(f\"Shape of the image: {img.shape}\") # checking the size of the image\n\nprint(\"\\nThe image after transformation\")\nprint(train_dataset[100]) # the pixel values are noramalized\nprint(\"\\n\")\n\nprint(f\"Sample image\")\nplt.imshow(img.permute((1,2,0))); #This module returns a view of the tensor input with its dimensions permuted.\n\n\nShape of the image: torch.Size([3, 64, 64])\n\nThe image after transformation\n(tensor([[[0.7098, 0.6980, 0.7216,  ..., 0.6157, 0.6000, 0.6118],\n         [0.7137, 0.7020, 0.7255,  ..., 0.6157, 0.5922, 0.5961],\n         [0.7216, 0.7098, 0.7255,  ..., 0.6078, 0.5686, 0.5686],\n         ...,\n         [0.7765, 0.7804, 0.8000,  ..., 0.7490, 0.7922, 0.7882],\n         [0.7686, 0.7882, 0.8235,  ..., 0.7843, 0.7882, 0.7843],\n         [0.7569, 0.7843, 0.8275,  ..., 0.8078, 0.7843, 0.7843]],\n\n        [[0.6431, 0.6392, 0.6706,  ..., 0.4431, 0.4353, 0.4353],\n         [0.6510, 0.6431, 0.6745,  ..., 0.4392, 0.4314, 0.4314],\n         [0.6627, 0.6510, 0.6706,  ..., 0.4314, 0.4196, 0.4196],\n         ...,\n         [0.6078, 0.6039, 0.6039,  ..., 0.6627, 0.7098, 0.7059],\n         [0.5804, 0.5804, 0.5725,  ..., 0.6980, 0.7059, 0.6980],\n         [0.5725, 0.5686, 0.5529,  ..., 0.7255, 0.6980, 0.7020]],\n\n        [[0.8235, 0.8118, 0.8431,  ..., 0.4627, 0.4667, 0.4627],\n         [0.8275, 0.8196, 0.8471,  ..., 0.4588, 0.4627, 0.4588],\n         [0.8392, 0.8275, 0.8431,  ..., 0.4471, 0.4549, 0.4549],\n         ...,\n         [0.6353, 0.6314, 0.6275,  ..., 0.7647, 0.8039, 0.7961],\n         [0.6078, 0.6078, 0.5922,  ..., 0.8000, 0.7961, 0.7804],\n         [0.5961, 0.5922, 0.5725,  ..., 0.8235, 0.7882, 0.7765]]]), 0)\n\n\nSample image"
  },
  {
    "objectID": "projects/computer_vison_project/Vegetable_Recognition.html#dataloader",
    "href": "projects/computer_vison_project/Vegetable_Recognition.html#dataloader",
    "title": "Vegetable Recognition",
    "section": "DataLoader",
    "text": "DataLoader\n\n\nCode\n# importing DataLoader\nfrom torch.utils.data import DataLoader\n\nBATCH_SIZE = 32\nNUM_WORKERS = os.cpu_count()\n\nprint(f\"cpu_count in machine: {NUM_WORKERS}\")\n\n# dataloader for training dataset\ntrain_dataloader = DataLoader(dataset = train_dataset,\n                              batch_size=BATCH_SIZE,\n                              num_workers=NUM_WORKERS,\n                              shuffle=True)\n\n# dataloader for validation dataset\nvalidation_dataloader = DataLoader(dataset=validation_dataset,\n                                   batch_size=BATCH_SIZE,\n                                   num_workers=NUM_WORKERS,\n                                   shuffle=False)\n\n\ncpu_count in machine: 2\n\n\n\n\nCode\n# Get image and label from train_dataloader\ntrain_dataloder_img, train_dataloder_label = next(iter(train_dataloader))\n\n# Print out the shapes\ntrain_dataloder_img.shape, train_dataloder_label.shape\n\n\n(torch.Size([32, 3, 64, 64]), torch.Size([32]))"
  },
  {
    "objectID": "projects/computer_vison_project/Vegetable_Recognition.html#visualize-some-images-from-dataloader",
    "href": "projects/computer_vison_project/Vegetable_Recognition.html#visualize-some-images-from-dataloader",
    "title": "Vegetable Recognition",
    "section": "Visualize some images from dataloader",
    "text": "Visualize some images from dataloader\n\n\nCode\nfrom torchvision.utils import make_grid # Make a grid of images.\n\ndef show_batch(data_loader):\n  for images, labels in data_loader:\n    fig, ax = plt.subplots(figsize = (15,8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n    break\n\nshow_batch(train_dataloader)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# device setup\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\n\n'cuda'"
  },
  {
    "objectID": "projects/computer_vison_project/Vegetable_Recognition.html#model-training",
    "href": "projects/computer_vison_project/Vegetable_Recognition.html#model-training",
    "title": "Vegetable Recognition",
    "section": "Model Training",
    "text": "Model Training\n\n\nCode\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Create class for model training and evaluation\nclass ImageClassificationBase(nn.Module): ## --&gt; nn.Module--&gt; Base class for all neural network modules. --&gt; https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\n  def training_step(self, batch):\n    images, labels = batch\n    images, labels = images.to(device), labels.to(device)\n    out = self(images) # Generate predictions\n    loss = F.cross_entropy(input= out, # Predicted unnormalized logits\n                           target = labels) # Ground truth class indices or class probabilities\n    return loss\n\n  def validation_step(self, batch):\n    images, labels = batch\n    images, labels = images.to(device), labels.to(device)\n    out = self(images) # Generate predictions\n    loss = F.cross_entropy(input = out, # Predicted unnormalized logits\n                           target = labels) # Ground truth class indices or class probabilities\n    acc = accuracy(outputs = out, # Calculate the accuracy\n                   labels = labels)\n    return {'validation_loss': loss.detach(), 'validation_accuracy':acc}\n\n  def validation_epoch_end(self, outputs):\n    batch_losses = [x['validation_loss'] for x in outputs]\n    # combine the losses\n    epoch_loss = torch.stack(batch_losses).mean() # PyTorch torch.stack() method joins (concatenates) a sequence of tensors (two or more tensors) along a new dimension.\n    batch_accuracy = [x['validation_accuracy'] for x in outputs]\n    epoch_accuracy = torch.stack(batch_accuracy).mean()\n    return {'validation_loss':epoch_loss.item(), 'validation_accuracy':epoch_accuracy.item()}\n\n  # printing the results\n  def epoch_end(self, epoch, result):\n    print(f\"Epoch {epoch},\\n train_loss:{result['train_loss']}, \\n validation_loss: {result['validation_loss']}, \\n validation_accuracy: {result['validation_accuracy']}\")\n\ndef accuracy(outputs, labels):\n  _, preds = torch.max(outputs, dim=1)\n  return torch.tensor(torch.sum(preds == labels).item()/ len(preds))\n\n\n\n\nCode\n@torch.no_grad() # Context-manager that disabled gradient calculation.\n\ndef evaluate(model, validation_dataloader):\n  \"\"\" Evaluate the model's performance on the validation dataset\"\"\"\n  model.eval()\n  outputs = [model.validation_step(batch) for batch in validation_dataloader]\n  return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n  history = []\n  optimizer = opt_func(model.parameters(), lr)\n  for epoch in range(epochs):\n    # training\n    model.train()\n    train_loss = []\n    for batch in train_loader:\n      loss = model.training_step(batch) # training the model for each batch\n      train_loss.append(loss) # collecting the loss\n      loss.backward() # Computes the gradient of current tensor w.r.t. graph leaves.--&gt; https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch-tensor-backward\n      optimizer.step() # Performs a single optimization step (parameter update). --&gt; https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html\n      optimizer.zero_grad() # Sets the gradients of all optimized torch.Tensor s to zero. --&gt; https://stackoverflow.com/a/48009142\n                            # official_doc --&gt; https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\n\n    # validation\n    result = evaluate(model, validation_dataloader)\n    result['train_loss'] = torch.stack(train_loss).mean().item()\n    history.append(result)\n  return history\n\n\n\n\nCode\n##Model Building\ndef conv_block(in_channels, out_channels, pool=False):\n\n  layers = [nn.Conv2d(in_channels=in_channels,    # Number of channels in the input image\n                      out_channels=out_channels,  # Number of channels produced by the convolution\n                      kernel_size=3, # Size of the convolving kernel\n                      padding=1), # Padding added to all four sides of the input\n            nn.BatchNorm2d(num_features=out_channels), # num_features (int)--&gt;'C'from an expected input of size (N,C,H,W) --&gt; https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d\n            nn.ReLU(inplace =True)] #-&gt; https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu\n  if pool: layers.append(nn.MaxPool2d(kernel_size=2)) # --&gt; https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\n  return nn.Sequential(*layers)\n\n\n\n\nCode\nclass ResNet9(ImageClassificationBase):\n  def __init__(self, in_channels, num_classes):\n    super().__init__()\n    # input: 32 x 3 x 64 x 64\n    self.conv1 = conv_block(in_channels, 64) # 32 x 64 x 64 x 64\n    self.conv2 = conv_block(64, 128, pool=True) # 32 x 128 x 32 x 32\n    self.res1 = nn.Sequential(conv_block(128, 128), # 32 x 128 x 32 x 32\n                              conv_block(128, 128)) # 32 x 128 x 32 x 32\n\n    self.conv3 = conv_block(128, 256, pool=True) # 32 X 256 x 16 x 16\n    self.conv4 = conv_block(256, 512, pool=True) # 32 x 256 x 8 x 8\n    self.res2 = nn.Sequential(conv_block(512, 512), # 32 x 512 x 8 x 8 --&gt; residual_blocks --&gt; ## https://towardsdatascience.com/resnets-residual-blocks-deep-residual-learning-a231a0ee73d2#:~:text=A%20residual%20block%20is%20a,layer%20in%20the%20main%20path.\n                              conv_block(512, 512)) # 32 x 512 x 8 x 8\n\n    self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d(1), # 32 x 512 x 1 x 1 --&gt; official_documenataion --&gt;https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html#torch.nn.AdaptiveMaxPool2d --&gt; simplified_version--&gt; https://stackoverflow.com/a/55869581\n                                    nn.Flatten(), # Flattens a contiguous range of dims into a tensor --&gt; https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten --&gt;simplified_version --&gt; https://www.tutorialspoint.com/how-to-flatten-an-input-tensor-by-reshaping-it-in-pytorch\n                                    nn.Dropout(0.2), # During training, randomly zeroes some of the elements of the input tensor --&gt; https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout --&gt; https://www.geeksforgeeks.org/dropout-in-neural-networks/\n                                    nn.Linear(in_features = 512,\n                                              out_features = num_classes)) # Applies a linear transformation to the incoming data --&gt;https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear --&gt;https://stackoverflow.com/a/54924812\n\n  def forward(self, xb):\n    out = self.conv1(xb)\n    out = self.conv2(out)\n    out = self.res1(out) + out\n    out = self.conv3(out)\n    out = self.conv4(out)\n    out = self.res2(out) + out\n    out = self.classifier(out)\n    return out\n\n\n\n\nCode\nmodel = ResNet9(3, len(train_dataset.class_names)).to(device)\nmodel\n\n\nResNet9(\n  (conv1): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (res1): Sequential(\n    (0): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (conv3): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv4): Sequential(\n    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (res2): Sequential(\n    (0): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (classifier): Sequential(\n    (0): AdaptiveAvgPool2d(output_size=1)\n    (1): Flatten(start_dim=1, end_dim=-1)\n    (2): Dropout(p=0.2, inplace=False)\n    (3): Linear(in_features=512, out_features=15, bias=True)\n  )\n)\n\n\n\n\nCode\n# Install torchinfo, import if it's available\n# Torchinfo provides information complementary to what is provided by print(your_model) in PyTorch,\n# similar to Tensorflow's model.summary() API to view the visualization of the model, which is helpful while debugging your network.\n\ntry:\n  import torchinfo\nexcept:\n  !pip install torchinfo\n  import torchinfo\n\nfrom torchinfo import summary\nsummary(model, input_size=[1, 3, 64, 64])\n\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting torchinfo\n  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\nInstalling collected packages: torchinfo\nSuccessfully installed torchinfo-1.8.0\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nResNet9                                  [1, 15]                   --\n‚îú‚îÄSequential: 1-1                        [1, 64, 64, 64]           --\n‚îÇ    ‚îî‚îÄConv2d: 2-1                       [1, 64, 64, 64]           1,792\n‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                  [1, 64, 64, 64]           128\n‚îÇ    ‚îî‚îÄReLU: 2-3                         [1, 64, 64, 64]           --\n‚îú‚îÄSequential: 1-2                        [1, 128, 32, 32]          --\n‚îÇ    ‚îî‚îÄConv2d: 2-4                       [1, 128, 64, 64]          73,856\n‚îÇ    ‚îî‚îÄBatchNorm2d: 2-5                  [1, 128, 64, 64]          256\n‚îÇ    ‚îî‚îÄReLU: 2-6                         [1, 128, 64, 64]          --\n‚îÇ    ‚îî‚îÄMaxPool2d: 2-7                    [1, 128, 32, 32]          --\n‚îú‚îÄSequential: 1-3                        [1, 128, 32, 32]          --\n‚îÇ    ‚îî‚îÄSequential: 2-8                   [1, 128, 32, 32]          --\n‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                  [1, 128, 32, 32]          147,584\n‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-2             [1, 128, 32, 32]          256\n‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-3                    [1, 128, 32, 32]          --\n‚îÇ    ‚îî‚îÄSequential: 2-9                   [1, 128, 32, 32]          --\n‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-4                  [1, 128, 32, 32]          147,584\n‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-5             [1, 128, 32, 32]          256\n‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-6                    [1, 128, 32, 32]          --\n‚îú‚îÄSequential: 1-4                        [1, 256, 16, 16]          --\n‚îÇ    ‚îî‚îÄConv2d: 2-10                      [1, 256, 32, 32]          295,168\n‚îÇ    ‚îî‚îÄBatchNorm2d: 2-11                 [1, 256, 32, 32]          512\n‚îÇ    ‚îî‚îÄReLU: 2-12                        [1, 256, 32, 32]          --\n‚îÇ    ‚îî‚îÄMaxPool2d: 2-13                   [1, 256, 16, 16]          --\n‚îú‚îÄSequential: 1-5                        [1, 512, 8, 8]            --\n‚îÇ    ‚îî‚îÄConv2d: 2-14                      [1, 512, 16, 16]          1,180,160\n‚îÇ    ‚îî‚îÄBatchNorm2d: 2-15                 [1, 512, 16, 16]          1,024\n‚îÇ    ‚îî‚îÄReLU: 2-16                        [1, 512, 16, 16]          --\n‚îÇ    ‚îî‚îÄMaxPool2d: 2-17                   [1, 512, 8, 8]            --\n‚îú‚îÄSequential: 1-6                        [1, 512, 8, 8]            --\n‚îÇ    ‚îî‚îÄSequential: 2-18                  [1, 512, 8, 8]            --\n‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-7                  [1, 512, 8, 8]            2,359,808\n‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-8             [1, 512, 8, 8]            1,024\n‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-9                    [1, 512, 8, 8]            --\n‚îÇ    ‚îî‚îÄSequential: 2-19                  [1, 512, 8, 8]            --\n‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                 [1, 512, 8, 8]            2,359,808\n‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-11            [1, 512, 8, 8]            1,024\n‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-12                   [1, 512, 8, 8]            --\n‚îú‚îÄSequential: 1-7                        [1, 15]                   --\n‚îÇ    ‚îî‚îÄAdaptiveAvgPool2d: 2-20           [1, 512, 1, 1]            --\n‚îÇ    ‚îî‚îÄFlatten: 2-21                     [1, 512]                  --\n‚îÇ    ‚îî‚îÄDropout: 2-22                     [1, 512]                  --\n‚îÇ    ‚îî‚îÄLinear: 2-23                      [1, 15]                   7,695\n==========================================================================================\nTotal params: 6,577,935\nTrainable params: 6,577,935\nNon-trainable params: 0\nTotal mult-adds (G): 1.52\n==========================================================================================\nInput size (MB): 0.05\nForward/backward pass size (MB): 24.12\nParams size (MB): 26.31\nEstimated Total Size (MB): 50.48\n==========================================================================================\n\n\n\n\nCode\ntorch.cuda.empty_cache() # Releases all unoccupied cached memory currently held by the caching allocator so that those can be used in other GPU application and visible in nvidia-smi.\n# official documentation --&gt; https://pytorch.org/docs/stable/generated/torch.cuda.empty_cache.html#torch.cuda.empty_cache\n\nfor batch in train_dataloader:\n  images, labels = batch\n  print(f\"image shape: \", images.shape)\n  print(f\"images device: \", images.device)\n  preds = model(images.to(device))\n  print('preds.shape', preds.shape)\n  break\n\n\nimage shape:  torch.Size([32, 3, 64, 64])\nimages device:  cpu\npreds.shape torch.Size([32, 15])\n\n\n\n\nCode\nhistory = [evaluate(model.to(device),\n                    validation_dataloader)]\nhistory\n\n\n[{'validation_loss': 2.708531379699707,\n  'validation_accuracy': 0.06648936122655869}]\n\n\n\n\nCode\nhistory += fit(epochs=5,\n               lr=0.01,\n               model=model,\n               train_loader=train_dataloader,\n               val_loader=validation_dataloader,\n               opt_func=torch.optim.Adam)\n\n\n\n\nCode\ndef plot_accuracies(history):\n    accuracies = [x['validation_accuracy'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\nplot_accuracies(history)\n\n\n\n\n\n\n\n\n\n\n\nCode\nhistory += fit(epochs=10,\n               lr=0.01,\n               model=model,\n               train_loader=train_dataloader,\n               val_loader=validation_dataloader,\n               opt_func=torch.optim.Adam)\n\n\n\n\nCode\ndef plot_accuracies(history):\n    accuracies = [x['validation_accuracy'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')\n    plt.grid(True);  # Add grid lines\n\nplot_accuracies(history)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['validation_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)\n\n\n\n\n\n\n\n\n\n\n\nCode\nxb = img.unsqueeze(0).to(device)\n\n\n\n\nCode\n# Test with individual Images\ndef predict_image(img, model, classes):\n  # convert to a batch of 1\n  xb = img.unsqueeze(0).to(device) # It returns a new tensor with a dimension of size one inserted at the specified position dim. --&gt; https://www.geeksforgeeks.org/how-to-squeeze-and-unsqueeze-a-tensor-in-pytorch/\n  # Get the prediction from the model\n  yb = model(xb)\n  # pick index with highest probability\n  _, preds = torch.max(yb, dim=1)\n  # Retreive the class label\n  return classes[preds[0].item()]\n\n\n\n\nCode\ndef show_image_prediction(img, label):\n  plt.imshow(img.permute(1,2,0)) # Returns a view of the original tensor input with its dimensions permuted.--&gt;https://pytorch.org/docs/stable/generated/torch.permute.html#torch.permute\n  pred = predict_image(img, model, dataset.classes)\n  print(\"Target:\", dataset.classes[label])\n  print('Prediction:', pred)\n\n\n\n\nCode\nshow_image_prediction(*validation_dataset[23])\n\n\nTarget: Bean\nPrediction: Bean\n\n\n\n\n\n\n\n\n\n\n\nCode\nimg, _ = validation_dataset[23]\nplt.imshow(img.permute(1,2,0))\n\n\n\n\n\n\n\n\n\n\n\nCode\ndummy_input = torch.randn(1, 3, 64, 64).to(device)\ninput_names = [ \"actual_input\" ]\noutput_names = [ \"output\" ]\n\n\n\n\nCode\n!pip install onnx\n\n\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n\nCollecting onnx\n\n  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 14.6/14.6 MB 86.8 MB/s eta 0:00:00\n\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.4)\n\nRequirement already satisfied: protobuf&gt;=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n\nRequirement already satisfied: typing-extensions&gt;=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n\nInstalling collected packages: onnx\n\nSuccessfully installed onnx-1.14.0\n\n\n\n\n\n\nCode\ntorch.onnx.export(model,\n                 dummy_input,\n                 \"ResNet9.onnx\",\n                 verbose=False,\n                 export_params=True,\n                 )\n\n\n============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n\n\n\n\nCode\n!pip install onnxruntime -q\n\n\n\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0.0/5.9 MB ? eta -:--:--\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∫ 5.8/5.9 MB 174.3 MB/s eta 0:00:01\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.9/5.9 MB 93.9 MB/s eta 0:00:00\n\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46.0/46.0 kB 5.6 MB/s eta 0:00:00\n\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 86.8/86.8 kB 11.2 MB/s eta 0:00:00\n\n\n\n\n\n\n\nCode\nimport onnxruntime\nimport numpy as np\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Load the ONNX model\nmodel_path = 'ResNet9.onnx'\nsession = onnxruntime.InferenceSession(model_path)\n\n# Define the image transformation function\ndef image_transformation(img):\n    # Open the image\n    image = Image.open(img)\n\n    # Define the transformations\n    transform = transforms.Compose([\n        transforms.Resize((64, 64)),\n        transforms.ToTensor()\n    ])\n\n    # Apply the transformations to the image\n    transformed_image = transform(image)\n\n    return transformed_image\n\n# Define the class labels\nclass_labels = ['Cucumber', 'Capsicum', 'Papaya', 'Tomato', 'Cabbage', 'Pumpkin', 'Bitter_Gourd',\n                'Radish', 'Broccoli', 'Cauliflower', 'Bean', 'Carrot', 'Bottle_Gourd', 'Potato', 'Brinjal']\n\n# Define the function for inference and displaying the image\ndef infer_and_display_image(image_path):\n    # Perform inference\n    input_image = image_transformation(image_path)\n    input_tensor = np.expand_dims(input_image, axis=0)\n\n    # Run inference\n    input_name = session.get_inputs()[0].name\n    output_name = session.get_outputs()[0].name\n    output = session.run([output_name], {input_name: input_tensor})\n\n    # Postprocess the output\n    output = output[0]\n    predicted_class_index = np.argmax(output)\n    predicted_class = class_labels[predicted_class_index]\n\n    # Display the image\n    image = Image.open(image_path)\n    plt.imshow(image)\n\n    # Print the predicted class\n    print(\"Predicted class:\", predicted_class)\n\n\n\n\n\n\nCode\n# Call the function with the image path\nimage_path = '/content/vegetable-image-dataset/Vegetable Images/validation/Carrot/1202.jpg'\ninfer_and_display_image(image_path)\n\n\nPredicted class: Carrot\n\n\n\n\n\n\n\n\n\n\n\nCode\nimage_path = '/content/vegetable-image-dataset/Vegetable Images/validation/Pumpkin/1209.jpg'\ninfer_and_display_image(image_path)\n\n\nPredicted class: Pumpkin"
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blogs",
    "section": "",
    "text": "Accessing Ollama in Free Google Colab Session\n\n\n\n\n\n\n\n\nMay 3, 2025\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1 Web Scraping and AI Summarization\n\n\n\n\n\n\n\n\nMay 3, 2025\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Actions Continuous Integration CI\n\n\n\n\n\n\n\n\nDec 3, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Actions Introduction\n\n\n\n\n\n\n\n\nDec 2, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nNatural Language Processing(NLP)\n\n\n\n\n\n\n\n\nNov 27, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nChi Square Test\n\n\n\n\n\n\n\n\nNov 21, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nSupport Vector Machines\n\n\n\n\n\n\n\n\nNov 20, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nSupervised Learning Algorithms\n\n\n\n\n\n\n\n\nNov 19, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nUnsupervised Learning Algorithms\n\n\n\n\n\n\n\n\nNov 19, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Docker\n\n\n\n\n\n\n\n\nNov 18, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nFeature Selection Techniques in Machine Learning\n\n\n\n\n\n\n\n\nSep 30, 2024\n\n\nSadashiv\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Algorithm\n\n\n\n\n\n\n\n\nSep 26, 2024\n\n\nSadashiv\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sadashiv Nandanikar",
    "section": "",
    "text": "Data Scientist @ Maruti Suzuki India Limited.\nExperienced Data Scientist | Machine Learning Specialist with a proven track record of driving business growth through data-driven insights, advanced analytics, and Python expertise."
  },
  {
    "objectID": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html",
    "href": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html",
    "title": "Feature Selection Techniques in Machine Learning",
    "section": "",
    "text": "Feature selection is a way of selecting the subset of the most relevant features from the original features set by removing the redundant, irrelevant, or noisy features.\nLet‚Äôs first understand some basics of feature selection."
  },
  {
    "objectID": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html#what-is-feature-selection",
    "href": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html#what-is-feature-selection",
    "title": "Feature Selection Techniques in Machine Learning",
    "section": "What is Feature Selection?",
    "text": "What is Feature Selection?\nA¬†feature is an attribute that has an impact on a problem or is useful for the problem, and choosing the important features for the model is known as feature selection.\nEach machine learning process depends on feature engineering, which mainly contains two processes; which are Feature Selection and Feature Extraction. Although feature selection and extraction processes may have the same objective, both are completely different from each other.\n\nThe main difference between them is that feature selection is about selecting the subset of the original feature set, whereas feature extraction creates new features.\nFeature selection is a way of reducing the input variable for the model by using only relevant data in order to reduce overfitting in the model.\n\nSo, we can define feature Selection as, ‚ÄúIt is a process of automatically or manually selecting the subset of most appropriate and relevant features to be used in model building.‚Äù Feature selection is performed by either including the important features or excluding the irrelevant features in the dataset without changing them."
  },
  {
    "objectID": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html#need-for-feature-selection",
    "href": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html#need-for-feature-selection",
    "title": "Feature Selection Techniques in Machine Learning",
    "section": "Need for Feature Selection",
    "text": "Need for Feature Selection\n\nAs we know, in machine learning, it is necessary to provide a pre-processed and good input dataset in order to get better outcomes. We collect a huge amount of data to train our model and help it to learn better.\nGenerally, the dataset consists of noisy data, irrelevant data, and some part of useful data.\nMoreover, the huge amount of data also slows down the training process of the model, and with noise and irrelevant data, the model may not predict and perform well.\nSo, it is very necessary to remove such noises and less-important data from the dataset and to do this, and Feature selection techniques are used.\n\nSelecting the best features helps the model to perform well. For example, Suppose we want to create a model that automatically decides which car should be crushed for a spare part, and to do this, we have a dataset. This dataset contains a Model of the car, Year, Owner‚Äôs name, Miles. So, in this dataset, the name of the owner does not contribute to the model performance as it does not decide if the car should be crushed or not, so we can remove this column and select the rest of the features(column) for the model building.\nBelow are some benefits of using feature selection in machine learning: - It helps in avoiding the [[Curse of Dimensionality]]. - It helps in the simplification of the model so that it can be easily interpreted by the researchers. - It reduces the training time. - It reduces overfitting hence enhance the generalization."
  },
  {
    "objectID": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html#feature-selection-techniques",
    "href": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html#feature-selection-techniques",
    "title": "Feature Selection Techniques in Machine Learning",
    "section": "Feature Selection Techniques",
    "text": "Feature Selection Techniques\nThere are mainly two types of Feature Selection techniques, which are: - Supervised Feature Selection technique Supervised Feature selection techniques consider the target variable and can be used for the labelled dataset. - Unsupervised Feature Selection technique Unsupervised Feature selection techniques ignore the target variable and can be used for the unlabeled dataset.\n\n\n\nFeature_Selection_Techniques_Drawing\n\n\nThere are mainly three techniques under supervised feature Selection:\n\n1. Wrapper Methods\nIn wrapper methodology, selection of features is done by considering it as a search problem, in which different combinations are made, evaluated, and compared with other combinations. It trains the algorithm by using the subset of features iteratively.\n\nOn the basis of the output of the model, features are added or subtracted, and with this feature set, the model has trained again.\nSome techniques of wrapper methods are:\n\nForward selection: Forward selection is an iterative process, which begins with an empty set of features. After each iteration, it keeps adding on a feature and evaluates the performance to check whether it is improving the performance or not. The process continues until the addition of a new variable/feature does not improve the performance of the model. ^71dca8\nBackward elimination: Backward elimination is also an iterative approach, but it is the opposite of forward selection. This technique begins the process by considering all the features and removes the least significant feature. This elimination process continues until removing the features does not improve the performance of the model.\nExhaustive Feature Selection: Exhaustive feature selection is one of the best feature selection methods, which evaluates each feature set as brute-force. It means this method tries & make each possible combination of features and return the best performing feature set.\nRecursive Feature Elimination: Recursive feature elimination is a recursive greedy optimization approach, where features are selected by recursively taking a smaller and smaller subset of features. Now, an estimator is trained with each set of features, and the importance of each feature is determined using¬†coef_attribute¬†or through a¬†_feature_importances_attribute.\n\n\n\n2. Filter Methods\nIn Filter Method, features are selected on the basis of statistics measures. This method does not depend on the learning algorithm and chooses the features as a pre-processing step.\nThe filter method filters out the irrelevant feature and redundant columns from the model by using different metrics through ranking.\nThe advantage of using filter methods is that it needs low computational time and does not overfit the data.\n\nSome common techniques of Filter methods are as follows:\n\nInformation Gain: Information gain determines the reduction in entropy while transforming the dataset. It can be used as a feature selection technique by calculating the information gain of each variable with respect to the target variable.\nChi-square Test: Chi-square test is a technique to determine the relationship between the categorical variables. The chi-square value is calculated between each feature and the target variable, and the desired number of features with the best chi-square value is selected.\nFisher‚Äôs Score: Fisher‚Äôs score is one of the popular supervised technique of features selection. It returns the rank of the variable on the fisher‚Äôs criteria in descending order. Then we can select the variables with a large fisher‚Äôs score.\nMissing Value Ratio: The value of the missing value ratio can be used for evaluating the feature set against the threshold value. The formula for obtaining the missing value ratio is the number of missing values in each column divided by the total number of observations. The variable is having more than the threshold value can be dropped.\n\\[\\text{Missing Value Ratio} = \\frac{\\text{Number of Missing Values} \\times 100}{\\text{Total Number of Observations}}\n  \\]\n\n\n\n3. Embedded Methods\nEmbedded methods combined the advantages of both filter and wrapper methods by considering the interaction of features along with low computational cost. These are fast processing methods similar to the filter method but more accurate than the filter method.\n\nThese methods are also iterative, which evaluates each iteration, and optimally finds the most important features that contribute the most to training in a particular iteration. Some techniques of embedded methods are:\n\nRegularization: Regularization adds a penalty term to different parameters of the machine learning model for avoiding overfitting in the model. This penalty term is added to the coefficients; hence it shrinks some coefficients to zero. Those features with zero coefficients can be removed from the dataset. The types of regularization techniques are L1 Regularization (Lasso Regularization) or Elastic Nets (L1 and L2 regularization).\nRandom Forest Importance: Different tree-based methods of feature selection help us with feature importance to provide a way of selecting features. Here, feature importance specifies which feature has more importance in model building or has a great impact on the target variable. Random Forest is such a tree-based method, which is a type of bagging algorithm that aggregates a different number of decision trees. It automatically ranks the nodes by their performance or decrease in the impurity (Gini impurity) over all the trees. Nodes are arranged as per the impurity values, and thus it allows to pruning of trees below a specific node. The remaining nodes create a subset of the most important features."
  },
  {
    "objectID": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html#how-to-choose-a-feature-selection-method",
    "href": "blogs/feature_selection_technique/Feature Selection Techniques in Machine Learning.html#how-to-choose-a-feature-selection-method",
    "title": "Feature Selection Techniques in Machine Learning",
    "section": "How to choose a Feature Selection Method?",
    "text": "How to choose a Feature Selection Method?\nFor machine learning engineers, it is very important to understand that which feature selection method will work properly for their model. The more we know the datatypes of variables, the easier it is to choose the appropriate statistical measure for feature selection.\n\n\n\nFeature_Selection_Flow_Chart\n\n\nTo know this, we need to first identify the type of input and output variables. In machine learning, variables are of mainly two types:\n\nNumerical Variables: Variable with continuous values such as integer, float\nCategorical Variables: Variables with categorical values such as Boolean, ordinal, nominals.\n\nBelow are some univariate statistical measures, which can be used for filter-based feature selection:\n\nNumerical Input, Numerical Output: Numerical Input variables are used for predictive regression modelling. The common method to be used for such a case is the Correlation coefficient.\n\nPearson‚Äôs correlation coefficient (For linear Correlation).\nSpearman‚Äôs rank coefficient (for non-linear correlation).\n\n¬†Numerical Input, Categorical Output: Numerical Input with categorical output is the case for classification predictive modelling problems.¬†In this case, also, correlation-based techniques should be used, but with categorical output.\n\nANOVA correlation coefficient (linear).\nKendall‚Äôs rank coefficient (nonlinear).\n\nCategorical Input, Numerical Output: This is the case of regression predictive modelling with categorical input. It is a different example of a regression problem. We can use the same measures as discussed in the above case but in reverse order.\nCategorical Input, Categorical Output: This is a case of classification predictive modelling with categorical Input variables.\nThe commonly used technique for such a case is Chi-Squared Test. We can also use Information gain in this case.\n\n\n\n\n\n\n\n\n\nInput Variable\nOutput Variable\nFeature Selection technique\n\n\n\n\nNumerical\nNumerical\n- Pearson‚Äôs correlation coefficient (For linear Correlation).- Pearson‚Äôs correlation coefficient (For linear Correlation)\n\n\nNumerical\nCategorical\n- ANOVA correlation coefficient (linear).  - Kendall‚Äôs rank coefficient (nonlinear).\n\n\nCategorical\nNumerical\n- Kendall‚Äôs rank coefficient (linear).  - ANOVA correlation coefficient (nonlinear).\n\n\nCategorical\nCategorical\n- Chi-Squared test (contingency tables).  - Mutual Information."
  },
  {
    "objectID": "blogs/Introduction_to_Docker/Introduction_to_Docker.html",
    "href": "blogs/Introduction_to_Docker/Introduction_to_Docker.html",
    "title": "Introduction to Docker",
    "section": "",
    "text": "Docker is a platform designed to help developers build, share, and run container applications."
  },
  {
    "objectID": "blogs/Introduction_to_Docker/Introduction_to_Docker.html#what-is-docker",
    "href": "blogs/Introduction_to_Docker/Introduction_to_Docker.html#what-is-docker",
    "title": "Introduction to Docker",
    "section": "",
    "text": "Docker is a platform designed to help developers build, share, and run container applications."
  },
  {
    "objectID": "blogs/Introduction_to_Docker/Introduction_to_Docker.html#why-do-we-need-dockers",
    "href": "blogs/Introduction_to_Docker/Introduction_to_Docker.html#why-do-we-need-dockers",
    "title": "Introduction to Docker",
    "section": "Why do we need Dockers?",
    "text": "Why do we need Dockers?\n\nConsistency Across Environments\n\n\nProblem: Applications often behave differently in development, testing, and production environments due to variations in configurations, dependencies, and infrastructure.\nSolution: Docker containers encapsulate all the necessary components, ensuring the application runs consistently across all environments.\n\n\n\nIsolation\n\n\nProblem: Running multiple applications on the same host can lead to conflicts, such as dependency clashes or resource contention.\nSolution: Docker provides isolated environments for each application, preventing interference and ensuring stable performance.\n\n\n\nScalability\n\n\nProblem: Scaling applications to handle increased load can be challenging, requiring manual intervention and configuration.\nSolution: Docker makes it easy to scale applications horizontally by running multiple container instances, allowing for quick and efficient scaling."
  },
  {
    "objectID": "blogs/Introduction_to_Docker/Introduction_to_Docker.html#how-exactly-docker-is-used",
    "href": "blogs/Introduction_to_Docker/Introduction_to_Docker.html#how-exactly-docker-is-used",
    "title": "Introduction to Docker",
    "section": "How exactly Docker is used?",
    "text": "How exactly Docker is used?\n\n\n\nImage credit: Geeksforgeeks\n\n\n\nDocker Engine\nDocker Engine is the core component of the Docker platform, responsible for creating, running, and managing Docker containers. It serves as the runtime that powers Docker‚Äôs containerization capabilities. Here‚Äôs an in-depth look at the Docker Engine:\n\n\nComponents of Docker Engine\n\n1. Docker Daemon (dockerd):\n\nFunction : The Docker daemon is the background service running on the host machine. It manages Docker objects such as images, containers, networks, and volumes.\nInteraction : It listens for Docker API requests and processes them, handling container lifecycle operations (start, stop, restart, etc.).\n\n\n\n2. Docker CLI (docker):\n\nFunction : The Docker Command Line Interface (CLI) is the tool that users interact with to communicate with the Docker daemon.\nUsage : Users run Docker commands through the CLI to perform tasks like building images, running containers, and managing Docker resources.\n\n\n\n3. REST API :\n\nFunction : The Docker REST API allows communication between the Docker CLI and the Docker daemon. It also enables programmatic interaction with Docker.\nUsage : Developers can use the API to automate Docker operations or integrate Docker functionality into their applications.\n\n\n\n\nDocker Image\nA Docker image is a lightweight, stand-alone, and executable software package that includes everything needed to run a piece of software, such as the code, runtime, libraries, environment variables, and configuration files. Images are used to create Docker containers, which are instances of these images.\n\nComponents of a Docker Image\n\nBase Image : The starting point for building an image. It could be a minimal OS image like alpine, a full-fledged OS like ubuntu, or even another application image like python or node.\nApplication Code : The actual code and files necessary for the application to run.\nDependencies : Libraries, frameworks, and packages required by the application.\nMetadata : Information about the image, such as environment variables, labels, and exposed ports.\n\n\n\nDocker Image Lifecycle\n\nCreation : Images are created using the docker build command, which processes the instructions in a Dockerfile to create the image layers.\n\nStorage : Images are stored locally on the host machine. They can also be pushed to and pulled from Docker registries like Docker Hub, AWS ECR, or Google Container Registry.\n\nDistribution : Images can be shared by pushing them to a Docker registry, allowing others to pull and use the same image.\n\nExecution : Images are executed by running containers, which are instances of these images.\n\n\n\nDockerfile\nA Dockerfile is a text file that contains a series of instructions used to build a Docker image. Each instruction in a Dockerfile creates a layer in the image, allowing for efficient image creation and reuse of layers. Dockerfiles are used to automate the image creation process, ensuring consistency and reproducibility.\n\nKey Components of a Dockerfile\n\nBase Image (FROM) : Specifies the starting point for the image, which could be a minimal operating system, a specific version of a language runtime, or another image.\nExample: FROM ubuntu:20.04\nLabels (LABEL) : Adds metadata to the image, such as version, description, or maintainer.\nExample: LABEL version=\"1.0\" description=\"My application\"\nRun Commands (RUN) : Executes commands in the image during the build process, typically used to install software packages. Example: docker RUN apt-get update && apt-get install -y python3\nCopy Files (COPY): Copies files or directories from the host system to the image.\nExample: COPY . /app\nEnvironment Variables (ENV) : Sets environment variables in the image.\nExample: ENV PATH /app/bin:$PATH\nWork Directory (WORKDIR) : Sets the working directory for subsequent instructions.\nExample: WORKDIR /app\nExpose Ports (EXPOSE) : Informs Docker that the container listens on specified network ports.\nExample: EXPOSE 8080\nCommand (CMD) : Provides a default command to run when the container starts.\nExample: CMD [\"python\", \"app.py\"]\nVolume (VOLUME) : Creates a mount point with a specified path and marks it as holding externally mounted volumes from the host or other containers.\nExample: VOLUME [\"/data\"]\nArguments (ARG) : Defines build-time variables.\nExample: ARG VERSION=1.0\n\n# Use an Official python runtime as a base image\nFROM python:3.8-slim\n\n# Set the working directory in the container\nWORKDIR /app \n\n# Copy the current directory contents into the container at /app \nCOPY . /app \n\n# Install the needed packages specified in requirements.txt\nRUN pip install -no-cache-dir -r requirements.txt \n\n# Make port 80 available to the world outside this container \nEXPOSE 80\n\n# Define enviroment vaiable\nENV NAME world\n\n# Run app.py when the container launches \nCMD [\"python\", \"app.py\"]\n\n\n\nDocker Container\nA Docker container is a lightweight, portable, and isolated environment that encapsulates an application and its dependencies, allowing it to run consistently across different computing environments. Containers are created from Docker images, which are immutable and contain all the necessary components for the application to run.\n\n\n\n\nRegistry\nA Docker registry is a service that stores and distributes Docker images. It acts as a repository where users can push, pull, and manage Docker images. Docker Hub is the most well-known public registry, but private registries can also be set up to securely store and manage images within an organization.\n\nKey Components of a Docker Registry:\n\nRepositories : A repository is a collection of related Docker images, typically different versions of the same application. Each repository can hold multiple tags, representing different versions of an image.\nTags : Tags are used to version images within a repository.\nFor example, myapp:1.0, myapp:2.0, and myapp:latest are tags for different versions of the myapp image.\n\n\n\nTypes of Docker Registries\n\nDocker Hub:\n\n\nDescription : The default public registry provided by Docker, which hosts a vast number of public images and also supports private repositories.\n\nURL : hub.docker.com\n\nUse Case : Publicly sharing images and accessing a large collection of pre-built images from the community and official repositories.\n\nPrivate Registries :\n\n\nDescription : Custom registries set up by organizations to securely store and manage their own Docker images.\n\nUse Case : Ensuring security and control over image distribution within an organization.\n\nThird-Party Registries :\n\n\nExamples : Amazon Elastic Container Registry (ECR), Google Container Registry (GCR), Azure Container Registry (ACR).\n\nUse Case : Integrating with cloud platforms for seamless deployment and management of images within cloud infrastructure.\n\n\n\n\nBenefits of Using Docker Registries\n1. Centralized Image Management\n\nRegistries provide a centralized location to store and manage Docker images, making it easier to organize and distribute them.\n2. Version Control :\n\nUsing tags, registries allow version control of images, enabling users to easily roll back to previous versions if needed.\n3. Collaboration:\n\nPublic registries like Docker Hub facilitate collaboration by allowing users to share images with the community or within teams.\n4. Security :\n\nPrivate registries ensure that sensitive images are stored securely and access is controlled within an organization.\n5. Integration with CI/CD :\n\nRegistries integrate seamlessly with CI/CD pipelines, automating the process of building, storing, and deploying Docker images.\n\n\n\nUse-cases\n\n1. Microservices Architecture\n\n\nDescription : Microservices break down applications into smaller, independent services, each running in its own container.\nBenefits : Simplifies deployment, scaling, and maintenance. Each service can be developed, updated, and deployed independently.\n\n\n\n2. Continuous Integration and Continuous Deployment (CI/CD)\n\n\nDescription : Docker ensures a consistent environment from development through testing to production.\nBenefits : Streamlines the CI/CD pipeline, reduces discrepancies between environments, and speeds up testing and deployment processes.\n\n\n\n3. Cloud Migration\n\n\nDescription : Containerizing applications to move them to the cloud.\nBenefits : Simplifies the migration process, allows applications to run consistently across different cloud providers, and optimizes resource usage.\n\n\n\n4. Scalable Web Applications\n\n\nDescription : Deploying web applications in containers for easy scaling.\nBenefits : Simplifies scaling up or down based on traffic, ensures consistent deployment, and enhances resource utilization.\n\n\n\n5. Testing and QA\n\n\nDescription : Creating consistent environments for testing applications.\nBenefits : Ensures tests are run in environments identical to production, speeds up the setup of test environments, and facilitates automated testing.\n\n\n\n6. Machine Learning and AI\n\n\nDescription : Deploying machine learning models and AI applications in containers.\nBenefits : Ensures consistency in the runtime environment, simplifies scaling of model training and inference, and facilitates collaboration and reproducibility.\n\n\n\n7. API Development and Deployment\n\n\nDescription : Developing and deploying APIs in containers.\nBenefits : Ensures APIs run consistently across environments, simplifies scaling, and improves deployment speed and reliability."
  },
  {
    "objectID": "blogs/Chi_Square_Test/Chi Square Test.html",
    "href": "blogs/Chi_Square_Test/Chi Square Test.html",
    "title": "Chi Square Test",
    "section": "",
    "text": "The chi-square test is a statistical test used to determine whether there is a significant difference between the expected frequencies and the observed frequencies in one or more categorical variables. It is commonly used to determine whether there is a significant association between two categorical variables\n\n\n\n\nExample of how the chi-square test can be used to determine whether there is a significant association between two categorical variables:\nSuppose we are interested in studying the relationship between diet and heart disease. We collect data on 100 people and record their diet (healthy or unhealthy) and whether they have heart disease (yes or no). The data looks like this:\n\n\n\nDiet\nHeart Disease\nHeart Disease\n\n\n\n\nHealthy\nYes\n20\n\n\nHealthy\nNo\n10\n\n\nUnhealthy\nYes\n30\n\n\nUnhealthy\nNo\n40\n\n\n\nWe can use the chi-square test to determine whether there is a significant association between diet and heart disease. Our null hypothesis is that there is no significant association between the two variables.\nTo perform the chi-square test, we first need to calculate the expected frequencies for each cell in the table. The expected frequency for a cell is the product of the row total and the column total for that cell, divided by the overall total.\nFor example, the expected frequency for the cell ‚ÄúHealthy, No Heart Disease‚Äù is: \\[(20 + 10) * (30 + 40) / 100 = 25\\] We can calculate the expected frequencies for all cells in the table as follows:\n\n\n\nDiet\nHeart Disease\nExpected Frequency\n\n\n\n\nHealthy\nYes\n25\n\n\nHealthy\nNo\n25\n\n\nUnhealthy\nYes\n50\n\n\nUnhealthy\nNo\n50\n\n\n\nNext, we calculate the chi-square statistic as follows:\n\\(\\Large\\sum\\left(\\frac{(Observed\\ Frequency - Expected\\ Frequency)^2}{Expected\\ Frequency}\\right)\\)\n\\(= \\Large\\frac{(20 - 25)^2}{25} + \\frac{(10 - 25)^2}{25} + \\frac{(30 - 50)^2}{50} + \\frac{(40 - 50)^2}{50} = 7.20\\)\nFinally, we compare the chi-square statistic to a critical value from a chi-square distribution table or by using a computer program. If the chi-square statistic is greater than the critical value, we reject the null hypothesis and conclude that there is a significant association between diet and heart disease. If the chi-square statistic is less than the critical value, we fail to reject the null hypothesis and conclude that there is no significant association between the two variables.\n\n\n\n\nThe chi-square test is often used in machine learning to evaluate the performance of a classification model. It is used to determine whether the predicted class labels from the model are significantly different from the true class labels. This can help you ensure that your model is making fair and accurate predictions and improve its overall performance.\nThe chi-square test can also be used to select the best features for a machine learning model. By measuring the correlation between each feature and the target variable, you can identify the most relevant and predictive features for your model. This can help improve the performance of your model by using only the most relevant and predictive features.\n\n\n\n\nFor example, suppose you have trained a classification model to predict whether a customer will churn (i.e., stop using your service). You can use the chi-square test to compare the predicted churn rates for different groups of customers (e.g., by age, gender, location) to the observed churn rates. If the predicted churn rates are significantly different from the observed churn rates, this may indicate that the model is making biased or inaccurate predictions.\nThe chi-square test can also be used to select the best features for a machine learning model. By measuring the correlation between each feature and the target variable, you can identify the most relevant and predictive features for your model.\n\n\n\n\n\n\nReference Article Chi-Square Test for Feature Selection in Machine learning | by sampath kumar gajawada | Towards Data Science\nPractical Implementation [[Feature_Selection_004_Chi-Square Test#Practical Implementation]]\n\n\n\n\n\n1. What is the chi-square test and how is it used in machine learning?\nThe chi-square test is a statistical test that is used to determine whether there is a significant association between two categorical variables. In machine learning, it is often used to evaluate the performance of a classification model and to select the best features for a model.\n2. When would you use the chi-square test in machine learning?\nThe chi-square test is typically used in machine learning when you want to evaluate the performance of a classification model or when you want to select the best features for a model. It is particularly useful when the data do not meet the assumptions of other statistical tests, such as normality or equal variance.\n3. How do you interpret the results of a chi-square test in machine learning?\nThe chi-square test returns a p-value, which indicates the probability of obtaining the observed results if the null hypothesis (i.e., the variables are independent) is true. If the p-value is less than a predetermined threshold (e.g., 0.05), you can reject the null hypothesis and conclude that there is a significant association between the variables. If the p-value is greater than the threshold, you cannot reject the null hypothesis and conclude that there is no significant association.\n4. How can you use the chi-square test to select the best features for a machine learning model?\nThe chi-square test can be used to select the best features for a machine learning model by evaluating the statistical significance of the relationship between each feature and the target variable. Features with a significant relationship to the target variable are more likely to be useful for predicting the target variable and are therefore more likely to be selected.\nHere are the steps on how to use the chi-square test to select the best features for a machine learning model:\n\nGather data. The first step is to gather data that includes the features you want to evaluate and the target variable.\nPrepare the data. The data should be prepared in a way that is compatible with the chi-square test. This may involve converting categorical variables to binary variables and removing features with missing values.\nCalculate the chi-square statistic. The chi-square statistic is calculated by comparing the observed frequencies of each feature with the expected frequencies if there was no relationship between the feature and the target variable.\nDetermine the p-value. The p-value is the probability of getting a chi-square statistic as extreme or more extreme than the one we calculated, assuming that there is no relationship between the two variables.\nSelect features. Features with a p-value less than a predetermined significance level are selected. The significance level is typically set to 0.05, which means that there is a 5% chance of selecting a feature that is not actually related to the target variable.\n\nThe chi-square test is a powerful tool that can be used to select the best features for a machine learning model. However, it is important to note that the chi-square test is only a statistical test and does not guarantee that the selected features will be useful for predicting the target variable. It is important to evaluate the performance of the selected features on a machine learning model to ensure that they are actually useful.\n5. How does the chi-square test compare to other statistical tests (e.g., t-test, ANOVA) in terms of its assumptions and power?\nThe chi-square test is a nonparametric test that does not assume a specific distribution or shape of the data. It is often used to evaluate the performance of a classification model or to select the best features for a machine learning model.\nIn comparison to other statistical tests, such as the t-test and ANOVA, the chi-square test has different assumptions and power. The t-test and ANOVA are parametric tests that assume that the data are normally distributed and have equal variances, respectively.These tests may be more powerful than the chi-square test when these assumptions are met, but may be less robust when the assumptions are violated.\nIn summary, the chi-square test is a nonparametric test that does not assume a specific distribution or shape of the data, and may be less powerful but more robust than parametric tests such as the t-test and ANOVA.\n6. What are some advantages and limitations of using the chi-square test in machine learning?\n\nSome advantages of using the chi-square test in machine learning include:\n\nIt is a widely used and well-established statistical test.\nIt is relatively easy to understandand implement.\nIt can be used to evaluate the performance of a classification model or select the best features for a machine learning model.\nIt is generally more robust than parametric tests, as it does not assume a specific distribution or shape of the data.\n\nHowever, there are also some limitations of using the chi-square test in machine learning:\n\nIt may be less powerful than parametric tests, and may not be as sensitive to detecting differences in the data.\nIt is only applicable to categorical data, and cannot be used with continuous or ordinal data.\nIt requires a large sample size to be effective, and may not be reliable with small sample sizes.\nIt may not be suitable for comparing more than two groups or categories."
  },
  {
    "objectID": "blogs/Chi_Square_Test/Chi Square Test.html#chi-square-test",
    "href": "blogs/Chi_Square_Test/Chi Square Test.html#chi-square-test",
    "title": "Chi Square Test",
    "section": "",
    "text": "The chi-square test is a statistical test used to determine whether there is a significant difference between the expected frequencies and the observed frequencies in one or more categorical variables. It is commonly used to determine whether there is a significant association between two categorical variables\n\n\n\n\nExample of how the chi-square test can be used to determine whether there is a significant association between two categorical variables:\nSuppose we are interested in studying the relationship between diet and heart disease. We collect data on 100 people and record their diet (healthy or unhealthy) and whether they have heart disease (yes or no). The data looks like this:\n\n\n\nDiet\nHeart Disease\nHeart Disease\n\n\n\n\nHealthy\nYes\n20\n\n\nHealthy\nNo\n10\n\n\nUnhealthy\nYes\n30\n\n\nUnhealthy\nNo\n40\n\n\n\nWe can use the chi-square test to determine whether there is a significant association between diet and heart disease. Our null hypothesis is that there is no significant association between the two variables.\nTo perform the chi-square test, we first need to calculate the expected frequencies for each cell in the table. The expected frequency for a cell is the product of the row total and the column total for that cell, divided by the overall total.\nFor example, the expected frequency for the cell ‚ÄúHealthy, No Heart Disease‚Äù is: \\[(20 + 10) * (30 + 40) / 100 = 25\\] We can calculate the expected frequencies for all cells in the table as follows:\n\n\n\nDiet\nHeart Disease\nExpected Frequency\n\n\n\n\nHealthy\nYes\n25\n\n\nHealthy\nNo\n25\n\n\nUnhealthy\nYes\n50\n\n\nUnhealthy\nNo\n50\n\n\n\nNext, we calculate the chi-square statistic as follows:\n\\(\\Large\\sum\\left(\\frac{(Observed\\ Frequency - Expected\\ Frequency)^2}{Expected\\ Frequency}\\right)\\)\n\\(= \\Large\\frac{(20 - 25)^2}{25} + \\frac{(10 - 25)^2}{25} + \\frac{(30 - 50)^2}{50} + \\frac{(40 - 50)^2}{50} = 7.20\\)\nFinally, we compare the chi-square statistic to a critical value from a chi-square distribution table or by using a computer program. If the chi-square statistic is greater than the critical value, we reject the null hypothesis and conclude that there is a significant association between diet and heart disease. If the chi-square statistic is less than the critical value, we fail to reject the null hypothesis and conclude that there is no significant association between the two variables.\n\n\n\n\nThe chi-square test is often used in machine learning to evaluate the performance of a classification model. It is used to determine whether the predicted class labels from the model are significantly different from the true class labels. This can help you ensure that your model is making fair and accurate predictions and improve its overall performance.\nThe chi-square test can also be used to select the best features for a machine learning model. By measuring the correlation between each feature and the target variable, you can identify the most relevant and predictive features for your model. This can help improve the performance of your model by using only the most relevant and predictive features.\n\n\n\n\nFor example, suppose you have trained a classification model to predict whether a customer will churn (i.e., stop using your service). You can use the chi-square test to compare the predicted churn rates for different groups of customers (e.g., by age, gender, location) to the observed churn rates. If the predicted churn rates are significantly different from the observed churn rates, this may indicate that the model is making biased or inaccurate predictions.\nThe chi-square test can also be used to select the best features for a machine learning model. By measuring the correlation between each feature and the target variable, you can identify the most relevant and predictive features for your model.\n\n\n\n\n\n\nReference Article Chi-Square Test for Feature Selection in Machine learning | by sampath kumar gajawada | Towards Data Science\nPractical Implementation [[Feature_Selection_004_Chi-Square Test#Practical Implementation]]\n\n\n\n\n\n1. What is the chi-square test and how is it used in machine learning?\nThe chi-square test is a statistical test that is used to determine whether there is a significant association between two categorical variables. In machine learning, it is often used to evaluate the performance of a classification model and to select the best features for a model.\n2. When would you use the chi-square test in machine learning?\nThe chi-square test is typically used in machine learning when you want to evaluate the performance of a classification model or when you want to select the best features for a model. It is particularly useful when the data do not meet the assumptions of other statistical tests, such as normality or equal variance.\n3. How do you interpret the results of a chi-square test in machine learning?\nThe chi-square test returns a p-value, which indicates the probability of obtaining the observed results if the null hypothesis (i.e., the variables are independent) is true. If the p-value is less than a predetermined threshold (e.g., 0.05), you can reject the null hypothesis and conclude that there is a significant association between the variables. If the p-value is greater than the threshold, you cannot reject the null hypothesis and conclude that there is no significant association.\n4. How can you use the chi-square test to select the best features for a machine learning model?\nThe chi-square test can be used to select the best features for a machine learning model by evaluating the statistical significance of the relationship between each feature and the target variable. Features with a significant relationship to the target variable are more likely to be useful for predicting the target variable and are therefore more likely to be selected.\nHere are the steps on how to use the chi-square test to select the best features for a machine learning model:\n\nGather data. The first step is to gather data that includes the features you want to evaluate and the target variable.\nPrepare the data. The data should be prepared in a way that is compatible with the chi-square test. This may involve converting categorical variables to binary variables and removing features with missing values.\nCalculate the chi-square statistic. The chi-square statistic is calculated by comparing the observed frequencies of each feature with the expected frequencies if there was no relationship between the feature and the target variable.\nDetermine the p-value. The p-value is the probability of getting a chi-square statistic as extreme or more extreme than the one we calculated, assuming that there is no relationship between the two variables.\nSelect features. Features with a p-value less than a predetermined significance level are selected. The significance level is typically set to 0.05, which means that there is a 5% chance of selecting a feature that is not actually related to the target variable.\n\nThe chi-square test is a powerful tool that can be used to select the best features for a machine learning model. However, it is important to note that the chi-square test is only a statistical test and does not guarantee that the selected features will be useful for predicting the target variable. It is important to evaluate the performance of the selected features on a machine learning model to ensure that they are actually useful.\n5. How does the chi-square test compare to other statistical tests (e.g., t-test, ANOVA) in terms of its assumptions and power?\nThe chi-square test is a nonparametric test that does not assume a specific distribution or shape of the data. It is often used to evaluate the performance of a classification model or to select the best features for a machine learning model.\nIn comparison to other statistical tests, such as the t-test and ANOVA, the chi-square test has different assumptions and power. The t-test and ANOVA are parametric tests that assume that the data are normally distributed and have equal variances, respectively.These tests may be more powerful than the chi-square test when these assumptions are met, but may be less robust when the assumptions are violated.\nIn summary, the chi-square test is a nonparametric test that does not assume a specific distribution or shape of the data, and may be less powerful but more robust than parametric tests such as the t-test and ANOVA.\n6. What are some advantages and limitations of using the chi-square test in machine learning?\n\nSome advantages of using the chi-square test in machine learning include:\n\nIt is a widely used and well-established statistical test.\nIt is relatively easy to understandand implement.\nIt can be used to evaluate the performance of a classification model or select the best features for a machine learning model.\nIt is generally more robust than parametric tests, as it does not assume a specific distribution or shape of the data.\n\nHowever, there are also some limitations of using the chi-square test in machine learning:\n\nIt may be less powerful than parametric tests, and may not be as sensitive to detecting differences in the data.\nIt is only applicable to categorical data, and cannot be used with continuous or ordinal data.\nIt requires a large sample size to be effective, and may not be reliable with small sample sizes.\nIt may not be suitable for comparing more than two groups or categories."
  },
  {
    "objectID": "blogs/Supervised_Learning_Algorithms/Supervised Learning Algorithms.html",
    "href": "blogs/Supervised_Learning_Algorithms/Supervised Learning Algorithms.html",
    "title": "Supervised Learning Algorithms",
    "section": "",
    "text": "Imagine teaching a computer like a teacher instructs a student. In supervised learning, we provide the computer with labeled examples. It‚Äôs like showing it the right answers and letting it figure out how to get there.\n\n\n\nsupervised learning\n\n\nWhy Do We Use It?\nSupervised learning helps the computer make predictions, classify things, and make decisions based on past experiences.\nMeet the Superstars!\n\n[[Linear Regression in Machine Learning|Linear Regression]]: Think of it as drawing a straight line through dots on a graph to make predictions, like guessing a house‚Äôs price based on its size.\n[[Decision Tree|Decision Trees]]: Imagine playing 20 Questions. It‚Äôs like that but for sorting things, such as deciding if an email is spam or not.\nSupport Vector Machines (SVM): Picture separating different groups of data with a clear line. It‚Äôs used in things like sorting images or categorizing text.\n\nHow It Works\n\nTraining: We teach the algorithm using a dataset with examples and their correct answers. It learns by finding patterns in this training data.\nTesting: After training, we test it on new, unseen data to see how well it can predict or classify.\n\nIn the Real World\n\nPredicting stock prices based on past trends.\nDeciding if an email is junk or not.\nRecognizing handwritten numbers in ZIP codes.\n\nPros and Cons\n\nPros: It‚Äôs widely used and can be very accurate if the training data is good.\nCons: You need labeled data (which can be costly), and it might not work well if the data is messy or the problem is tricky.\n\nTakeaway\nSupervised learning is like training a pet with treats. It‚Äôs essential in machine learning, especially when you know what the right answers should be. It‚Äôs like the foundation of our machine learning journey!\n\n\nReference Reading\n# Supervised Learning: Algorithms, Examples, and How It Works"
  },
  {
    "objectID": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html",
    "href": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html",
    "title": "Natural Language Processing(NLP)",
    "section": "",
    "text": "Natural language processing is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data."
  },
  {
    "objectID": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#what-is-nlp",
    "href": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#what-is-nlp",
    "title": "Natural Language Processing(NLP)",
    "section": "",
    "text": "Natural language processing is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data."
  },
  {
    "objectID": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#what-is-natural-language",
    "href": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#what-is-natural-language",
    "title": "Natural Language Processing(NLP)",
    "section": "What is Natural Language",
    "text": "What is Natural Language\nIn neuropsychology, linguistics, and the philosophy of language, a natural language or ordinary language is any language that has evolved naturally in humans through use and repetition without conscious planning or premeditation. Natural languages can take different forms, such as speech or signing. They are distinguished from constructed and formal languages such as those used to program computers or to study logic"
  },
  {
    "objectID": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#real-world-applications",
    "href": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#real-world-applications",
    "title": "Natural Language Processing(NLP)",
    "section": "Real World Applications",
    "text": "Real World Applications\n\nContextual Advertisements\nNatural Language Processing (NLP) is used for contextual advertisements by analyzing the text content of a webpage or a user‚Äôs search query to understand the context and intent behind it. Based on this analysis, relevant ads are shown to the user that match their interests and needs. NLP techniques such as named entity recognition, sentiment analysis, and topic modeling are used to extract relevant information from the text and match it with suitable ads. This helps to provide a more personalized and relevant advertising experience to the user.\nEmail Clients - spam filtering, smart reply\nNLP is used for email clients in two main ways: spam filtering and smart reply. In spam filtering, NLP algorithms are used to analyze the content of incoming emails to determine whether they are legitimate or spam.\nThis is done by analyzing features such as the sender‚Äôs email address, the text content, and the presence of certain keywords.\nSmart reply, on the other hand, uses NLP to suggest relevant and personalized responses to emails based on the context and content of the message.\nNLP techniques such as text classification and natural language generation are used for this purpose, resulting in more efficient and effective email communication.\nSocial Media - removing adult content, opinion mining\nNLP is used in social media platforms for two primary purposes: removing adult content and opinion mining. In the first case, NLP algorithms are used to analyze the text, images, and videos posted by users to identify and remove adult content, hate speech, and other inappropriate content. In opinion mining, NLP techniques such as sentiment analysis are used to extract insights from the large volumes of text data generated by social media users. This can help businesses and organizations understand customer opinions and preferences and make informed decisions based on them.\nSearch Engines\nNLP is used extensively in search engines to improve the accuracy and relevance of search results. NLP algorithms are used to analyze the text content of web pages and user queries to understand the underlying meaning and intent.This is done by techniques such as natural language understanding, entity recognition, and text classification. The search engine can then provide more relevant results to the user based on the context and meaning of their query, resulting in a better search experience. NLP is also used for features such as auto-complete, query expansion, and personalized search results.\nChatbots\nNLP is a crucial component of chatbots, which are designed to simulate human conversation and provide automated customer support. NLP algorithms are used to understand user queries and generate appropriate responses. This is done by techniques such as natural language understanding, intent recognition, and named entity recognition. Chatbots can also use sentiment analysis to understand the user‚Äôs mood and personalize their response accordingly. By leveraging NLP, chatbots can provide fast and efficient customer support, 24/7, and handle a wide range of queries, leading to enhanced customer satisfaction."
  },
  {
    "objectID": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#common-nlp-tasks",
    "href": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#common-nlp-tasks",
    "title": "Natural Language Processing(NLP)",
    "section": "Common NLP Tasks",
    "text": "Common NLP Tasks\n\nDocument/Text Classification\nNLP is used for text classification, which involves categorizing large volumes of text into predefined categories or classes. This is useful for tasks such as document classification, spam filtering, and sentiment analysis. NLP algorithms are used to analyze the text content and extract relevant features, such as the presence of certain keywords, the context of the text, and the structure of the document.These features are then used to train machine learning models that can classify new text data into the appropriate categories. NLP-based text classification can be used across a wide range of industries, including finance, healthcare, and e-commerce, to automate processes and improve efficiency.\n\n\n\n\n\n\nNote\n\n\n\nWe do this by cleaning up the words, putting them in order, and showing the computer examples of what each group should look like. Then, the computer can sort new words into the right group based on what it learned before.\n\n\nSentiment analysis\nNLP is used for sentiment analysis, which involves analyzing text data to determine the emotional tone or sentiment expressed by the author.\nSentiment analysis is useful in many applications, such as understanding customer feedback, monitoring social media sentiment, and predicting stock market trends.\nNLP techniques such as natural language understanding and machine learning algorithms are used to identify sentiment-bearing words and phrases and classify them as positive, negative, or neutral.\nSentiment analysis can provide valuable insights into customer attitudes and opinions, allowing businesses to make data-driven decisions and improve their products and services.\n\n\n\n\n\n\nNote\n\n\n\nüí° We can teach computers to read and understand the feelings people express in their words using NLP. It‚Äôs like teaching the computer to know whether someone is happy or sad based on the words they use. This helps us understand how people feel about things like movies, products, or events. It‚Äôs like asking your friends how they feel about something, but the computer can do it faster and with more words\n\n\nInformation Retrieval\nNLP is used for information retrieval, which involves finding relevant information from large collections of unstructured text data.Information retrieval is useful in many applications, such as search engines, chatbots, and question-answering systems. NLP techniques such as natural language understanding, text classification, and entity recognition are used to extract relevant information and understand the user‚Äôs query or intent. This allows the system to retrieve the most relevant and useful information, leading to a better user experience and increased efficiency.\n\n\n\n\n\n\nNote\n\n\n\nüí° We can teach computers to find the best information for us by reading and understanding lots of text using NLP. It‚Äôs like teaching the computer to look through a big book to find the answer to a question we have. The computer can find the information faster than we can and give us the best answer. It‚Äôs like having a super smart helper who can find anything we need!\n\n\nParts of Speech Tagging\nNLP is used for Parts of Speech (POS) tagging, which involves labeling each word in a sentence with its corresponding part of speech, such as noun, verb, adjective, etc. POS tagging is useful in many NLP applications, such as text-to-speech conversion, machine translation, and information retrieval.NLP techniques such as rule-based tagging and statistical tagging are used to automatically assign POS tags to each word based on its context and other linguistic features. Accurate POS tagging helps improve the accuracy of downstream NLP tasks and is an important step in text analysis and understanding.\n\n\n\n\n\n\nNote\n\n\n\nüí° We can teach computers to recognize the different types of words in a sentence using NLP. It‚Äôs like teaching the computer to know whether a word is a person, a thing, an action, or a description. By doing this, the computer can understand what the sentence is about and what each word is doing. It‚Äôs like having a robot assistant that can help us understand sentences better!\n\n\nLanguage Detection And Machine Translation\nNLP is used for language detection and machine translation, which involves identifying the language of a text and translating it into another language. Language detection is useful in many applications, such as text classification, sentiment analysis, and content filtering. Machine translation is useful for cross-language communication and understanding, and can be used in applications such as international business and diplomacy.\n\n\n\n\n\n\nNote\n\n\n\nüí° We can teach computers to understand and speak different languages using NLP. It‚Äôs like having a super-smart robot that can translate languages for us! By teaching the computer different languages and their grammar, it can help us understand what someone is saying in a different language, and even help us talk to them back in their own language. It‚Äôs like having a personal language tutor at our fingertips!\n\n\nConversational Agents\nNLP is used for conversational agents, which are computer programs designed to simulate human-like conversations with users. Conversational agents, also known as chatbots or virtual assistants, are used in many applications, such as customer support, personal assistants, and language learning. NLP techniques such as natural language understanding and generation, dialogue management, and sentiment analysis are used to enable conversational agents to understand and respond to user queries and generate appropriate responses. The goal is to create conversational agents that are indistinguishable from human agents in their conversational abilities.\n\n\n\n\n\n\nNote\n\n\n\nüí° We can teach computers to talk to us like humans using NLP. It‚Äôs like having a computer friend we can ask questions to and get answers from! By teaching the computer how to understand what we‚Äôre saying and how to respond, it can help us with things like finding information, playing games, or just keeping us company. It‚Äôs like having a cool virtual assistant we can chat with anytime!\n\n\nKnowledge Graph and QA Systems\nNLP is used for knowledge graph and question-answering (QA) systems, which involve organizing and connecting information from multiple sources to enable efficient information retrieval and answering of user queries. Knowledge graphs represent knowledge as nodes and edges in a graph structure, which can be queried using natural language questions. QA systems use NLP techniques such as entity recognition, relation extraction, and semantic parsing to understand user queries and retrieve relevant information from knowledge graphs or other sources. The goal is to create intelligent systems that can provide accurate and comprehensive answers to user queries.\nClick here for more information\n\n\n\n\n\n\n\nNote\n\n\n\nüí° We can teach computers to organize and understand information like we do using NLP. It‚Äôs like creating a big brain for the computer! By connecting different pieces of information and understanding what we‚Äôre asking, it can help us answer questions or find things we need. It‚Äôs like having a really smart friend who knows everything and can help us learn new things too!\n\n\nText Summarization\nNLP is used for text summarization, which involves automatically generating a condensed version of a longer piece of text while preserving its essential information.NLP techniques such as sentence scoring, text classification, and semantic analysis are used to identify and extract the most important sentences or phrases from a document and create a summary. Text summarization is used in various applications such as news articles, academic papers, and legal documents to enable efficient information consumption and understanding. The goal is to create accurate and concise summaries that capture the essence of the original text.\n\n\n\n\n\n\nNote\n\n\n\nüí° We can teach computers to read long stories or articles and then make a short summary using NLP. It‚Äôs like having a machine that can pick out the most important parts of a story and tell you what it‚Äôs about in just a few sentences. It‚Äôs really helpful when you don‚Äôt have time to read the whole thing, but you still want to know what it‚Äôs about!\n\n\nTopic Modelling\nNLP is used for topic modelling, which is a technique that identifies hidden topics or themes in a collection of documents. It involves grouping together similar words and phrases into topics, and then assigning each document a distribution of topics that best represents its content.NLP techniques such as clustering, latent Dirichlet allocation, and word frequency analysis are used to perform topic modelling. Topic modelling is useful in various applications such as information retrieval, recommendation systems, and content analysis. It enables better organization and understanding of large collections of text data by identifying key themes and patterns.\nClick here for more information\n\n\n\n\n\n\n\n\nNote\n\n\n\nüí° We can teach computers to find hidden topics or themes in a bunch of stories or articles using NLP. It‚Äôs like having a machine that can group together similar words and ideas to help us understand what the stories are all about. It‚Äôs really helpful when we have a lot of stories to read and want to find the important themes quickly!\n\n\nText Generation\nNLP is used for text generation, which involves generating new text that is similar to the style and content of existing text.This can be done using machine learning models that have been trained on large amounts of text data. NLP techniques such as recurrent neural networks and generative adversarial networks are commonly used for text generation. Text generation has various applications such as chatbots, automatic text completion, and content creation.It enables machines to produce human-like text that can be useful in various industries such as marketing and customer service.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nüí° We can use NLP to teach machines to create new text. It‚Äôs like teaching a robot how to write stories or messages just like humans do.\n\n\nSpell Checking And Grammar Correction\nNLP is used for spell checking and grammar correction by analyzing written text and comparing it to a database of correct spellings and grammar rules. This involves identifying and correcting spelling errors, as well as suggesting alternative words or phrasings that would improve grammar and overall readability. By using NLP techniques, spell checking and grammar correction tools can quickly and accurately identify errors and suggest corrections, making it easier for writers to produce high-quality written content. \n\n\n\n\n\n\nNote\n\n\n\nüí° Spell checking and grammar correction using NLP means using a computer to help us check if our writing is spelled correctly and if the grammar is right.\n\n\nText parsing\nText parsing is the process of breaking down text into smaller components to better understand its structure and meaning.In natural language processing (NLP), text parsing is used to analyze and extract important information from text, such as identifying the subject, object, and verb in a sentence. It involves using algorithms and models to automatically analyze and categorize different parts of text, allowing for more efficient processing and analysis of large amounts of data. Text parsing is used in a variety of NLP applications, including sentiment analysis, machine translation, and chatbots.\n\n\n\n\n\n\n\nNote\n\n\n\nüí° Text parsing with NLP means understanding the structure and meaning of sentences. Just like how we understand a story by reading it, NLP can help a computer understand what a sentence means and what it‚Äôs talking about.\n\n\nSpeech To Text\nSpeech to Text is a popular application of NLP that involves converting spoken language into text. This technology uses techniques like audio signal processing and natural language understanding to accurately transcribe spoken words into written text. Speech to Text is used in various applications like dictation software, automated subtitling for videos, and virtual assistants."
  },
  {
    "objectID": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#approaches-to-nlp",
    "href": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#approaches-to-nlp",
    "title": "Natural Language Processing(NLP)",
    "section": "Approaches to NLP",
    "text": "Approaches to NLP\nOver the years, Natural Language Processing (NLP) research has seen different approaches, each building upon the previous ones. Some of the major approaches include:\n\nHeuristic methods\nHeuristic methods or heuristic technique, is any approach to problem solving or self-discovery that employs a practical method that is not guaranteed to be optimal, perfect, or rational, but is nevertheless sufficient for reaching an immediate, short-term goal or approximation. Where finding an optimal solution is impossible or impractical, heuristic methods can be used to speed up the process of finding a satisfactory solution.\n\n\n\n\n\n\n\nNote\n\n\n\nüìå In the early days of NLP, rule-based systems were the primary approach. These methods involved creating hand-crafted rules and heuristics to solve specific language processing problems. While these methods were simple to implement, they were often inflexible and limited by the available knowledge of the language.\n\n\n\n\nExamples\n\nRegular Expression\nRegular regression is a classic statistical approach used in natural language processing (NLP) under the heuristic method. In regular regression, a linear model is trained using a set of features extracted from the text data. These features are typically hand-crafted by domain experts and can include measures of word frequency, length, and syntax. The trained model can then be used for tasks such as sentiment analysis, named entity recognition, and text classification. However, regular regression has some limitations, such as the need for expert feature engineering and its inability to capture complex relationships between words and sentences.\nWordNet\nWordNet is a lexical database of English words, which was developed by researchers at Princeton University. It organizes words into sets of synonyms called ‚Äúsynsets‚Äù and describes the semantic relationships between them. Each synset contains a group of words that share a common meaning, and the relationships between synsets are captured in a network of nodes and edges.\nIn NLP, WordNet is often used for tasks such as word sense disambiguation and semantic similarity analysis. WordNet provides a way to group words with similar meanings, which can be helpful in determining the intended meaning of a word in context. For example, if a sentence contains the word ‚Äúbank,‚Äù WordNet can be used to identify whether it refers to a financial institution or a river bank, based on the surrounding words and the context of the sentence.\nOverall, WordNet is a useful tool for NLP researchers and practitioners who need to work with language data and want to leverage the relationships between words and concepts to improve their analyses.\nClick here for more information\n\nOpen Mind Common Sense\nOpen Mind Common Sense (OMCS) is a knowledge base developed by the MIT Media Lab, which aims to provide a large, structured database of common-sense knowledge that can be used in natural language processing applications. OMCS is created through crowdsourcing and allows people to enter statements about the world in natural language, which are then parsed and stored in a database. This knowledge base can be used to help NLP systems better understand the meaning behind natural language and make more accurate predictions about human behavior and actions. The heuristic approach of OMCS involves manually designing a structured database of knowledge, which can be queried and used to improve NLP applications.\n\n\n\nAdvantages\nHeuristic methods in NLP have several advantages.\n\nFirst, they do not require large amounts of labeled data, which can be time-consuming and expensive to obtain.\nSecond, heuristic methods can be easily customized for specific applications and domains.\nThird, they are often more interpretable than machine learning or deep learning methods, allowing for better understanding of how the system is making its decisions.\nFourth, heuristic methods can be faster to implement and run than more complex approaches.\n\n\n\nCurrent Applications of Heuristic Methods in Natural Language Processing\nHeuristic methods have been used in Natural Language Processing (NLP) for decades, and they continue to be used in many current NLP applications. One such application is sentiment analysis, where heuristic rules are used to identify positive, negative, or neutral sentiment in text. Heuristic methods are also used in named entity recognition, where rules based on language patterns are used to identify and classify entities like names, organizations, and locations. Another application is question answering, where heuristic methods are used to generate answers based on patterns in the question and knowledge sources.\nIn addition to these applications, heuristic methods are also used for text classification, information extraction, and summarization. While deep learning models have recently gained popularity in NLP, heuristic methods are still widely used because they are often more interpretable and easier to modify than complex neural networks. Furthermore, heuristic methods can be useful in scenarios where large amounts of annotated data are not available, and rule-based methods can be created and fine-tuned with smaller datasets.\nOverall, heuristic methods continue to play an important role in NLP, and they are likely to remain a key component of NLP systems in the future.\n\n\nMachine learning-based methods\n\nWith the advent of machine learning, researchers began developing models that learned patterns and relationships in language data. These models could be trained on large datasets, allowing them to capture more complex language structures.\n\n\nAdvantages of Machine Learning Methods over Heuristic Methods in NLP\nMachine learning methods have become increasingly popular in Natural Language Processing (NLP) due to their numerous advantages over heuristic methods. Some of the advantages are:\n\nLearning from Data Machine learning algorithms can learn from large datasets and generalize well on unseen data, which is not possible with heuristic methods.\nAdaptability Machine learning methods can adapt to new data and improve their performance over time, whereas heuristic methods require manual tuning for each task.\nHigher Accuracy Machine learning methods can achieve higher accuracy compared to heuristic methods, especially in complex tasks such as speech recognition, sentiment analysis, and machine translation.\nTime-Saving Machine learning methods can automate tasks that would be time-consuming or impossible to perform manually, such as text classification or clustering.\nScalability Machine learning methods can scale to large datasets and handle high-dimensional data, which is a challenge for heuristic methods.\n\nMachine learning methods can scale to large datasets and handle high-dimensional data, which is a challenge for heuristic methods.\n\n\n\nMachine learning algorithms used in NLP\nThere are several machine learning algorithms used in NLP, some of which are Naive Bayes - a probabilistic algorithm that works well for text classification tasks such as spam filtering, sentiment analysis, and topic categorization.\nSupport Vector Machines (SVM) - a supervised learning algorithm that can be used for text classification and sequence labeling tasks.\nLogistic Regression - A type of algorithm used for binary classification problems, where the goal is to predict whether a given input belongs to one of two possible classes.\nLDA (Latent Dirichlet Allocation) - A probabilistic model used for topic modeling in NLP, where the goal is to identify topics within a collection of documents.\nHidden Markov Models - A statistical model used for sequence prediction problems, where the goal is to predict the sequence of states or outputs based on observed data. It is commonly used for speech recognition and named entity recognition.\n\n\n\nDeep learning-based methods\nDeep learning, a subset of machine learning, involves the use of artificial neural networks with multiple layers to learn increasingly complex patterns. Deep learning-based models, such as Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs), have shown significant success in NLP tasks such as language modeling, machine translation, and sentiment analysis. These models require large amounts of data and computing power to train, but they have led to many breakthroughs in the field.\n\n\n\nAdvantages of Deep Learning Methods in NLP\nDeep learning methods have several advantages over traditional machine learning methods in NLP:\n\nBetter performance: Deep learning models can achieve higher accuracy levels than traditional machine learning models in complex NLP tasks such as language translation and sentiment analysis.\nFeature learning: Deep learning algorithms can automatically learn features from the data, eliminating the need for feature engineering, which is often required in traditional machine learning.\nHandling large datasets: Deep learning algorithms are better suited for handling large datasets, as they can learn from a vast amount of data without overfitting or losing accuracy.\nGeneralization: Deep learning models can generalize better to unseen data, allowing them to make accurate predictions on new data points.\n\n\n\n\nCommon Neural Network Architectures for NLP\nNeural networks have been very effective in natural language processing tasks. Here are some popular architectures used in NLP:\n\nRecurrent Neural Network (RNN): It is a type of neural network where connections between nodes form a directed cycle. RNNs are useful for processing sequential data.\nLong Short-Term Memory (LSTM): It is a type of RNN that solves the vanishing gradient problem and allows the model to remember important information from earlier in the sequence.\nGated Recurrent Unit (GRU)/Convolutional Neural Network (CNN): These are alternative RNN architectures that have been shown to work well for certain NLP tasks.\nTransformers: It is a newer architecture that has gained popularity in recent years, especially in tasks such as language modeling and machine translation. It is based on a self-attention mechanism that allows the model to focus on different parts of the input sequence.\nAutoencoders: It is a type of neural network that can be used for unsupervised learning tasks such as text generation or representation learning."
  },
  {
    "objectID": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#challenges-in-nlp",
    "href": "blogs/Natural_Language_Processing(NLP)/Natural_Language_Processing(NLP).html#challenges-in-nlp",
    "title": "Natural Language Processing(NLP)",
    "section": "Challenges in NLP",
    "text": "Challenges in NLP\n\nAmbiguity\nOne of the major challenges in Natural Language Processing (NLP) is the ambiguity of human language. Ambiguity refers to situations where a word or a sentence can have multiple meanings or interpretations. For example, the word ‚Äúbank‚Äù can refer to a financial institution or a riverbank. Similarly, the sentence ‚ÄúI saw her duck‚Äù can mean ‚ÄúI saw the bird she owns‚Äù or ‚ÄúI saw her physically duck down.‚Äù This creates confusion for NLP models that rely on clear and unambiguous language. NLP researchers tackle the challenge of ambiguity by developing algorithms that can understand the context in which words are used and disambiguate the multiple meanings based on the context.\n\n\nDealing with Contextual Words\nContextual words are words that take on different meanings depending on the context in which they are used.This poses a major challenge in NLP as machines may not be able to accurately interpret the intended meaning of such words. For example, the word ‚Äúbank‚Äù can refer to a financial institution or a river bank. Another example is the word ‚Äúbass‚Äù which can refer to a fish or a low-frequency sound in music.\nTo address this challenge, NLP models are designed to consider the context of the word within the sentence, paragraph or document in order to determine the appropriate meaning. Some popular techniques used to deal with contextual words include word sense disambiguation and named entity recognition. However, the complexity of language and the vast number of possible contexts means that this remains an ongoing challenge in NLP.\n\n\nColloquialisms and slang\nColloquialisms and slang are informal words and expressions used in everyday language, which can pose a challenge in NLP. These words may not have a clear definition or meaning, and their usage can vary based on context and culture. For example, the slang term ‚Äúlit‚Äù can mean exciting or under the influence of drugs, depending on the context. Handling colloquialisms and slang is particularly important in social media analysis and chatbot development, where informal language is commonly used.\n\n\nSynonyms\nOne of the major challenges in natural language processing (NLP) is dealing with synonyms, which are words that have similar meanings but are different in their spelling or usage. This creates ambiguity and difficulty in understanding the true meaning of a sentence.For example, ‚Äúbuy‚Äù and ‚Äúpurchase‚Äù are synonyms, but they may be used differently in different contexts, such as ‚ÄúI bought a new car‚Äù versus ‚ÄúI purchased a new house.‚Äù NLP algorithms must be able to accurately identify and interpret synonyms in order to understand the intended meaning of a sentence.\n\n\nIrony, Sarcasm, and Tonal Differences\nOne of the significant challenges in NLP is detecting the tone of a text, especially irony and sarcasm. This is because the tone is often conveyed through the context and cannot be determined solely based on the words used.For example, the statement ‚ÄúOh great, another meeting‚Äù can be interpreted as positive or negative depending on the tone. Additionally, different regions or cultures may use different tonal expressions, making it difficult for NLP models to accurately detect them.\n\n\nSpelling Errors\nSpelling errors are a common challenge in NLP, as they can significantly affect the accuracy of text analysis.For example, the word ‚Äúteh‚Äù instead of ‚Äúthe‚Äù can cause confusion for NLP algorithms. This challenge is particularly prevalent in user-generated content such as social media posts, where people often use abbreviations or non-standard spellings. NLP techniques such as spell checking and correction can help mitigate this issue, but they may not always be foolproof.\n\n\nCreativity\nExplanation: One of the significant challenges in NLP is the ability to generate creative and novel sentences. It involves generating language that is not just grammatically correct but also unique and meaningful. Current NLP models struggle with producing original content, especially in tasks like text generation, poetry, and storytelling. For instance, a model might be able to generate a coherent sentence, but it may not be imaginative or creative.\nExample: A simple example would be generating a poem. While current NLP models can produce a grammatically correct poem, they might not be able to create a poem that is creative, has rhyme or meter, and evokes emotions in the reader. This is because generating creative content involves understanding not just the meaning of words but also their associations, connotations, and cultural significance.\n\n\nDiversity\nOne of the significant challenges in NLP is dealing with diversity in language, which includes differences in language structures, styles, dialects, and cultures. For example, different regions may have different ways of expressing the same idea, making it difficult to develop universal language models. Additionally, languages themselves can have varying levels of complexity, making it challenging to develop models that can handle the nuances of each language. An example of this challenge is that many languages have multiple scripts, and some languages may not even have a written form."
  },
  {
    "objectID": "blogs/Day 1  Web Scraping and AI Summarization/Day 1  Web Scraping and AI Summarization.html#introduction",
    "href": "blogs/Day 1  Web Scraping and AI Summarization/Day 1  Web Scraping and AI Summarization.html#introduction",
    "title": "Day 1 Web Scraping and AI Summarization",
    "section": "Introduction",
    "text": "Introduction\nIn this blog, I explore how to leverage Large Language Models (LLMs) for real-world tasks by combining them with traditional web scraping techniques. You‚Äôll learn how to extract website content using Python and then summarize it automatically using OpenAI‚Äôs API. This hands-on walkthrough demonstrates the synergy between classic data extraction and modern AI-powered summarization.\n\nImporting Libraries\n\nImport necessary libraries: openai, os, requests, BeautifulSoup, load_dotenv, display, and Markdown.\nThese libraries are used for interacting with the OpenAI API, handling operating system interactions, making HTTP requests, parsing HTML, loading environment variables, and displaying Markdown content.\nDependencies can be installed using requirements.txt.\nCode:\n# importing the libaries\nimport openai\nimport os\nimport requests\nfrom bs4 import BeautifulSoup\nfrom dotenv import load_dotenv\nfrom IPython.display import display, Markdown\n\n\n\nSetting Up API Key\n\nLoad environment variables from the .env file using load_dotenv().\nSet the OpenAI API key using openai.api_key = os.getenv(\"OPENAI_API_KEY\").\nCode:\n# load the environment variables from .env file \nload_dotenv()\n\n# set the OpenAI API key \nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n\n\nWebsite Class\n\nThe Website class is defined to fetch and parse website content.\nIt takes a URL as input, retrieves the HTML content using requests.get() with headers to mimic a browser, and parses it with BeautifulSoup.\nThe class extracts the title and visible text of the webpage, removing irrelevant elements like script, style, img, and input tags.\nCode:\n# Some websites need you to use proper headers when fetching them:\nheaders = {\n    # The User-Agent header is used to identify the client making the request.\n    # This helps in mimicking a real browser to avoid being blocked by websites.\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n}\n\nclass Website:\n    def __init__(self, url):\n        \"\"\"\n        Initialize a Website object from the given URL using the BeautifulSoup library.\n\n        Args:\n            url (str): The URL of the website to fetch and parse.\n        \"\"\"\n        self.url = url  # Store the URL of the website.\n\n        # Send an HTTP GET request to the URL with the specified headers.\n        response = requests.get(url, headers=headers)\n\n        # Parse the HTML content of the response using BeautifulSoup.\n        soup = BeautifulSoup(response.content, 'html.parser')\n\n        # Extract the title of the webpage, if available. If not, set it to \"No title found\".\n        self.title = soup.title.string if soup.title else \"No title found\"\n\n        # Remove irrelevant elements like &lt;script&gt;, &lt;style&gt;, &lt;img&gt;, and &lt;input&gt; from the body of the webpage.\n        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n            irrelevant.decompose()\n\n        # Extract the visible text from the body of the webpage, separating lines with a newline character.\n        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n\n\n\nPrompts\n\nSystem Prompt: Instructs the AI on its role and desired output format (e.g., summarizing a website in markdown).\nUser Prompt: Contains the specific request or query for the AI, such as summarizing the content of a given website.\nCode:\n# Define our system prompt\nsystem_prompt = \"You are an assistant that analyzes the contents of a website \\\nand provides a short summary, ignoring text that might be navigation related. \\\nRespond in markdown.\"\n\n# A function that writes a User Prompt that asks for summaries of websites:\ndef user_prompt_for(website):\n    user_prompt = f\"You are looking at a website titled {website.title}\\n\"\n    user_prompt += \"The contents of this website is as follows; \\\n    please provide a short summary of this website in markdown. \\\n    If it includes news or announcements, then summarize these too.\\n\\n\"\n    user_prompt += website.text\n    return user_prompt\n\n\n\nMessages\n\nThe OpenAI API requires messages to be structured as a list of dictionaries, with each dictionary containing a ‚Äòrole‚Äô (system or user) and ‚Äòcontent‚Äô (the prompt).\nCode:\ndef message_for(website):\n    return [\n        {'role': 'system', 'content': system_prompt},\n        {'role': 'user', 'content': user_prompt_for(website)}\n    ]\n\n\n\nSummarization Function\n\nThe summarize() function takes a URL, creates a Website object, constructs the messages with the system and user prompts, and calls the OpenAI API to generate a summary.\nThe generated summary is then returned.\nCode:\ndef summarize(url):\n    website = Website(url)\n    response = openai.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=message_for(website)\n    )\n    return response.choices[0].message.content\n\n\n\nDisplaying Summaries\n\nThe display(Markdown()) function is used to display the website summaries in Markdown format.\nCode:\ndisplay(Markdown(summarize(\"[https://edwarddonner.com](https://edwarddonner.com)\")))\ndisplay(Markdown(summarize(\"[https://cnn.com](https://cnn.com)\")))\ndisplay(Markdown(summarize(\"[https://anthropic.com](https://anthropic.com)\")))\n\n\n\nOutput After running the below code\ndisplay(Markdown(summarize(\"[https://anthropic.com](https://anthropic.com)\")))"
  },
  {
    "objectID": "blogs/Day 1  Web Scraping and AI Summarization/Day 1  Web Scraping and AI Summarization.html#recent-announcements",
    "href": "blogs/Day 1  Web Scraping and AI Summarization/Day 1  Web Scraping and AI Summarization.html#recent-announcements",
    "title": "Day 1 Web Scraping and AI Summarization",
    "section": "Recent Announcements",
    "text": "Recent Announcements\n\nISO 42001 Certification: An announcement regarding achieving certification in responsible AI practices.\nClaude 3.7 Sonnet Launch: Announcement of the release of the latest iteration of Claude, touted as the most intelligent AI model yet.\n\nAnthropic positions itself as a leader in developing AI with a focus on safety and long-term societal benefits."
  }
]